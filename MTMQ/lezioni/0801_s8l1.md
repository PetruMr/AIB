# Matrice di densità

## Introduzione

La **matrice di densità** sarà l'argometnpo di questa lezione.

Si tratta di un modo di approcciare la descrizione dei sistemi quantistici che non si basa sul concetto di stato puro, ma su quello di stato misto. Ci aiutano a definire meglio i sistemi aperti, i fenomeni della decoerenza, etc.

## 1 ⋅ Formalismo delle matrici di densità

Andiamo a riprendere i postulati della meccanica quantistica e li andiamo a riesprimere utilizzando le matrici di densità.

### 1.1 ⋅ Definizioni iniziali

#### 1.1.1 ⋅ Stato puro

Un sistema in uno **stato puro** si definisce come:

$$
\ket{\psi} \in \mathcal{H}
\\ \ \\
\begin{align*}
\text{i)} & \quad \braket{\psi | \psi} = 1
\\ \ \\
\text{ii)} & \quad \ket{\psi} \approx e^{i\theta} \ket{\psi}
\end{align*}
$$

Uno **stato misto** invece è definito da tanti $\ket{\psi_i}$ con probabilità $p_i$:, tali che:
- $\sum_i p_i = 1$
- $0 \leq p_i \leq 1$.

C'è quindi una miscela statistica classica.

#### 1.1.2 ⋅ Definizione di ket e bra

Il **ket** è definito come:

$$
\ket{\psi} = 
\begin{pmatrix}
\psi_1 \\
\psi_2 \\
\vdots \\
\psi_n
\end{pmatrix}
$$

E il **bra** è definito come:

$$
\bra{\psi} =
\begin{pmatrix}
\psi_1^* & \psi_2^* & \cdots & \psi_n^*
\end{pmatrix}
$$

Dove $^*$ indica il complesso coniugato, ovvero:

$$
\psi^* = \Re(\psi) - i\Im(\psi)
$$

Il **bra** moltiplicato con il **ket** ci dà:

$$
\braket{\psi | \phi} = \sum_i \psi_i^* \phi_i
$$

Mentre il **ket** moltiplicato con il **bra** ci dà:

$$
\ket{\psi} \bra{\psi} =
\begin{pmatrix}
\psi_1 \\
\psi_2 \\
\vdots \\
\psi_n
\end{pmatrix}
\begin{pmatrix}
\psi_1^* & \psi_2^* & \cdots & \psi_n^*
\end{pmatrix}
=
\begin{pmatrix}
\psi_1 \psi_1^* & \psi_1 \psi_2^* & \cdots & \psi_1 \psi_n^* \\
\psi_2 \psi_1^* & \psi_2 \psi_2^* & \cdots & \psi_2 \psi_n^* \\
\vdots & \vdots & \ddots & \vdots \\
\psi_n \psi_1^* & \psi_n \psi_2^* & \cdots & \psi_n \psi_n^*
\end{pmatrix}
$$

(Ovvero una matrice di dimensione $n \times n$).

### 1.2 ⋅ Matrici di densità

#### 1.2.1 ⋅ Definizioni

Abbiamo $\rho$ che è una matrice di densità, definita come:

$$
\rho_{\psi} = \ket{\psi} \bra{\psi}
$$

Che è una matrice $N\times N$ che dipende dal vettore $\ket{psi}$ normalizzato.

Abbiamo poi:

$$
\rho_{\psi'} = e^{i\theta} \ket{\psi'} \bra{\psi'} e^{-i\theta} = \ket{\psi} \bra{\psi} = \rho_{\psi}
$$

#### 1.2.2 ⋅ Proprietà 1

$$
\rho_\psi = \ket{\psi} \bra{\psi}
$$

Che ci da:

$$
\rho_\psi^\dagger = \rho_\psi
\\ \ \\
\rho_\psi^2 = \rho_\psi
$$

Se queste cose valgono si dice che è un operatore di proiezione su un qualche sottospazio.

Vediamo subito che se io considero lo spazio $\mathcal{H}_\psi$ tale che:

$$
\mathcal{H}_\psi = \{ \lambda \ket{\psi} | \lambda \in \mathbb{C} \} \quad, \quad \ket{\Phi} \in \mathcal{H}_\psi^{\perp}
$$

Verificare inoltre le proprietà:
- $\rho_\psi (\lambda \ket{\psi}) = \lambda \ket{\psi}$
- $\rho_\psi \ket{\Phi} = 0$

Inoltre vale che:
- $\rho_\psi$ è limitato
  - $\| \rho_\psi \| = 1$
- $\rho_\psi$ è un operatore positivo
  - $\forall \ket{\alpha} \in \mathcal{H} \quad \bra{\alpha} \rho_\psi \ket{\alpha} \geq 0$
  - Dimostrazione dell'ultima equivalenza: $\bra{\alpha} \rho_\psi \ket{\alpha} = \braket{\alpha | \psi} \braket{\psi | \alpha} = |\braket{\alpha | \psi}|^2 \geq 0$

#### 1.2.3 ⋅ Proprietà dimostrate

La prima prorietà:

$$
\rho_\psi^\dagger =  (\ket{\psi}\bra{\psi})^\dagger = \bra{\psi}^\dagger \ket{\psi}^\dagger = \ket{\psi} \bra{\psi} = \rho_\psi
$$

E la seconda:

$$
\rho_\psi^2 = \ket{\psi} \bra{\psi} \ket{\psi} \bra{\psi} = \ket{\psi} \braket{\psi | \psi} \bra{\psi} = \ket{\psi} \bra{\psi} = \rho_\psi
$$

### 1.3 ⋅ Traccia

Abbiamo che la **traccia** di una matrice è definita come:

$$
\text{Tr}(\rho) = \sum_i \rho_{ii}
$$

In particolare, la traccia di $\rho_\psi$ è:

$$
\text{Tr}(\rho_\psi) = 1
= \sum_{k=1}^N \braket{e_k | \psi} \braket{\psi | e_k} = \sum_{k=1}^N \braket{e_k | \rho_\psi | e_k}
$$

Scelta la base o.n. $\{\ket{e_k}\}^{m}_{k=1}$. Scegliamo quello che ci pare, in particolare ci scegiamo all'inizio:
- $\ket{e_1} = \ket{\psi}$
- Poi gli altri li andiamo a formare usando il metodo di Gram-Schmidt, quindi otteniamo tutti gli altri che sono **ortogonali** a $\ket{\psi}$.

Quindi abbiamo scelto una base furba dove tutti gli elementi sono ortogonali a $\ket{\psi}$, pertanto la moltiplicazione $\braket{e_k | \psi}$ sarà nulla per $k \neq 1$.

Quindi abbiamo:
- $\braket{\psi | e_k} = 0, k \geq 2$
- $\braket{\psi | e_1} = \braket{\psi | \psi} = 1$

#### 1.3.1 ⋅ Proprietà 2

In particolare, per $\rho_\psi = \ket{\psi} \bra{\psi}$ abbiamo che:
1. $\rho_\psi$ è limitato
  1. $\| \rho_\psi \| = 1$
  2. Questo non lo andiamo ad usare nella nostra dimostrazione come cosa, in quanto ci limitiamo a dimostrare il caso $n$ dimensionale, tuttavia diventa utile per il caso infinito dimensionale.
2. $\rho_\psi^\dagger = \rho_\psi$
3. $\rho_\psi \geq 0$
4. $\text{Tr}(\rho_\psi) = 1$
5. $\rho_\psi^2 = \rho_\psi$
   1. Idempotenza

Se noi andiamo a definire una matrice $\rho$ tale che soddisfa queste 5 proprietà, allora riusciamo a definire una matrice di densità.

$$
\text{Se ho matrice } \rho \text{ t.c. } (i), (ii), (iii), (iv), (v) \text{ sono vere } \iff \rho=\ket{\psi}\bra{\psi}, \exists \ket{\psi} \in \mathcal{H}
$$

Se parto da uno stato fisico e costruirco la $\rho$, allora abbiamo dimostrato che le proprietà sono vere.

Dimostriamo anche al contrario, ovvero che se noi abbiamo che valgono queste 5 proprietà allora possiamo andare a descrivere queste proprietà. Si usa il **teorema spettrace**:

$$
A = A^T \implies \exists \text{ base autovettori (ortonormali) }
\\ \ \\
A \ket{\psi_k} = \lambda_k \ket{\psi_k} \quad, \quad \lambda_k \in \mathbb{R}
$$

Quindi abbiamo che:

$$
\rho^\dagger = \rho \implies \rho = \sum_{k=1}^H \lambda_k \ket{\psi_k} \bra{\psi_k}
\\ \ \\
= \begin{pmatrix}
\lambda_1 & 0 & \cdots & 0 \\
0 & \lambda_2 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \lambda_n
\end{pmatrix}
$$

(Proiettori diversi sono uguali a 0, mentre quelli uguali sono 1).

Abbiamo che, la proprietà 5 ci dice che abbiamo unicamente autovalori, ordinati in qualche modo:

$$
\rho^2 = \sum_{k=1}^{N} \lambda^2_k \ket{\psi_k} \bra{\psi_k} = \sum_{k=1}^{N} \lambda_k \ket{\psi_k} \bra{\psi_k} = \rho
$$

In quando abbiamo che $\lambda^2_k = \lambda_k$, visto che abbiamo che $\lambda_k \in \{0, 1\}$ (sono tutti 0 tranne uno che è 1).

Infine abbiamo che:

$$ 
1 = \text{Tr}[\rho] = \sum_{k=1}^{N} \lambda_k \quad \quad \lambda_1 = 1, \quad \lambda_2 = ... = \lambda_{N} = 0
$$

### 1.4 ⋅ Primo postulato

Andiamo a definire lo **stato puro** come descritto da una matrice di densità $\rho$ che ha le 5 proprietà definite prima, ovvero:
1. $\rho$ è limitato
2. $\rho^\dagger = \rho$
3. $\rho \geq 0$
4. $\text{Tr}(\rho) = 1$
5. $\rho^2 = \rho$

### 1.5 ⋅ Secondo postulato (Evoluzione)

Ovvero abbiamo che:

$$
\begin{align*}
\ket{\psi(t=0)} \to & \ket{\psi(t)} = e^{-i \frac{tH}{\hbar}} \ket{\psi(t=0)}
\\ \ \\
& \bra{\psi(t)} = \bra{\psi(t=0)} e^{i \frac{tH}{\hbar}}
\end{align*}
$$

Abbiamo quindi che:

$$
\rho(t = 0) = \ket{\psi(t=0)} \bra{\psi(t=0)}
\\ \ \\
\downarrow
\\ \ \\
\rho(t) = e^{-i \frac{tH}{\hbar}} \rho(t=0) e^{i \frac{tH}{\hbar}} = e^{-i \frac{tH}{\hbar}} \ket{\psi(t=0)} \bra{\psi(t=0)} e^{i \frac{tH}{\hbar}}
$$

Definiamo un **osservabile A**, ovvero un operatore autoaggiunto, ovveor $A = A^\dagger$. Cosa ci possiamo fare?

$$
\braket{A} = \braket{\psi | A | \psi}
$$

Ed abbiamo che $\rho = \ket{\psi} \bra{\psi}$, quindi andiamo a riderfinirelo in termini della matrice di densità.

Partiamo con un **osservazione**: $\{\ket{e_k}\} = $ base ortonormale. Quindi possiamo andare ad avere:
- $P_k = \ket{e_k} \bra{e_k}$
  - Per esempio $P_1 = \ket{e_1} \bra{e_1}$ proietta sul primo sottospazio
  - $P_2 = \ket{e_2} \bra{e_2}$ proietta sul secondo sottospazio
  - etc.

Se noi abbiamo $P_1 + P_2$ abbiamo un operatore di proiezione che proietta sul sottospazio generato da $\ket{e_1}$ e $\ket{e_2}$.

Cosa succede se li sommo tutti, quindi? Ovvero se noi abbiamo $P_1 + P_2 + ... + P_N$, su cosa proietta? Esso proietta su tutto lo spazio di Hilbert, e l'unico operatore che lo fa è l'identità, quindi:

$$
P_1 + P_2 + ... + P_N = \mathbb{I}
\\ \ \\
\sum_{k=1}^{N} \ket{e_k} \bra{e_k} = \mathbb{I}
$$

Quest'ultima equazione ha un secondo nome in matematica, ovvero la **risoluzione dell'identità** (perché risoluzione? perché scompongo l'identità in tutti operatori unidimensionali).

Torniamo quindi indietro a $\braket{A} \equiv \braket{\psi | A | \psi}$, e andiamo a metterci un operatore di identità:

$$
\begin{align*}
\braket{A} &= \braket{\psi | A | \psi}
\\ \ \\
&= \braket{\psi | A \mathbb{I} | \psi}
\\ \ \\
&= \braket{\psi | A \left( \sum_{k=1}^{N} \ket{e_k} \bra{e_k} \right) | \psi}
\\ \ \\
&= \sum_{k=1}^{N} \braket{\psi | A | e_k} \braket{e_k | \psi}
\\ \ \\
&= \sum_{k=1}^{N} \braket{e_k | \psi} \braket{\psi | A | e_k}
\\ \ \\
&= \sum_{k=1}^{N} \braket{e_k | \rho_\psi A | e_k}
\\ \ \\
&= \text{Tr}[\rho_\psi A]
\end{align*}
$$

### 1.6 ⋅ Misura proiettiva

Spesso indicata con **PVM** (Che vuol dire "*Projection Valued Measure*").

Se noi dobbiamo **misurare** un osservabile, ovvero $A$ tale che $A = A^\dagger$, definito prima come:

$$
A = \sum_{k=1}^{N} \lambda_k P_k = \sum_{k=1}^{N} \lambda_k \ket{e_k} \bra{e_k}
$$

Consideriamo una famiglia $\{P_k\}^N_{k=1}$ con operatori di proiezione tali che:
- $P_k = P_k^\dagger$
- $P_k^2 = P_k$
- $P_k P_e = 0$ per $k \neq e$
- $\sum_{k=1}^{N} P_k = \mathbb{I}$

Quindi parlare di una misura di un osservabile vuol dire volere questa famiglia di proiettori.

Cosa fa la misura quantistica? Dopo aver misurato l'osservabile $A$ sullo stato aribtrario $\ket{\psi} \in \mathcal{H}$:
- Il **risultato** è uno dei possibili autovalori $\lambda_k$
  - Che lo ottengo con una certa probabilità $p_k$
  - La probabilità è $\ket{\psi} = \sum_{k=1}^N c_k \ket{e_k}$
  - Con $c_k = \braket{e_k | \psi}$
  - E quindi la probabilità è: $p_k = |c_k|^2 = |\braket{e_j | \psi }|^2$
  - Quindi la prima proprietà della misura è che essa è **probabilistica**
- La misura è inoltre **distruttiva**, ovvero:
  - Dopo la misura lo stato del sistema è $\ket{e_k}$.
  - In particolare: $\ket{\psi} \to \ket{e_k} = \frac{P_k \ket{\psi}}{\sqrt{\braket{\psi | P_k^\dagger P_k | \psi}}}$

Questo tipo di misure che è l'unico modo che abbiamo per indagare negli stati quantistici, non mi permette di fare alcune cose.

#### 1.6.1 ⋅ Esempio

Immaginiamo di prendere un **qubit**, che è descritto da:

$$
\ket{\psi} = a \ket{0} + b \ket{1}
$$

Abbiamo una base computazionale, ovvero $\{\ket{0}, \ket{1}\}$.

Abbiamo che:

$$
P_0 = \ket{0} \bra{0}
\\ \ \\
P_1 = \ket{1} \bra{1}
$$

PVM ci da:

$$
A = (+1) P_0 + (-1) P_1
$$

Dove $P_0 = |a|^2$ e $P_1 = |b|^2$.

Sappiamo che il nostro *qubit* può essere stato preparato o in $\ket{0}$ o in $\ket{1}$. Sia $\ket{0} = \ket{\psi_1}$ e $\ket{1} = \ket{\psi_2}$, per aiutarci a renderlo più generico. Allora abbiamo se noi abbiamo (e poi misuriamo, abbiamo la probabilità di):

$$
\ket{\psi} = \ket{\psi_1} = \ket{0} \quad \text{se misuro} \quad +1 \implies P_+ = 1
\\ \ \\
\ket{\psi} = \ket{\psi_2} = \ket{1} \quad \text{se misuro} \quad -1 \implies P_- = 1
$$

Immaginiamo però di avere i due possibili stati:

$$
\ket{\psi_1} = \ket{0}
\\ \ \\
\ket{\psi_2} = \frac{1}{\sqrt{2}} \ket{0} + \frac{1}{\sqrt{2}} \ket{1}
$$

Da qui, abbiamo che il primo caso ci da solo la misura di $(+1)$ con probabilità di $P_+ = 1$, mentre se noi abbiamo l'altro stato allora abbiamo le probabilità di misurare positivo o negativo con probabilità di $P_+ = P_- = 1/2$.

Notiamo che quindi la misura di positivo non ci va a dire nulla sullo stato del sistema, mentre la misura di negativo ci dice che lo stato è $\ket{\psi_2}$.

> Le misure quantistiche PVM **non** distinguino stati non ortogonali.

Questa cosa rimane sempre vera, però posso fare un po' di meglio con alcuni altri tipi di misura, ovvero le misure **POVM**.

### 1.7 ⋅ Misura POVM

Le misure **POVM** (Positive operator valued measure).

Abbiamo $\{M_n\}$ (con esito delle misure $\lambda_n$) che sono operatori tali che ($M_n ^\dagger M_n \geq 0$):
- $\sum_n M_n^\dagger M_n = \mathbb{I}$

La misura dello stato $\ket{\psi}$:
- Abbiamo un **esito probabilistico**
  - $\lambda_n$ con $p_n = \braket{\psi | M_n^\dagger M_n | \psi}$
- Abbiamo il **collasso**
  - $\ket{\psi} \to \frac{M_n \ket{\psi}}{\sqrt{\braket{\psi | M_n^\dagger M_n | \psi}}}$

Abbiamo che, inoltre:

$$
PVM \subset POVM
\\ \ \\
\text{dove}
\\ \ \\
M_n = P_n \text{ proiettore } A= \sum_k \lambda_k P_k
\\ \ \\
M_n ^\dagger = P_n^\dagger = P_n
$$

Tutte le misure proiettive che abbiamo visto prima sono un caso particolare delle misure POVM.

Abbiamo che:

$$
\sum_n P_n = \sum_n \braket{\psi | M_n ^\dagger M_n | \psi}
\\ \ \\
= \braket{\psi | \left( \sum_n M_n ^\dagger M_n \right) | \psi}
\\ \ \\
= \braket{\psi | \mathbb{I} | \psi}
\\ \ \\
= \braket{\psi | \psi} = 1
$$

Con le POVM abbiamo:
- $\lambda_0 \quad M_0 = \ket{1} \bra{1}$
- $\lambda_1 \quad M_1 = \ket{\phi} \bra{\phi}$, dove $\ket{\phi} = \frac{1}{\sqrt{2}} \ket{0} + \frac{1}{\sqrt{2}} \ket{1}$
- $\lambda_2 \quad M_2$ tale che $M_0^\dagger M_0 + M_1^\dagger M_1 + M_2 ^\dagger M_2 = \mathbb{I}$

Supponiamo di star misurando $\ket{\psi} = \ket{0}$, allora abbiamo che:
- $p_0 = 0$
- $p_1 \neq 0$
- $p_2 \neq 0$

Se invece stiamo misurando $\ket{\psi} = \ket{\phi}$, allora abbiamo che:
- $p_0 \neq 0$
- $p_1 = 0$
- $p_2 \neq 0$

Quindi riusciamo a definire dei casi dove:
- Se troviamo $M_0$ allora sappiamo che lo stato è $\ket{1}$ con sicurezza
- Se troviamo $M_1$ allora sappiamo che lo stato è $\ket{\phi}$ con sicurezza
- Se troviamo $M_2$ allora non possiamo dire nulla

Quindi questa misura POVM è, con un insieme di cose scelte attentamente, in grado di distinguere stati non ortogonali (anche se non al 100%). Risultano quindi utili per la misura.

Da notare che ho una famiglia più grande dei possibili stati che posso misurare. L'unica condizione che viene imposta a questa famiglia è l'uguaglianza:

$$
\sum_n M_n^\dagger M_n = \mathbb{I}
$$

### 1.8 ⋅ Concetto delle POVM nelle matrici di densità

Se noi abbiamo uno POVM definita dalla famiglia $\{M_n\}$ tale che $\sum_n M_n^\dagger M_n$ mi definire la misura su $\ket{\psi}$:
- Misuriamo $\lambda_n$ con probabilità $p_n = \braket{\psi | M_n^\dagger M_n | \psi}$
- Lo stato collassa a $\ket{\psi} \to \frac{M_n \ket{\psi}}{\sqrt{\braket{\psi | M_n^\dagger M_n | \psi}}}$

Adesso ricordiamoci la definizione di matrice di densità $\rho_\psi = \ket{\psi} \bra{\psi}$.

Abbiamo quindi:
- Misuriamo $\lambda_n$ con probabilità $p_n = \text{Tr}[M_n^\dagger M_n \rho_\psi]$
- Lo stato collassa a $\rho_\psi \to \frac{M_n \rho_\psi M_n^\dagger}{\text{Tr}[M_n^\dagger M_n \rho_\psi]}$