# Lezioni di una prof che segue Nielsen Chuang QIQT

Il link della playlist è [questo](https://www.youtube.com/watch?v=Joj2pH1Jczc&list=PLqLyTdPNhQZwfLoL4QMeI6scnyH1c__tE&index=1)

## 1 ⋅ Introduzione

Andiamo a spiegare i concetti principali del corso e di quello che si intende con Qubit e altro.

### 1.1 ⋅ Differenza tra bit e qubit

Il bit è $x\in \{0,1\}$, mentre il qubit è $\alpha |0\rangle + \beta |1\rangle$ con $\alpha, \beta \in \mathbb{C}$ e $|\alpha|^2 + |\beta|^2 = 1$.

Una superposizione è uno stato del tipo: $\frac{1}{\sqrt{2}}|0\rangle + \frac{1}{\sqrt{2}}|1\rangle$, per esempio. In generale si intende una combinazione lineare di stati di base.

### 1.2 ⋅ Perché non usiamo numeri reali

Questa è una domanda fatta da uno studente, ed è: perché non usiamo valori reali per i coefficienti dei qubit? Ovvero per $\alpha$ e $\beta$?.

La risposta è: questo è stato indagato, si chiamano **Rebit**, ovvero *Real-qubit*, ma si è anche visto che non ci sono le stesse operazioni disponibili e si perde parte del vantaggio che si ha con i qubit.

### 1.3 ⋅ Operazioni sui qubit

Per i bit abbiamo per esempio operazioni come l'**AND** e l'**OR**, mentre per i qubit abbiamo operazioni come l'**Hadamard** e l'**X**.

Le **quantum gates** sono *trasformazioni lineari* (matrici) che agiscono sui Qubit.

Per esempio la $X$ gate è: 

$$
X = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}
$$

Ed è equivalente ad una porta "NOT" ma per i Qubit.

Viene fatto l'esempio con $X\ket{+} = \ket{+}$. Un'altra cosa da notare è: $X\ket{-} = -\ket{-}$.

Quindi abbiamo:
- $X\ket{+} = \ket{+}$
- $X\ket{-} = -\ket{-}$

Questi, come sappiamo dall'algebra lineare, saranno quindi gli **eigenvectors** e gli **eigenvalues** della matrice $X$, ovvero:
- $\ket{+}$ è un **eigenvector** di $X$ con **eigenvalue** $+1$
- $\ket{-}$ è un **eigenvector** di $X$ con **eigenvalue** $-1$

### 1.4 ⋅ Pauli matrices

Andiamo a definire le matrici di Pauli, che sono:

$$
I = \sigma_0 = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}
\\ 
X = \sigma_x = \sigma_1 = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}
\\
Y = \sigma_y = \sigma_2 = \begin{pmatrix} 0 & -i \\ i & 0 \end{pmatrix}
\\
Z = \sigma_z = \sigma_3 = \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}
$$

Con i vari eigenvalues ed eigenvectors che sono:
- $\sigma_0$
  - $\ket{0}$, $\lambda=+1$
  - $\ket{1}$, $\lambda=+1$
- $\sigma_1$
  - $\ket{+}$, $\lambda=+1$
  - $\ket{-}$, $\lambda=-1$
- $\sigma_2$
  - $\ket{i}$, $\lambda=+1$
    - Ovvero $\ket{i} = \frac{1}{\sqrt{2}}(\ket{0} + i\ket{1})$
  - $\ket{-i}$, $\lambda=-1$
    - Ovvero $\ket{-i} = \frac{1}{\sqrt{2}}(\ket{0} - i\ket{1})$
- $\sigma_3$
  - $\ket{0}$, $\lambda=+1$
  - $\ket{1}$, $\lambda=-1$

Da notare che la $X$ gate fa un **bit-flip**, mentre la $Z$ gate fa un **phase-flip**, ovvero al posto di flippare da $\ket{0}$ a $\ket{1}$ flippa da $\ket{+}$ a $\ket{-}$.

Tutte le qubit gate da 1 qubit sono invertibili, ovvero esiste sempre una matrice inversa.

Anche tutte le qubit gate da 2 qubit sono invertibili. In generale tutte le qubit gate sono invertibili.

### 1.5 ⋅ Universal quantum gate

Nei computer classici una gate universale è il **NAND** (non è l'unica, ma è una di quelle universali). Universale vuol dire che con solo questa puoi andare a costruire tutte le altre.

Nei **computer quantistici** per avere un insieme universale di gate si usano:
- **Gate a 1 qubit**
- **CNOT**

E da qui si possono generare tutte le altre.

### 1.6 ⋅ Deutsch algorithm

Prendiamo il **problema** iniziale per definire questo algoritmo:
- Abbiamo una funzione binaria $f(x), x \in \{0,1\}$
- Ci sono due casi:
  - $f(0) = f(1)$ (funzione costante)
  - $f(0) \neq f(1)$ (funzione bilanciata)

Data questa funzione, il problema è: come possiamo determinare se una funzione è costante o bilanciata?

Innanzitutto definiamo cosa vuol dire "data $f$"; si intende avere un **black box** che implementa la funzione $f$.

Classicamente questa funzione richiede 2 **query** per determinare se la funzione è costante o bilanciata.

Con un computer quantistico si può fare con una sola query. Vediamo come.

#### 1.6.1 ⋅ Introduzione

Andiamo a definire una **control gate** che funziona nel seguente modo:

```
         ┌────┐ 
r1  |x>──│    │─|x>
         │ Uf │ 
r1  |y>──│    │─|y ⊕ f(x)>
         └────┘
```
Quindi il risultato è $\ket{x, y \oplus f(x)}$.

Una cosa che possiamo fare è per esempio dare un input $\ket{x}$ che è una sovrapposizione di $\ket{0}$ e $\ket{1}$, ovvero $\frac{1}{\sqrt{2}}(\ket{0} + \ket{1})$. Questo è il primo step dell'algoritmo.

Successivamente, come secondo step, dobbiamo andare a **estrarre** informazioni riguardo a $f(0) = f(1)$ o $f(0) \neq f(1)$ come una fase relativa.

Il terzo e ultimo step è quello di misurare e identificare se $f$ è costante o bilanciata.

C'è 1 sola query che viene effettuata al **black box**.

#### 1.6.2 ⋅ Implementazione

Praticamente prendiamo la gate $U_f$ e ci andiamo a mettere come input $\ket{x}$ e $\ket{y}$ i valori:
- $\ket{x} = \frac{1}{\sqrt{2}}(\ket{0} + \ket{1})$
- $\ket{y} = \frac{1}{\sqrt{2}}(\ket{0} - \ket{1}$
  - Da notare che questo qubit si chiama anche **ancilla qubit**.
  - Questi sono **qubit ausiliari** che vengono usati per fare calcoli.
  - Molti algoritmi quantistici usano uno o più qubit ausiliari.

Adesso andiamo a calcolare quale è il risultato di applicare $U_f$ a questi due input.

Quindi l'input state è:

$$
\left(\frac{1}{\sqrt{2}}(\ket{0} + \ket{1})\right)_d \left(\frac{1}{\sqrt{2}}(\ket{0} - \ket{1})\right)_a
\\ \ \\
= \frac{1}{2}(\ket{0}_d + \ket{1}_d)(\ket{0}_a - \ket{1}_a)
\\ \ \\
= \frac{1}{2}(\ket{0}_d\ket{0}_a - \ket{0}_d\ket{1}_a + \ket{1}_d\ket{0}_a - \ket{1}_d\ket{1}_a)
\\ \ \\ \ \\
\text{togliendo le lettere diventa: }
\\ \ \\
= \frac{1}{2}(\ket{00} - \ket{01} + \ket{10} - \ket{11})
$$

Quindi applicando $U_f$ a questo stato otteniamo:

$$
U_f\left(\frac{1}{2}(\ket{00} - \ket{01} + \ket{10} - \ket{11})\right)
\\ \ \\
= \frac{1}{2}(\ket{0}\ket{f(0)} + \ket{1}\ket{f(1)} - \ket{0}\ket{1 \oplus f(0)} - \ket{1}\ket{1\oplus f(1)})
$$

Notare che:
- $1 \oplus f(0) = \overline{f(0)}$
- $1 \oplus f(1) = \overline{f(1)}$

Quindi possiamo anche scrivere:

$$
= \frac{1}{2}(\ket{0}\ket{f(0)} + \ket{1}\ket{f(1)} - \ket{0}\ket{\overline{f(0)}} - \ket{1}\ket{\overline{f(1)}})
$$

A questo punto andiamo a capire i vari casi, quindi confrontiamo come cambia se abbiamo che $f(0) = f(1)$ o $f(0) \neq f(1)$:
- Se $f(0) = f(1)$ allora:
  - $\ket{f(0)} = \ket{f(1)}$
  - $\ket{\overline{f(0)}} = \ket{\overline{f(1)}}$
  - Quindi il risultato sarà:
    - $\frac{1}{2}(\ket{0}\ket{f(0)} + \ket{1}\ket{f(0)} - \ket{0}\ket{\overline{f(0)}} - \ket{1}\ket{\overline{f(0)}})$
    - $\frac{1}{2}(\ket{0} + \ket{1})(\ket{f(0)} - \ket{\overline{f(0)}})$
- Se $f(0) \neq f(1)$ allora:
  - $\ket{\overline{f(0)}} = \ket{f(1)}$
  - $\ket{f(0)} = \ket{\overline{f(1)}}$
  - Quindi il risultato sarà:
    - $\frac{1}{2}(\ket{0}\ket{f(0)} + \ket{1}\ket{f(1)} - \ket{0}\ket{\overline{f(0)}} - \ket{1}\ket{\overline{f(1)}})$
    - $\frac{1}{2}(\ket{0} - \ket{1})(\ket{f(0)} - \ket{f(1)})$

Notiamo che quindi abbiamo **estratto l'informazione** relativo all'essere pari o dispiari della funzione all'interno della **fase relativa** del *data registry* (il primo qubit).

Quindi possiamo fare una misura sul primo qubit e capire se la funzione è costante o bilanciata, in particolare ci applichiamo una **Hadamard** gate e misuriamo usando la base computazionale $\{\ket{0}, \ket{1}\}$.

Quindi siamo riusciti a fare tutto questo con una sola query.

### 1.7 ⋅ Deutsch-Josza algorithm

Diciamo di avere la funzione arbitraria $f(x)$ dove:
- $x = x_1x_2...x_n$ con $x_i \in \{0,1\}$
  - Quindi $x$ è una stringa di $n-$bit
- $f(x)$ è una funzione che mappa $x$ in $\{0,1\}$
- Ci sono due casi:
  - $f(x)$ è costante, ovvero $f(x) = 0$ per ogni $x$ oppure $f(x) = 1$ per ogni $x$
  - $f(x)$ è bilanciata, ovvero $f(x)$ è uguale a $0$ per metà degli input e $1$ per l'altra metà

Il problema è: come possiamo determinare se una funzione è costante o bilanciata?

Ci viene dato un **black box** che implementa la funzione $f(x)$.

Da notare che un computer classico richiede $2^{n-1} + 1$ query per determinare se la funzione è costante o bilanciata, ovvero dobbiamo andare a fare una query per metà degli input + 1.

Questo, con un algoritmo quantistico, si può fare usando 1 sola query.

### 1.8 ⋅ Entangled bits

Andiamo a descrivere come possiamo passare da $\ket{+}\ket{0}$ a $\frac{1}{\sqrt{2}}(\ket{00} + \ket{11})$.

Per fare questo possiamo usare una **CNOT** gate tra i due qubit.



## 2 ⋅ Postulati della MQ

Nelle ultime lezioni abbiamo definito un **qubit** come:
- Qualcosa che sta in uno spazio vettoriale lineare complesso di due dimensioni
- Lo stato di un sistema quantistico a due livelli
- Queste due cose sono intercambiabili

Classicalmente, si descrive tipicamente lo stato di un sistema come un set di *generalized coordinates* e *generalized momenta* / *velocities*.

Per esempio, per descrire un insieme di particelle in un sistema classico, si può usare un set di coordinate e velocità.

Questo tipo di descrizione è dovuta venire abbandonata quando siamo arrivati a descrivere la MQ. Solo i sistemi classici possono essere espressi così, quelli quantistici no.

Andiamo a vedere quindi i postulati e come possiamo andare a descrivere i nostri sistemi

### 2.1 ⋅ Postulato 1

> Status of a quantum system are associated with **unit-vectors** in a Hilbert space.

Quindi non sono più associati a coordinate e velocità, ma a **unit-vectors** in uno spazio di Hilbert, ovvero uno spazio vettoriale complesso. Non ci interessa andare a definire lo spazio di Hilbert in modo rigoroso, ci limitiamo a considerarlo come un: **finite dimensional linear vecotr space endowed with an inner product**. Si chiama anche una **inner product space**.

Come lo andiamo a definire?

Ricordiamoci che: sia $\mathbb{V}$ uno spazio vettoriale lineare. $\mathbb{V}$ è una collezione di vettori $\{\ket{v}\}$, dove $\ket{v}$ è un vettore in $\mathbb{V}$, tale che:
1. se $\ket{v}, \ket{w} \in \mathbb{V}$, allora $\ket{v} + \ket{w} \in \mathbb{V}$
2. se $\ket{v} \in \mathbb{V}$ e $\alpha \in \mathbb{C}$, allora $\alpha \ket{v} \in \mathbb{V}$
3. Se $\alpha, \beta \in \mathbb{C}$ e $\ket{v}, \ket{w} \in \mathbb{V}$, allora $\alpha \ket{v} + \beta \ket{w} \in \mathbb{V}$
   1. Qualsiasi combinazione lineare complessa di vettori in $\mathbb{V}$ è ancora in $\mathbb{V}$
4. Esiste un vettore nullo $0$ in $\mathbb{V}$ tale che $\ket{v} + 0 = \ket{v}$ per ogni $\ket{v} \in \mathbb{V}$
   1. Non usiamo $\ket{0}$ per non confonderlo con lo stato $\ket{0}$ di un qubit

Alcuni esempi possono essere per esempio:
- Uno spazio di $d\times1$ complex matrices
  - Anche scrivible come $d-dimensional$ complex vectors
  - Anche scrivibile come $d-dimensional$ column vectors
  - Questo si scrive anche come $\mathbb{C}^d$
  - Per esempio $\ket{v} = \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_d \end{pmatrix}$ che sta in $\mathbb{C}^d$

Qua continua una discussione sui vettori, sulle basi, su come esprimere i vettori in termini di basi, ecc. 

Un esempio meno banale di uno spazio di Hilbert è quello di uno spazio di funzioni.

Consideriamo lo spazio di funzioni "square-integrable" definito nel seguente modo:

$$
\psi(x) : [0,1] \to \mathbb{C}
\\ \ \\
\text{Ovvero complex-valued functions}
$$

Il fatto che sono square-integrable vuol dire che:

$$
\int_{0}^{1} \psi^*(x) \psi(x) dx = \int_{0}^{1} |\psi(x)|^2 dx < \infty
$$

Quindi c'è un insieme finito di elementi attraverso i quali possiamo andare ad esprimere la funzione.

#### 2.1.1 ⋅ Inner product e dual space

Andiamo a definire l'**inner product** tra due vettori $\ket{v}$ e $\ket{w}$ come:

$$
\braket{v|w} = \sum_{i=1}^{d} v_i^* w_i
$$

L'inner product è una funzione che prende due vettori e restituisce un numero complesso. Inoltre ha le seguenti proprietà:
1. $\braket{v|w} = \braket{w|v}^*$
2. $\braket{v|v} \geq 0$
3. $\braket{v|v} = 0$ se e solo se $\ket{v} = 0$
4. $\braket{v|\alpha w + \beta z} = \alpha \braket{v|w} + \beta \braket{v|z}$ - linearità nel secondo termine
5. $\braket{\alpha v + \beta w|z} = \alpha^* \braket{v|z} + \beta^* \braket{w|z}$ - anti-linearità nel primo termine

Definiamo inoltre il $\bra{v}$ come il **bra** di $\ket{v}$, ovvero il **dual vector** di $\ket{v}$.

Esso è:

$$
\bra{v} = \left(\begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_d \end{pmatrix}^* \ \right)^T = \begin{pmatrix} v_1^* & v_2^* & \cdots & v_d^* \end{pmatrix}
$$

#### 2.1.2 ⋅ Norma

La **norma** di un vettore $\ket{v}$ è definita come:

$$
||\ket{v}|| = \sqrt{\braket{v|v}}
$$

La norma è 0 se e solo se il vettore è il vettore nullo.

Se la norma di un vettore è 1, allora il vettore è detto **normalized**.

#### 2.1.3 ⋅ Qubit state space

Qubit è un two-level quantum system. Ovvero è qualcosa che sta in $\mathbb{C}^2$.

Possiamo scrivere un qubit come:

$$
\ket{\psi} = \alpha \ket{0} + \beta \ket{1}
$$

Dove $\alpha, \beta \in \mathbb{C}$ e $|\alpha|^2 + |\beta|^2 = 1$. Questa conservazione è importante per le probabilità.

Un esempio di base per $\mathbb{C}^2$ è:
- $\ket{0} = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$
- $\ket{1} = \begin{pmatrix} 0 \\ 1 \end{pmatrix}$

Di quanti parametri abbiamo bisogno per descrivere un qubit? Abbiamo bisogno di 4 parametri, ma sappiamo che la norma è 1, quindi abbiamo 3 parametri liberi. Inoltre, abbiamo che la fase globale non è osservabile, quindi abbiamo 2 parametri liberi.

Quindi ci bastano **2 parametri per descrivere un qubit**.

#### 2.1.4 ⋅ Continuo di spiegare come si descrive un qubit in base al postulato 1

Q. states sono dei vettori unitari in uno spazio di Hilbert.

Per esempio possiamo avere:
- Particelle con **spin 1/2**
- Atomo a due livelli (ground state e excited state)
- Polarizzazione della luce

Riguardo allo spin: particelle elemntari, come gli elettroni, i protoni, etc. hanno un momento angolare intrinseco chiamato **spin**. Lo spin genera un campo magnetico, quindi possiamo andare a misurare lo spin di una particella tramite un campo magnetico.

In unità di $\hbar$ (Plank's constant) diciamo che lo spin 1/2 di una particella può avere due possibili valori: $+\frac{\hbar}{2}$ e $-\frac{\hbar}{2}$. Si può appunto misurare usando un campo magnetico. Si chiamano a volte **up** e **down**.

Diremo che la **spin 1/2** è una 2-d quantum system con due stati di base: $\ket{\uparrow}$ e $\ket{\downarrow}$ o $\ket{+1/2}$ e $\ket{-1/2}$.

Un altro modo è usando appunto un atomo a due livelli, **ground** e **excited**. Se noi lo raffreddiamo abbastanza, allora riusciamo a non farli "accedere" a nessun altro stato. Andiamo a definire un qubit come:
- $\ket{0}$ come lo stato di **ground**, ovvero anche $\ket{g}$
- $\ket{1}$ come lo stato di **excited**, ovvero anche $\ket{e}$

Questi sono anche chiamati come **superconducting qubits**.

#### 2.1.5 ⋅ Altre cose di algebra

Ritorniamo un attimo al concetto di dual vectors.

$$
\ket{\psi} = \alpha \ket{0} + \beta \ket{1}
\\ \ \\
\bra{\psi} = \alpha^* \bra{0} + \beta^* \bra{1}
\\ \ \\
\braket{\psi|\psi} = |\alpha|^2 + |\beta|^2 = 1
$$

Quest'ultima cosa è **l'idempotenza**.

Notare che:
- $\braket{0|0} = 1$
- $\braket{1|1} = 1$
- $\braket{0|1} = 0$
- $\braket{1|0} = 0$
  - Questi sono **ortogonali** tra di loro, in quanto il loro inner product è 0.

Per normalizzare un vettore $\ket{\psi}$ e quindi portarlo al vettore unitario corrispondente $\ket{\tilde{\psi}}$ possiamo fare:

$$
\ket{\tilde{\psi}} = \frac{\ket{\psi}}{||\ket{\psi}||} = \frac{\ket{\psi}}{\sqrt{\braket{\psi|\psi}}}
$$

#### 2.1.6 ⋅ Bloch sphere representation

Dato un qubit del tipo:

$$
\ket{\psi} = \alpha \ket{0} + \beta \ket{1}
$$

Andiamo a definire l'$\alpha$ e la $\beta$ come:

$$
\alpha = |\alpha| e^{i \phi_\alpha}
\\ \ \\
\beta = |\beta| e^{i \phi_\beta}
\\ \ \\
\text{Con } \phi_\alpha, \phi_\beta \in [0, 2\pi]
$$

Inoltre, affinché la norma sia 1, abbiamo che:

$$
|\alpha|^2 + |\beta|^2 = 1
\\ \ \\
\implies \begin{cases} |\alpha| = \cos(\theta/2) \\ |\beta| = \sin(\theta/2) \end{cases}
$$

Quindi possiamo andare a riscrivere lo stato come:

$$
\ket{\psi} = \cos(\theta/2) e^{i \phi_\alpha} \ket{0} + \sin(\theta/2) e^{i \phi_\beta} \ket{1}
$$

Notiamo che quindi abbiamo 3 parametri:
- $\theta$
- $\phi_\alpha$
- $\phi_\beta$

Tuttavia, in realtà possiamo andare a riscrivere le cose raggruppando $\phi_\alpha$:

$$
\ket{\psi} = e^{\i\phi_\alpha} \left[ \cos(\theta/2) \ket{0} + e^{i(\phi_\beta - \phi_\alpha)} \sin(\theta/2)\ket{1} \right]
$$

E definiamo:
- $\phi = \phi_\beta - \phi_\alpha$
  - Questa si chiama **fase relativa** (tra $\ket{0}$ e $\ket{1}$)

A questo punto, facciamo notare che $e^{i\phi_\alpha}$ è una fase globale. Questa face non è osservabile, quindi possiamo ignorarla.

Pertanto possiamo riscrivere il tutto come:

$$
\ket{\psi} = \cos(\theta/2) \ket{0} + e^{i\phi} \sin(\theta/2) \ket{1}
$$

E quindi abbiamo **due** parametri:
- $\theta \in [0, \pi]$
  - "Quanto è vicino a $\ket{0}$ o a $\ket{1}$"
  - $\theta = 0$ corrisponde a $\ket{0}$
  - $\theta = \pi$ corrisponde a $\ket{1}$
  - Va solo fino a $\pi$ in quanto mi è inutile farlo andare oltre (fare tutto il giro). Se me lo immagino bene, posso andare ad esprimere qualcosa che va oltre a $\pi$ come un'altra cosa che sta in $[0, \pi]$ e cambia $\phi$ 
- $\phi \in [0, 2\pi]$
  - Fase relativa

Questo tipo di parametri sono chiamati **spherical coordinates**.

Quindis si possono mappare *uno ad uno** gli stati di un qubit alla superficie di una sfera unitaria in $\mathbb{R}^3$. Questa sfera è chiamata **Bloch sphere**.

Descriviamo le tre basi che più comunemente usiamo in termini della sfera di Bloch:
- $\ket{0}, \ket{1}$
  - $\ket{0} \implies \theta = 0, \phi \in [0, 2\pi]$
  - $\ket{1} \implies \theta = \pi, \phi \in [0, 2\pi]$
  - Questi sono i **north** e **south pole** della sfera di Bloch
- $\ket{+}, \ket{-}$
  - $\ket{+} \implies \theta = \frac{\pi}{2}, \phi = 0$
  - $\ket{-} \implies \theta = \frac{\pi}{2}, \phi = \pi$
- $\ket{i}, \ket{-i}$
  - $\ket{i} \implies \theta = \frac{\pi}{2}, \phi = \frac{\pi}{2}$
  - $\ket{-i} \implies \theta = \frac{\pi}{2}, \phi = \frac{3\pi}{2}$

Queste 3 basi stanno tutte su un "asse" della sfera di Bloch, il primo sta sull'asse delle $z$, il secondo sull'asse delle $x$ e il terzo sull'asse delle $y$.

Notiamo questo fatto interessante che tutte le basi di qubit si trovano su lati opposti della sfera di Bloch.

Con questa rappresentazione, possiamo notare che le trasformazioni sui qubit che possiamo fare corrispondono a delle rotazioni sulla sfera di Bloch:
- Per esempio la $X$ gate, che porta $\ket{0}$ a $\ket{1}$ corrisponde a una rotazione di $\pi$ lungo l'asse delle $x$.
- Per passare da $\ket{+}$ a $\ket{-}$ dobbiamo fare una rotazione di $\pi$ lungo l'asse delle $y$. Questo corrisponde alla $Y$ gate.
- Per invece passare da $\ket{i}$ a $\ket{-i}$ dobbiamo fare una rotazione di $\pi$ lungo l'asse delle $z$. Questo corrisponde alla $Z$ gate.

In generale, possiamo dire che una trasformazione su un qubit corrisponde a una rotazione sulla sfera di Bloch.

I punti **all'interno della sfera** rappresentano quelli che sono chiamati **mixed states**: sono stati che vengono dalla mescolazione di stati "puri", ovvero degli stati che si trovano sulla superficie della sfera.

### 2.2 ⋅ Postulato 2 / 3 - Osservabili / operatori e evoluzione nel tempo

Classicamente unos tato è descritto da $(\vec{x}, \vec{p})$, rispettivamente posizione e momento. 

Un osservabile $f(\vec{x},\vec{p})$, per esempio il momento angolare, l'energia, etc., è una funzione delle coordinate e dei momenti. 

> Il secondo posulato ci dice che gli **osservabili** in MQ sono degli operatori Hermitiani su uno spazio di Hilbert.

Cosa è un **operatore Hermitiano**? Essenzialmente delle matrici. Definiamo le proprietà che hanno in modo rigoroso:
- Sia $M$ un operatore su uno spazio di Hilbert $\mathbb{H}$
- $M$ è Hermitiano se e solo se $M = M^\dagger$

Abbiamo già visto alcune matrici di questo tipo, per esempio la $X$ gate.

In generale le Pauli matrices sono Hermitiane.

Notare che se noi abbiamo:

$$
\hbar/2 \cdot X = \sigma_X (\text{Pauli spin matrix})
\\ \ \\
\hbar = \frac{h}{2\pi}
$$

Allora questo è un operatore Hermitiano che rappresenta la dimensione fisica del momento angolare.

Cosa importante:
- Hermitian matrices hanno **real eigenvalues**
- I valori che una quantità fisica può avere $\equiv$ gli autovalori del corrispondente operatore Hermitiano
- Per esempio $\{\ket{0}, \ket{1}\}$ sono gli autovettori di $\sigma_z$ e $\hbar/2$ e $-\hbar/2$ sono gli autovalori

Come lo chiamiamo l'operatore che rappresenta una quantità fisica? Lo chiamiamo **osservabile**.


Altre cose notevoli:
- $(AB)^\dagger$ = $B^\dagger A^\dagger$
  - Quindi $(M \ket{\psi})^\dagger = \bra{\psi} M^\dagger = \bra{\psi} M$
- Siano gli autovalori di un operatore Hermitiano $M$ $\lambda_1, \lambda_2, ...$ e gli autovettori $\ket{v_1}, \ket{v_2}, ...$
  - Allora $\braket{v_i|v_j} = \delta_{ij}$
  - Gli autovettori di un operatore Hermitiano sono **ortonormali**
  - $\braket{v_i|M|v_j} = \lambda_j \braket{v_i|v_j} = \lambda_j \delta_{ij} = \lambda_i \delta_{ij}$
  - $\lambda^* = \lambda$ per un operatore Hermitiano
  - Da tenere in mente che $\braket{e|e} = \sum_i |a_i|^2 \geq 0$

#### 2.2.1 ⋅ Scrivere le cose usando le matrici

Per andare a creare una correlazione tra *observable* e *matrici*.

In pratica noi abbiamo:

$$
M \ket{\psi} = \ket{\phi}
$$

Dove:
- $M$ è un operatore (generico, ancora non lo stiamo definendo come Hermitiano)
- $\ket{\psi}, \ket{\phi}$ sono stati / vettori.

Diciamo che ci sia una base $\{\ket{b_i}\}_{i=1,...,d}$ in cui possiamo esprimere $\ket{\psi}$ e $\ket{\phi}$ come:

$$
\ket{\psi} = \sum_{i=1}^{d} c_i \ket{b_i}
\\ \ \\
\ket{\phi} = \sum_{i=1}^{d} s_i \ket{b_i}
$$

Allora abbiamo che:

$$
M \sum_i c_i \ket{b_i} = \sum_i s_i \ket{b_i}
$$

E anche i seguenti risultati:

$$
\sum_i c_i \braket{b_j|M|b_i} = s_j
\\ \ \\
M \ket{b_i} = \ket{\chi} = \sum_j c_j^{(i)}\ket{b_j}
\\ \ \\
\braket{b_j|M|b_i} = c_j^{(i)}
$$

Usando tutti questi fatti possiamo andare a costruire la rappresentazione matriciale di $M$ usando la base $\{\ket{b_i}\}$, dove per ogni indice $(i,j)$ del matrice esso è definito da $\braket{b_j|M|b_i}$.

Andiamo a fare un esempio di questa cosa, usando $\sigma_x$ e $\ket{0}, \ket{1}$ come base.

$$
\sigma_x \ket{0} = \ket{1}
\\ \ \\
\sigma_x \ket{1} = \ket{0}
\\ \ \\ \ \\
\braket{0|\sigma_x|0} = 0
\\ \ \\
\braket{1|\sigma_x|0} = 1
\\ \ \\
\braket{0|\sigma_x|1} = 1
\\ \ \\
\braket{1|\sigma_x|1} = 0
$$

Quindi otteniamo che la matrice di $\sigma_x$ è, nella base $\{\ket{0}, \ket{1}\}$:

$$
\sigma_x = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}
$$

Invece se la vogliamo rappresentare nella base $\{\ket{+}, \ket{-}\}$, allora dobbiamo fare una sequenza di calcoli.

Da notare che la matrice di un operatore Hermitiano è **sempre** diagonale nelle sue **eigenbasis** (base fatta dai suoi autovettori).

### 2.2.2 ⋅ Outer product

Abbiamo definito fin'ora l'inner product: $\braket{v|w}$. Andiamo a definire l'**outer product**:

$$
\ket{v}\bra{w} = \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_d \end{pmatrix} \begin{pmatrix} w_1^* & w_2^* & \cdots & w_d^* \end{pmatrix}
$$

Questo ci genera una matrice.

Un esempio potrebbe essere:

$$
\ket{0}\bra{0} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} \begin{pmatrix} 1 & 0 \end{pmatrix} = \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix}
$$

Questo è chiamato un **projection operator**.

Notiamo che se noi lo applichiamo a un vettore, otteniamo la seguente sequenza di eventi:

$$
(\ket{0}\bra{0})\ket{\psi} = \ket{0}(\braket{0|\psi}) = \braket{0|\psi}\ket{0} = \alpha \ket{0}
$$

Quindi è una **proiezione** del vettore $\ket{\psi}$ sullo spazio generato da $\ket{0}$.

Andiamo a costruire anche le altre combinazioni possibili:

$$
\ket{0}\bra{1} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} \begin{pmatrix} 0 & 1 \end{pmatrix} = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}
\\ \ \\
\ket{1}\bra{0} = \begin{pmatrix} 0 \\ 1 \end{pmatrix} \begin{pmatrix} 1 & 0 \end{pmatrix} = \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix}
\\ \ \\
\ket{1}\bra{1} = \begin{pmatrix} 0 \\ 1 \end{pmatrix} \begin{pmatrix} 0 & 1 \end{pmatrix} = \begin{pmatrix} 0 & 0 \\ 0 & 1 \end{pmatrix}
$$

Adesso andiamo a notare alcune cose:
- $\ket{0}\bra{0} + \ket{1}\bra{1} = I$
  - Deriva dalla **completeness relation**
  - Sia $\{\ket{b_i}\}$ una base, allora $\sum_i \ket{b_i}\bra{b_i} = I$
- $\ket{0}\bra{0} - \ket{1}\bra{1} = \sigma_z$
- $\ket{0}\bra{1} + \ket{1}\bra{0} = \sigma_x$

Come lo ricolleghiamo agli operatori Hermitiani? Gli operatori Hermitiani sono combinazioni lineari di outer products:
- Sia dato $M$ con eigenvalues $\lambda_i$ e autovettori $\ket{e_i}$
- Allora abbiamo: $M = \sum_i \lambda_i \ket{e_i}\bra{e_i}$

Quindi lo si può scrivere come:

$$
M = \begin{pmatrix} \lambda_1 & 0 & \cdots & 0 \\ 0 & \lambda_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & \lambda_d \end{pmatrix}
$$

Questa è chiamata la **spectral decomposition** di $M$.

Tutti gli operatori Hermitiani sono combinazioni lineari di outer products. Questo è un fatto molto importante.

#### 2.2.3 ⋅ Evoluzione temporale - postulato 3 QM

> L'evoluzione temporale di uno stato quantistico è descritta da un operatore unitario.
>
> $\ket{\psi(t)} = U(t)\ket{\psi(t=0)}$

Da notare che: $U$ è **unitario** se e solo se $U^\dagger U = UU^\dagger = I$.

Una cosa che questo implica è che un opratore unitario è **reversibile**: $U^{-1} = U^\dagger$.

Possiamo anche scrivere l'evoluzione nel tempo usando l'equazione di Schrödinger:

$$
i\hbar \frac{d}{dt}\ket{\psi(t)} = H\ket{\psi(t)}
$$

Dove $H$ non è la Hadamard gate, ma è l'**Hamiltonian operator**. Questo è un operatore Hermitiano che rappresenta l'energia del sistema.

Sia $H$ indipendente dal tempo, allora abbiamo la soluzione:

$$
\ket{\psi(t)} = e^{-iHt/\hbar}\ket{\psi(0)}
$$

Da notare che $e^{-iHt/\hbar}$ rimane un operatore hermitiano, lo si può dimostrare facendo l'espansione della serie di Taylor.

**Unitary transformations** preservano la norma. Questo è importante in quanto **preservano la probabilità** di un sistema.

#### 2.2.4 ⋅ Sunto della scorsa lezione che sembra un bel riassunto

Andiamo a ripeterci un attimo cosa sono Hermitian operators, unitary operators, etc:
- **Hermitian**
  - $M = M^\dagger$
  - Gli autovalori sono reali
  - Quindi sono gli **osservabili**
- **Unitary**
  - $UU^\dagger = U^\dagger U = I$
  - Sono le **trasformazioni temporali**
  - Preservano la norma
  - Sono le **quantum gates**
- C'è una cosa in come a queste due classi, e si chiamano **normal operators**
  - $[N, N^\dagger] = 0 = NN^\dagger - N^\dagger N$
  - Gli operatori Hermitiani e Unitari sono normali
  - Questa è la classe di operatori che sono **diagonalizzabili** e che hanno una base di autovettori ortonormali (e si può applicare il teorema spettrale)
- Alcuni operatori sono sia Hermitiani che Unitari
  - Un esempio è la $H$ gate
- Una **sottoclasse** dei Hermitian sono i **positive operators**
  - Hanno tutti autovalori positivi
- **Projection operator**
  - Sono quelli operatori che sono Hermitiani e che sono **idempotent**
  - $\Pi^2 = \Pi$
  - Alcuni esempi sono $\ket{0}\bra{0}$, $\ket{1}\bra{1}$, etc.
  - Il rank di un operatore è il numero di autovalori dell'operatore che sono diversi da 0
  - Il rank di un projection operator è 1
  - Questi sono una sotto-classe dei positive operators
  - L'unico projection operator che ha rank 2 è $I$
  - Si dice che un set $\{\Pi_i\}$ è una **complete set of projectors** se $\sum_i \Pi_i = I$
  - Si dice che un set $\{\Pi_i\}$ è una **orthogonal set of projectors** se $\Pi_i\Pi_j = 0$ per $i \neq j$, o anche $\Pi_i\Pi_j = \delta_{ij}\Pi_i$
  - Qualsiasi base ortogonale è una complete set of projectors e in particolare $\{\ket{b_i}\bra{b_i}\}$ è un proiettore
  - Possiamo costruire un proiettore usando un qualsiasi stato $\ket{\psi}$ come $\ket{\psi}\bra{\psi}$ e otteniamo qualcosa che è idempotente e che proietta su $\ket{\psi}$

### 2.3 ⋅ Postulato 4 - Misura

> When observable $A$ is measured on state $\ket{\psi}$, the set of outcomes (the possible values the measurment can take) is the set of eigenvalues of $A$.
>
>  The probability of obtaining outcome $\alpha_i$ is given by:
>
> $$
> p(\alpha_i) = |\braket{\psi|\alpha_i}|^2
> $$
>
> (eigenstate associated with $\alpha_i$)
>
> The second part, the "Born rule", is the following:
> - The state of the system after measurment **collapses** to one of the eigenstates of $A$ associated with $\alpha_i$

Andiamo ora a vedere un esempio dove contestualizziamo cosa stiamo descrivendo.

Immaginiamo di avere il seguente circuito:

``` 
          ┌───────────┐─|a_1>
r1  |ψ>─○─│ A measure │─|...>
          └───────────┘─|a_i>
```

Ci sono tutti i possibili outcome $a_i$ che possono essere ottenuti dalla misura di $A$. La probabilità di ottenere un certo outcome è data da $|\braket{\psi|a_i}|^2$.

Spieghiamo il **collapse**: ricordiamoci che $\{\ket{\alpha_i}\}$ formano una base ortonormale per il system space. Andiamo ad espandere $\ket{\psi}$ come una combinazione lineare di questi autovettori:

$$
\ket{\psi} = \sum_i c_i \ket{\alpha_i}
$$

Dopo la misura con l'apparato di misura lo stato non è più in una superposizione, ma "collassa" appunto in uno degli stati di $\{\ket{\alpha_i}\}$.

La **probabilità** è quindi 

$$
p(\alpha_i) = |\braket{\psi|\alpha_i}|^2 
\\ \ \\
= (\braket{\psi|\alpha_i}) (\braket{\alpha_i|\psi})^*
\\ \ \\
= \braket{\psi|\alpha_i}\braket{\alpha_i|\psi}
\\ \ \\
(\text{Da notare che quindi } = |\braket{\alpha_i|\psi}|^2 )
\\ \ \\
= \sum_j c_j^* \braket{\alpha_j|\alpha_i} \sum_k c_k \braket{\alpha_i|\alpha_k}
\\ \ \\
= |c_i|^2
$$

Quindi $c_i$ è proprio la **probability amplitude**, che squadrato ci da la **proprietà**.

#### 2.3.1 ⋅ Projective measurments

Per adesso abbiamo discusso i projective measurments, ovvero usiamo un set di proiettori $\{\Pi_i\}$ che sono una complete set of projectors. Questi proiettori sono tali che $\Pi_i\Pi_j = \delta_{ij}\Pi_i$.



---

```
Cose utili per circuiti:
          ┌────┐ 
r1  |x>─○─│    │─|x>
          │ Uf │ 
r1  |y>─○─│    │─|y ⊕ f(x)>
          └────┘
```