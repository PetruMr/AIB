# 1. Introduction

## 1.1 Parte generica (numeri complessi, quando usare la MQ, etc.)

### 1.1.1 Quando usare la MQ?

In particoalre si applica a situazioni dove le cose che si analizza sono dell'ordine di grandezza di $\hbar$, ovvero $\hbar \approx 10^{-34} \, \text{Js} (1.054 \times 10^{-34} \ kg \ m^2/s)$.

Per esempio quando:
- Il momento angolare $L \sim \hbar$.
- Quando l'incertezza $\Delta x \Delta p \sim \hbar$.
- Quando l'incertezza $\Delta E \Delta t \sim \hbar$.
- Quando l'azione $S = \int L \, dt \sim \hbar$.
  - Questo è un concetto che poi non rivedremo tanto

Alcuni esempi che sono fatti sono:
- Un elettrone in un atomo di idrogeno
  - Che ha $\Delta p \Delta x \sim \hbar$.
- Un granello di polvere in aria
  - Che è di tanti ordini di grandezza più grande di $\hbar$.
  - Quindi in questo caso non si può usare.

### 1.1.2 Key concepts in quantum mechanics

La **funzione d'onda**, una funzione che dipende dalla *posizione* e dal *tempo*. Si tratta di una funzione complessa, e la sua interpretazione è che il modulo quadro di questa funzione d'onda è la probabilità di trovare una particella in una certa posizione.

Gli **operatori** agiscono su $\psi$, di solito si scrivono con $\hat x$ per esempio. Gli operatori si scrivono, quando operano su $\psi$, come $\hat x = x \psi$.

### 1.1.3 L'equazione di Schrodinger

L'EQ di S. è:

$$
i \hbar \frac{\partial \psi}{\partial t} = \hat H \psi
\\ \ \\
= (\hat{KE} + \hat{V}) \psi
\\ \ \\
= - \frac{\hbar^2}{2m} \frac{\partial^2 \psi}{\partial x^2} + V(x) \psi
$$

Dove $\hat{KE}$ è l'operatore dell'energia cinetica, $\hat{V}$ è l'operatore dell'energia potenziale, e $\hat H$ è l'operatore dell'energia totale (**Hamiltonian, "energy operator"**)

## 1.2 Probabilità

Immaginiamo di misurare una palla in un punto nello spazio. Queste misure non saranno mai completamente identiche anche nel mondo classico, sia per imprecisione nella misura che nell'impostare di nuovo lo stato classico del quale eseguiamo misure.

Quello che otteniamo, quindi, è una **distribuzione di probabilità** che ci mostra dove è più probabile, appunto, trovare la palla.

Questo concetto è intimamente collegato alla MQ e alla funzione d'onda.

La funzione d'onda, $\psi(x)$, è una funzione complessa che ci dice dove è più probabile trovare una particella. Il modulo quadro di questa funzione d'onda, $|\psi(x)|^2 = P(x)$, è la probabilità di trovare la particella in una certa posizione.

La probabilità di trovare una particella in un determinato posto (non ci interessa il posto x specifico, in quanto la probabilità è sicuramente pressoché 0: immagina di cercare una persona nata esattamente in un momento x, è sicuramente 0, ma se "allarghi" la ricerca, la probabilità diventa realistica e utile) è data da:

$$
p(\text{trovare la particella tra } a \text{ e } b) = \int_{a}{b}|\psi(x)|^2 dx
$$

### 1.2.1 Distribuzioni di probabilità e le loro proprietà

Ci sono due probabilità principali:
- **Probabilità discreta**
- **Probabilità continua**

#### 1.2.1.1 Probabilità discreta 

Immaginiamo di avere i dati $[0,0,1,1,1,2,2,3,4,5]$, ovvero 2 persone hanno risposto 0, 3 persone hanno risposto 1, 2 persone hanno risposto 2, 1 persona ha risposto 3, 1 persona ha risposto 4, e 1 persona ha risposto 5.

Quindi a partire da questo possiamo calcoalre la probabilità di 1 per esempio, ovvero $P(1) = \frac{2}{10}$.

La probabilità totale è 1, ovvero $\sum_{i} P(i) = 1$.

#### 1.2.1.2 Probabilità continua

Immaginiamo ora di chiedere ad un numero di persone quanto tempo sono rimaste in attesa in una chiamata. Le risposte potrebbero essere del tipo: $[0.072, 0.117, 0.232, 0.549, 0.799, 1.099, 1.740, 1.836, 1.888, 2.161]$. Assumono quindi un insieme di valori continui, che non possono essere trattati come i valori discreti.

Pertanto a questo punto noi possiamo: assumere siano discreti OPPURE cercare una distribuzione di probabilità che li riesca a rappresentare.

Questa funzione è $\rho(x)$, chiamata la **densità di probabilità**. Questa funzione è tale che:

$$
\int_{-\infty}^{\infty} \rho(x) dx = 1
$$

Da notare che data questa distribuzione abbiamo che $P(x=1)=0$, per esempio. Quindi il modo di effettivamente calcolare le probabilità è:

$$
P(a \leq x \leq b) = \int_{a}^{b} \rho(x) dx
$$

### 1.2.2 Proprietà

**Moda**, ovvero l'elemento più probabile:
- Per una distribuzione discreta è l'elemento con la probabilità più alta
  - Nell'esempio di prima è 1
- Per una distribuzione continua è il punto in cui la densità di probabilità è massima
  - Però qual'è la probabilità di ottenere proprio un certo valore? $0$. Ricordiamo che ogni punto singolo ha probabilità 0.

**Mediana**, ovvero il valore che divide la distribuzione in due parti uguali:
- Per una distribuzione discreta è il valore che divide la distribuzione in due parti uguali
- Per una distribuzione continua è il valore tale che la probabilità di ottenere un valore minore è uguale alla probabilità di ottenere un valore maggiore
  - Quindi la mediana è il valore tale che $\int_{-\infty}^{x_{\text{med}}} \rho(x) dx = \int_{x_{\text{med}}}^{\infty} \rho(x) dx$
  - O anche, deve fare 0.5: $\int_{-\infty}^{x_{\text{med}}} \rho(x) dx = 0.5$

**Media**, ovvero il valore medio:
- Per una distribuzione discreta è la somma dei valori moltiplicati per la probabilità di ottenere quel valore
  - Ovvero si scrive come $M = \sum_{i} P(x = x_i) x_i$
- Per una distribuzione continua è l'integrale dei valori moltiplicati per la densità di probabilità
  - Ovvero si scrive come $M = \int_{-\infty}^{\infty} \rho(x) x \ dx$

**Valore atteso** (expected value) di una funzione $f(x)$:
- Per una distribuzione discreta è la media con una funzione applicata ai valori 
  - Si scrive come $\braket{f} = \sum_{i} P(x = x_i) f(x_i)$
- Per una distribuzione continua è l'integrale con una funzione applicata ai valori
  - Si scrive come $\braket{f} = \int_{-\infty}^{\infty} \rho(x) f(x) \ dx$

### 1.2.3 Tipi di distribuzioni

Possiamo avere diversi tipi di distribuzioni:
- Alcune **simmetriche** (come la gaussiana)
  - Che possono essere più "strette" o più larghe"
- Altre che possono essere asimmetriche, come la distribuzione esponenziale
- Altre che sono simmetriche ma non hanno un solo picco, per esempio la **bimodal**.

### 1.2.4 Varianza

La varianza è un modo di misurare la "*broadness*" della distribuzione.

Immaginiamo di voler trovare come valore atteso quello di $\Delta x = x - \braket{x}$.

Se noi facciamo:
- $\braket{\Delta x} = 0$
  - Quindi non ci è utile (a sinistra sono negativi, a destra sono positivi e si cancellano poi a vicenda)
- $\braket{|\Delta x|}$
  - Questo è ragionevole, però diventa "doloroso" andare a fare tutti i calcoli visto che abbiamo dei valori assoluti quindi usiamo un altro modo ancora

Il modo per misurare la varianza è:

$$
\sigma^2 = \braket{(\Delta x)^2} = \braket{x^2} - \braket{x}^2
$$

## 1.3 Normalizzazione della funzione d'onda

Abbiamo detto che nelle distribuzioni di probabilità la somma delle probabilità è 1. Questo è vero anche per la funzione d'onda, ovvero:

$$
\int_{-\infty}^{\infty} |\psi(x)|^2 dx = 1
$$

Possiamo notare che per esempio alcune funzioni non sono normalizzabili, come ad esempio $\psi(x) = x^3$. Notiamo che questa qua non è normalizzabile, in quanto:

$$
\int_{-\infty}^{\infty} |x^3|^2 dx = \int_{-\infty}^{\infty} x^6 dx = \infty
$$

In particolare noi andiamo a mettere una richiesta: **$\psi$ deve essere quadrato sommabile**, ovvero:

$$
\int_{-\infty}^{\infty} |\psi(x)|^2 dx \text{ is finite}
$$

Inoltre mettiamo una proprietà che ne consegue ed è più "facile", ovvero che:

$$
\psi \to 0 \text{ as } |x| \to \infty
$$

Riscriviamo un attimo l'equazione di Schrodinger:

$$
i \hbar \frac{\partial \psi}{\partial t} = - \frac{\hbar^2}{2m} \frac{\partial^2 \psi}{\partial x^2} + V(x) \psi
$$

Notiamo che quindi, se $\psi$ risolve l'equazione di Schrodinger, allora anche $A \psi$ risolve l'equazione di Schrodinger, con $A$ una *costante complessa*, in quanto noi la potremmo dividere da entrambi i lati.

Da notare che con il fatto che $A$ è una costante, potremmo pensare di incorrere in problemi nell'evoluzione temporale *E INVECE* non ci sono sti problemi: nell'evoluzione temporale, la normalizzazione viene mantenuta.

### 1.3.1 Evoluzione nel tempo della funzione d'onda

$$
\frac{d}{dt} \int_{-\infty}^{\infty} |\psi(x,t)|^2 dx =?=  \int_{-\infty}^{\infty} \frac{\partial}{\partial t} |\psi(x,t)|^2 dx
\\ \ \\
= \int_{-\infty}^{\infty} \frac{\partial}{\partial t} \psi^* \psi dx
\\ \ \\
= \int_{-\infty}^{\infty} \left( \frac{\partial \psi^*}{\partial t} \psi + \psi^* \frac{\partial \psi}{\partial t} \right) dx
$$

A questo punto possiamo usare l'equazione di Schrodinger:

$$
= \int_{-\infty}^{\infty} \left( \frac{i \hbar}{2m} \frac{\partial^2 \psi^*}{\partial x^2} \psi + \frac{i \hbar}{2m} \psi^* \frac{\partial^2 \psi}{\partial x^2} \right) dx
\\ \ \\
= \frac{i \hbar}{2m} \int_{-\infty}^{\infty} \left( \frac{\partial^2 \psi^*}{\partial x^2} \psi - \psi^* \frac{\partial^2 \psi}{\partial x^2} \right) dx
\\ \ \\
= \frac{i \hbar}{2m} \left[\psi^* \frac{\partial\psi}{\partial x} - \frac{\partial \psi^*}{\partial x} \psi \right] _{-\infty}^{\infty}
$$

Ma abbiamo che se $\psi$ è normalizzabile, allora $\psi \to 0$ per $|x| \to \infty$, quindi il termine si annulla (si può dimostrare che $\psi$ tende a 0 più veloce di quanto $\frac{\partial \psi}{\partial x}$ possa tendere a infinito).

Quindi il risultato è:

$$
\frac{d}{dt} \int_{-\infty}^{\infty} |\psi(x,t)|^2 dx = 0
\\ \ \\
\implies \int_{-\infty}^{\infty} |\psi(x,t)|^2 dx = \text{const}
$$

Pertanto, l'evoluzione temporale della funzione d'onda mantiene la normalizzazione.

### 1.3.2 Esempio

Consideriamo la funzione:

$$
\psi (x) = \begin{cases} 0 & \text{se } |x| > 1 \\ A e^{i x} (1-x^2) & \text{altrimenti} \end{cases}
$$

Quindi:

$$
\int_{-\infty}^{\infty} |\psi(x)|^2 dx
\\ \ \\
= \int_{-1}^{1} A \ e^{i x} (1-x^2) A \ e^{-i x} (1-x^2) dx
\\ \ \\
= A^2 \int_{-1}^{1} (1-x^2)^2 dx
\\ \ \\
= A^2 \int_{-1}^{1} (1-2x^2 + x^4) dx
\\ \ \\
= A^2 \left[ x - \frac{2}{3} x^3 + \frac{1}{5} x^5 \right]_{-1}^{1}
\\ \ \\
= A^2 \left[ 1 - \frac{2}{3} + \frac{1}{5} - (-1 + \frac{2}{3} - \frac{1}{5}) \right]
\\ \ \\
= A^2 \left[ 1 - \frac{2}{3} + \frac{1}{5} + 1 - \frac{2}{3} + \frac{1}{5} \right]
\\ \ \\
= A^2 \left[ 2 - \frac{4}{3} + \frac{2}{5} \right]
\\ \ \\
= A^2 \left[ \frac{30 - 20 + 6}{15} \right]
\\ \ \\
= A^2 \left[ \frac{16}{15} \right]
$$

Quindi:

$$
\int_{-\infty}^{\infty} |\psi(x)|^2 dx = 1
\\ \ \\
\implies A = \sqrt{\frac{15}{16}}
$$

## 1.4 Operatori

### 1.4.1 Misura di "movimento" di una particella

Noi abbiamo in precendeza definito la posizione di una particella come una probabilità rispetto alla sua funzione d'onda.

Se noi immaginiamo di voler capire come la particella si muove, non ci basta misurarla in momenti diversi, dobbiamo preparare un **ensamble** di sistemi preparati in modo identico e che misuriamo una volta per ogni sistema, ma in generale tante volte e in tanti momenti diversi. Questo ci andrà a permettere di rappresentare l'evoluzione temporale della particella a livello odi funzione d'onda (quindi con una distribuzione di probabilità).

Possiamo andare a prevedere questa evoluzione? Andiamo a condsiderare $\frac{d}{dt} \braket{x}$:

$$
\frac{d}{dt} \braket{x} = \frac{d}{dt} \int_{-\infty}^{\infty} x |\psi(x,t)|^2 dx
\\ \ \\
= \int_{-\infty}^{\infty} x \frac{\partial}{\partial t} |\psi(x,t)|^2 dx
\\ \ \\
= \frac{i\hbar}{2m} \int_{-\infty}^{\infty} x \left( \frac{\partial \psi^*}{\partial t} \psi + \psi^* \frac{\partial \psi}{\partial t} \right) dx
$$

A questo punto facciamo l'integrazione per parti, andando a considerare:

$$
u = x \quad \quad dv = \frac{\partial}{\partial x} (\psi^* \frac{\partial \psi}{\partial t} - \psi \frac{\partial \psi^*}{\partial t}) dx
\\ \ \\
du = dx \quad \quad v = \psi^* \frac{\partial \psi}{\partial t} - \psi \frac{\partial \psi^*}{\partial t}
$$

E quindi otteniamo:

$$
\int_{-\infty}^{\infty} x \frac{\partial}{\partial t} |\psi(x,t)|^2 dx = \frac{i\hbar}{2m} \left[ x \left( \psi^* \frac{\partial \psi}{\partial t} - \psi \frac{\partial \psi^*}{\partial t} \right) \right]_{-\infty}^{\infty} - \frac{i\hbar}{2m} \int_{-\infty}^{\infty} \left( \psi^* \frac{\partial \psi}{\partial t} - \psi \frac{\partial \psi^*}{\partial t} \right) dx
\\ \ \\
= \frac{i\hbar}{2m} \int_{-\infty}^{\infty} \left( \psi^* \frac{\partial \psi}{\partial t} - \psi \frac{\partial \psi^*}{\partial t} \right) dx
\\ \ \\
\text{separiamo}
\\ \ \\
= \frac{i\hbar}{2m} \int_{-\infty}^{\infty} \psi^* \frac{\partial \psi}{\partial t} dx + \frac{i\hbar}{2m} \int_{-\infty}^{\infty} \psi \frac{\partial \psi^*}{\partial t} dx
$$

Anche qua facciamo integrare per parti:

$$
u = \psi \quad \quad dv = \frac{\partial \psi^*}{\partial t} dx
\\ \ \\
du = \frac{\partial \psi}{\partial x} \quad \quad v = \psi^*
$$

E notiamo che la parte che viene fuori è 0, mentre quella da integrare è identica all'altro elemento, quindi otteniamo:

$$
= \frac{i\hbar}{m} \int_{-\infty}^{\infty} \psi^* \frac{\partial \psi}{\partial t} dx = \braket{\hat{v}}
$$

Quello che ci dà è la una distribuzione di probabilità della velocità in un senso quantistico.

### 1.4.2 Altri operatori

Vediamo come sono quindi accomunati un po tutti gli operatori dal modo di trascriverli.

$$
\braket{v} = - \frac{i\hbar}{m} \int_{-\infty}^{\infty} \psi^* \frac{\partial \psi}{\partial x} dx
\\ \ \\
\braket{p} = - i \hbar \int_{-\infty}^{\infty} \psi^* \frac{\partial \psi}{\partial x} dx
\\ \ \\
\braket{x} = \int_{-\infty}^{\infty} \psi^* (x) \psi dx
$$

Quindi in generale sono del tipo:

$$
\hat{y} = y [...]
$$

Quindi abbiamo:

$$
\hat{x} = x \cdot [...]
\\ \ \\
\hat{v} = - \frac{i\hbar}{m} \frac{\partial}{\partial x} [...]
\\ \ \\
\hat{p} = - i \hbar \frac{\partial}{\partial x} [...]
\\ \ \\
\hat{T} = - \frac{\hbar^2}{2m} \frac{\partial^2}{\partial x^2} [...]
$$

Gli operatori scritti sono:
- La posizione
- La velocità
- Il momentum
- Il momento squadrato

Questo quindi ci permette di esprimere il valore previsto per qualsiasi quantità fisica. Ci basta trovare gli operatori di quella quantità e poi fare il prodotto scalare con la funzione d'onda.

### 1.4.3 Esempio

Trovare $\braket{\hat{p}}$ della funzione d'onda:

$$
\psi(x) = \begin{cases} 0 & \text{se } |x| > 1 \\ A(1-x^2) & \text{altrimenti} \end{cases}
$$

Quindi ciò che calcoliamo è:

$$
\braket{\hat{p}} = \int_{-\infty}^{+\infty} \psi^* \left( - i \hbar \frac{\partial}{\partial x} \right) \psi \ dx
\\ \ \\
= \int_{-1}^{1} A^2 (1-x^2) \left( - i \hbar \frac{\partial}{\partial x} \right) (1-x^2) \ dx
\\ \ \\
= - i \hbar A^2 \int_{-1}^{1} (1-x^2) \frac{\partial}{\partial x} (1-x^2) \ dx
\\ \ \\
= i \hbar A^2 \int_{-1}^{1} (1-x^2) 2x \ dx
\\ \ \\
= 2 i \hbar A^2 \int_{-1}^{1} x - x^3 \ dx
\\ \ \\
= 0
$$

In quanto la funzione da integrare è dispari, quindi l'integrale è 0.

## 1.5 Principio di indeterminazione di Heisenberg

Questo è un principio molto importante che è built in nella MQ.

Una prima intuitiva dimostrazione della scomodità di misusare la posizione e la wavelength di un onda:
- Se noi abbiamo immaginiamo un onda che si ripete tante volte ed ha tanti picchi, allora abbiamo appunto molti picchi che ci possono dare una risposta piuttosto accurata sulla lunghezza d'onda dell'onda
- Se invece abbiamo 1 unico picco, allora non ci è possibile dire molto sulla lunghezza d'onda dell'onda

D'altro canto:
- Se noi abbiamo tanti picchi, abbiamo difficoltà a determinare dove esattamente si trova l'onda
- Se invece abbiamo un solo picco, allora possiamo dire con molta precisione dove si trova l'onda

In particolare, da **fourier analysis**, ci esce l'equazione: $\Delta \lambda \Delta x \geq 1$.

Come è stato associato alla materia un onda? Dobbiamo parlare di **Debroglie**.

In particolare, c'erano già le seguenti equazioni:
- $E = mc^2$
- $E = h F$
- c = $\lambda F$

Quindi $\implies F = c/\lambda$.

Quindi:

$$
m c^2 = h \frac{c}{\lambda}
\\ \ \\
m c = \frac{h}{\lambda}
\\ \ \\
p = \frac{h}{\lambda}
$$

Mentre le equazioni precedenti avevano un utilizzo specifico, il primo per la relatività e il secondo per la quantizzazione dell'energia, la terza è applicabile alla materia.

Unendo quindi le due equazioni, otteniamo:

$$
p = \frac{h}{\lambda} \quad \quad \text{e} \quad \quad \Delta \lambda \Delta x \geq 1
\\ \ \\
\Delta p \Delta x \geq \hbar/2
$$

Andiamo anche un po ad analizzare semanticamente cosa possono significare queste cose:
- $\Delta p \sim$ lunghezza d'onda, la frequenza dell'onda nello spazio
- $\Delta x \sim$ posizione
- Qua stiamo parlando della *frequency* dell'onda nello spazio

Mentre per l'energia abbiamo:
- $\Delta E \sim$ tempo, la frequenza dell'onda nel tempo
- $\Delta t \sim$ tempo
- Qua stiamo parlando della *frequency* dell'onda nel tempo (quanto velocemente oscilla)

## 1.6 Key concepts of QM, revisited

Gli operatori chiave che abbiamo trattato per ora sono:
- Opetatori, vengono usati nell'equazione di Schrodinger e agiscono sulla funzione d'onda $\psi$.
- Gli operatori e la funzione d'onda collaborano per darci degli osservabili
- L'equazione di S. è una soluzione della funzione d'onda.

# 2. Equazione di Schrodinger

## 2.1 Separazione di variabili

### 2.1.1 ODE e PDE

Andiamo a definire **Ordinary Differential Equation (ODE)** e **Partial Differential Equation (PDE)**.

Un'ODE è un'equazione differenziale in cui le funzioni dipendono da una sola variabile indipendente.
- Per esempio $x(t)$, che dipende quindi solo dal tempo, $y(t)$ che dipende solo dal tempo, etc.

Una PDE è un'equazione differenziale in cui le funzioni dipendono da più di una variabile indipendente.
- Per esempio $\vec{E} (x,y,z)$, quindi dipende da 3 variabili indipendenti, $\psi(x,t)$, quindi dipende da 2 variabili indipendenti, etc.

### 2.1.2 Separazione di variabili

Si tratta essenzialmente di "indovinare".

Supponiamo di voler trovare una funzione (nel caso dell'elettromagnetismo è il potenziale $V(x,y,z)$) e supponiamo che si possa scrivere come:

$$
V(x,y,z) = X(x) Y(y) Z(z)
$$

Quindi riusciamo a separare le variabili in 3 funzioni diverse.

Questa soluzione funziona? In questo caso sì, ci sono tanti casi nei quali questa soluzione naive funziona, ma non in tutti.


### 2.1.3 Wave equation

Andiamo a trascrivere l'equazione d'onda:

$$
\frac{\partial^2 u(x,t)}{\partial t^2} = c^2 \frac{\partial^2 u(x,t)}{\partial x^2}
$$

Questa equazione è quella usata a mettere in relazione **l'accelerazione di un punto** con **la curvatura della funzione**. Essenzilamente stiamo correlando la seconda derivata temporale con la seconda derivata spaziale.

Questa funzione si può per esempio usare per calcolare come dovrebbe funzionare una stringa che vibra.

Andiamo ad analizzare come possiamo separare le variabili:

$$
u(x,t) = X(x) T(t)
$$

Quindi a questo punto possiamo riscrivere le funzioni come segue:

$$
\frac{\partial^2 (X(x)T(t))}{\partial t^2} = c^2 \frac{\partial^2 X(x)T(t)}{\partial x^2}
$$

Ma possiamo tirare fuori le cose che non dipendono dalla parte che viene integrata in quanto sono costanti:

$$
X(x) \frac{\partial^2 T(t)}{\partial t^2} = c^2 T(t) \frac{\partial^2 X(x)}{\partial x^2}
$$

Ora possiamo dividere per $X(x) T(t)$:

$$
\frac{1}{T(t)} \frac{\partial^2 T(t)}{\partial t^2} = c^2 \frac{1}{X(x)} \frac{\partial^2 X(x)}{\partial x^2}
$$

A questo punto vediamo che a sinistra abbia un equazione che dipende da $t$ mentre a destra una che dipende unicamente da $x$. Quindi se noi cambiamo la $x$, la $t$ non cambia ma l'equazione deve rimanere valida e viceversa vale anche per la $t$. Pertanto possiamo dire che entrambe le parti devono essere costanti:

$$
\frac{1}{T(t)} \frac{\partial^2 T(t)}{\partial t^2} = a
\\ \ \\
c^2 \frac{1}{X(x)} \frac{\partial^2 X(x)}{\partial x^2} = a
$$

A questo punto moltiplichiamo entrambi i lati per $T(t)$ e $X(x)$:

$$
\frac{\partial^2 T(t)}{\partial t^2} = a T(t)
\\ \ \\
\frac{\partial^2 X(x)}{\partial x^2} = a X(x)
$$

Quindi abbiamo due equazioni differenziali ordinarie, che possiamo risolvere. Da notare che l'unica funzione che derivata due volte ci da la stessa funzione è la funzione esponenziale. Quindi otteniamo:

$$
T(t) = A e^{\sqrt{a} t}
\\ \ \\
X(x) = B e^{\frac{\sqrt{a}}{c} x}
$$

E quindi possiamo scrivere:

$$
u(x,t) = A e^{\sqrt{a} t} B e^{\frac{\sqrt{a}}{c} x}
\\ \text{unendo le due costanti di normalizzazione abbiamo:} \\
u(x,t) = C e^{\sqrt{a} t} e^{\frac{\sqrt{a}}{c} x}
$$

A questo punto, con questa equazione, possiamo determinare $A$ e $a$ usando le boundary conditions.

## 2.1.4 Heat equation

Andiamo a calcolare la soluzione per l'equazione di come si diffonde il calore.

$$
\frac{\partial u(x,t)}{\partial t} = \alpha \frac{\partial^2 u(x,t)}{\partial x^2}
$$

Quindi rifacciamo lo stesso passaggio iniziale di separare $u$ in $X(x) T(t)$:

$$
u(x,t) = X(x)T(t)
$$

Sostituendo questa forma nell'equazione del calore otteniamo:

$$
X(x) \frac{\partial T(t)}{\partial t} = \alpha T(t) \frac{\partial^2 X(x)}{\partial x^2}
$$

A questo punto possiamo dividere per $X(x) T(t)$:

$$
\frac{1}{T(t)} \frac{\partial T(t)}{\partial t} = \alpha \frac{1}{X(x)} \frac{\partial^2 X(x)}{\partial x^2}
$$

Abbiamo quindi due parti che dipendono da $t$ e $x$ rispettivamente, quindi possiamo dire che entrambe devono essere costanti:

$$
\frac{1}{T(t)} \frac{\partial T(t)}{\partial t} = -\lambda
$$

$$
\alpha \frac{1}{X(x)} \frac{\partial^2 X(x)}{\partial x^2} = -\lambda
$$

Risolvendo queste equazioni otteniamo:

1. La soluzione per $T(t)$:

$$
T(t) = A e^{-\lambda t}
$$

2. La soluzione per $X(x)$:

L'equazione differenziale per $X(x)$ è un'equazione di tipo armonico:

$$
\frac{\partial^2 X(x)}{\partial x^2} + k^2 X(x) = 0
$$

dove $k^2 = \frac{\lambda}{\alpha}$. Le soluzioni di questa equazione sono combinazioni lineari di funzioni seno e coseno:

$$
X(x) = B \cos(kx) + C \sin(kx)
$$

Quindi, combinando le soluzioni, la soluzione generale per $u(x,t)$ è:

$$
u(x,t) = (B \cos(kx) + C \sin(kx)) e^{-\lambda t}
$$

Dove $k^2 = \frac{\lambda}{\alpha}$. I valori di $k$ e le costanti $B$ e $C$ vengono determinati dalle condizioni al contorno e dalle condizioni iniziali del problema specifico.

In sintesi, la soluzione corretta per l'equazione del calore con la separazione delle variabili è:

$$
u(x,t) = (B \cos(kx) + C \sin(kx)) e^{-\lambda t}
$$

## 2.2 Schrodinger equation

Supponiamo che la soluzione possa essere scritta come il prodotto di due funzioni, una dipendente solo da $x$ e l'altra solo da $t$:

$$
\psi(x,t) = \phi(x) T(t)
$$

Sostituendo questa forma nell'equazione di Schrödinger otteniamo:

$$
i \hbar \phi(x) \frac{\partial T(t)}{\partial t} = \left( -\frac{\hbar^2}{2m} \frac{\partial^2 \phi(x)}{\partial x^2} + V(x) \phi(x) \right) T(t)
$$

Dividiamo entrambi i lati per $\phi(x) T(t)$:

$$
i \hbar \frac{1}{T(t)} \frac{\partial T(t)}{\partial t} = \left( -\frac{\hbar^2}{2m} \frac{1}{\phi(x)} \frac{\partial^2 \phi(x)}{\partial x^2} + V(x) \right)
$$

Poiché il lato sinistro dell'equazione dipende solo da $t$ e il lato destro solo da $x$, ciascuno deve essere uguale a una costante che chiamiamo $E$:

$$
i \hbar \frac{1}{T(t)} \frac{\partial T(t)}{\partial t} = E
$$

$$
-\frac{\hbar^2}{2m} \frac{1}{\phi(x)} \frac{\partial^2 \phi(x)}{\partial x^2} + V(x) = E
$$

Ora abbiamo due equazioni differenziali ordinarie:

1. Per $T(t)$:

$$
\frac{1}{T(t)} \frac{\partial T(t)}{\partial t} = -\frac{iE}{\hbar}
$$

2. Per $\phi(x)$:

$$
-\frac{\hbar^2}{2m} \frac{\partial^2 \phi(x)}{\partial x^2} + V(x) \phi(x) = E \phi(x)
$$

#### 2.2.3 Risoluzione delle equazioni

1. La soluzione per $T(t)$:

$$
\frac{\partial T(t)}{\partial t} = -\frac{iE}{\hbar} T(t)
$$

Integrando otteniamo:

$$
T(t) = e^{-\frac{iE}{\hbar} t}
$$

2. La soluzione per $\phi(x)$:

L'equazione differenziale per $\phi(x)$ è l'equazione di Schrödinger indipendente dal tempo:

$$
-\frac{\hbar^2}{2m} \frac{\partial^2 \phi(x)}{\partial x^2} + V(x) \phi(x) = E \phi(x)
$$

Questa è un'equazione agli autovalori dove $E$ è l'autovalore associato all'energia della particella e $\phi(x)$ è la funzione d'onda stazionaria.

#### 2.2.4 Soluzione generale

La soluzione generale dell'equazione di Schrödinger dipendente dal tempo è:

$$
\psi(x,t) = \phi(x) e^{-\frac{iE}{\hbar} t}
$$

Dove $\phi(x)$ è una soluzione dell'equazione di Schrödinger indipendente dal tempo e $E$ è l'energia corrispondente a questa soluzione. Le funzioni $\phi(x)$ e i valori di $E$ vengono determinati dalle condizioni al contorno e dalle specifiche del potenziale $V(x)$.

In sintesi, la soluzione per l'equazione di Schrödinger dipendente dal tempo con la separazione delle variabili è:

$$
\psi(x,t) = \phi(x) e^{-\frac{iE}{\hbar} t}
$$

Dove $\phi(x)$ soddisfa l'equazione di Schrödinger indipendente dal tempo:

$$
-\frac{\hbar^2}{2m} \frac{\partial^2 \phi(x)}{\partial x^2} + V(x) \phi(x) = E \phi(x)
$$

---

Il professore le scrive come:

$$
i \hbar \frac{dT}{dt} = E T
\\ \ \\
- \frac{\hbar^2}{2m} \frac{d^2 X}{dx^2} + V(x) X = E X
$$

Dove $T$ è la parte temporale e $X$ è la parte spaziale (Al posto di $\phi$).

Da notare che possiamo risolvere l'equazione del tempo in modo molto semplice:

$$
\frac{dT}{dt} = - \frac{iE}{\hbar} T
\\ \ \\
\frac{1}{T} dT = - \frac{iE}{\hbar} dt
\\ \ \\
\int \frac{1}{T} dT = - \frac{iE}{\hbar} \int dt
\\ \ \\
\ln(T) = - \frac{iE}{\hbar} t + C
\\ \ \\
T = e^{- \frac{iE}{\hbar} t + C}
\\ \ \\
T = e^{- \frac{iE}{\hbar} t} e^C
\\ \ \\
T = e^{- \frac{iE}{\hbar} t} C
$$

(La C viene anche omessa a volte)

## 2.3 Stationary solutions to the Schrödinger equation

Ripetiamo un attimo l'equazione di Schrödinger:

$$
i\hbar \frac{\partial \psi}{\partial t} = -\frac{\hbar^2}{2m} \frac{\partial^2 \psi}{\partial x^2} + V(x) \psi
$$

Noi abbiamo riscritto la funzione d'onda separando le variabili nel seguente modo:

$$
\psi(x,t) = X(x) e^{-\frac{iE}{\hbar} t}
$$

Consideriamo quindi la densità di probabilità:

$$
\rho(x,t) = |\psi(x,t)|^2 = |X(x) e^{-\frac{iE}{\hbar}}|^2
\\ \ \\
= X^*(x) e^{\frac{iE}{\hbar} t} X(x) e^{-\frac{iE}{\hbar} t}
\\ \ \\
= |X(x)|^2
$$

Quindi non è dipendente dal tempo!

Quindi, da ricordare che la densità di probabilità di una particella in uno stato stazionario è indipendente dal tempo, ovvero intuitivamente la probabilità di trovare la particella in una certa posizione non cambia nel tempo (ciò che cambia sarà la fase, che quindi se vengono combinate più stati con fasi diverse si possono incorrere in fenomeni costruttivi o distruttivi).

Un'altra cosa che cambia nel tempo sono le evoluzioni di osservabili non posizionali: per esempio per il momento angolare, la fase temporale gioca un ruolo fondamentale.

### 2.3.1 Operatore

Immaginiamo ora di applicare un operatore generico $\hat{Q}$ alla funzione d'onda:

$$
\braket{Q} = \int \psi^* \hat{Q} \psi \ dx
\\ \ \\
= \int X^* e^{\frac{iE}{\hbar} t} \hat{Q} X e^{-\frac{iE}{\hbar} t} \ dx
$$

Possiamo fare il passaggio di cancellare il tempo (in quanto la maggiorparte degli operatori che usiamo non dipendono dal tempo, quindi la parte del tempo, per l'operatore, è una costante che possiamo tirare fuori, per esempio $\hat{x} = x$, $\hat{p} = -i\hbar \frac{\partial}{\partial x}$, etc):

$$
= e^{\frac{iE}{\hbar} t} e^{-\frac{iE}{\hbar} t} \int X^* \hat{Q} X \ dx
\\ \ \\
= \int X^* \hat{Q} X \ dx
$$

Quindi $\braket{Q}$ è **indipendente dal tempo**.

### 2.3.2 Stationary states and energy

Ricordiamo che la parte spaziale della **TISE** è:

$$
- \frac{\hbar^2}{2m} \frac{d^2 X}{dx^2} + V(x) X = E X
\\ \ \\
\hat{H} X = E X
$$

Supponiamo di voler calcolare il valore di aspettazione dell'energia:

$$
\braket{\hat{H}} = \int X^* e^{\frac{iE}{\hbar} t} \hat{H} X e^{-\frac{iE}{\hbar} t} \ dx
$$

Possiamo cancellare il tempo, in quanto l'Hamiltoiano non dipende dal tempo:

$$
= \int X^* \hat{H} X \ dx
\\ \ \\
= \int X^* E X \ dx
\\ \ \\
= E \int X^* X \ dx
\\ \ \\
= E
$$

In quanto $\int X^* X \ dx = 1$ (se lo abbiamo normalizzato, per il fatto che le probabilità devono sommare a 1).

#### 2.3.3 Deviazione standard

Vogliamo ora calcolare $\sigma_{\hat{H}}^2$:

$$
\sigma_{\hat{H}}^2 = \braket{\hat{H}^2} - \braket{\hat{H}}^2
$$

Il secondo termine è già stato calcolato, quindi ci manca il primo:

$$
\braket{\hat{H}^2} = \int X^* e^{\frac{iE}{\hbar} t} \hat{H}^2 X e^{-\frac{iE}{\hbar} t} \ dx
\\ \ \\
= \int X^* \hat{H}^2 X \ dx
\\ \ \\
= \int X^* \hat{H} (\hat{H} X) \ dx
\\ \ \\
= \int X^* \hat{H} (E X) \ dx
\\ \ \\
= E \int X^* \hat{H} X \ dx
\\ \ \\
= E^2
$$

Quindi abbiamo che la deviazione standard è:

$$
\sigma_{\hat{H}}^2 = E^2 - E^2 = 0
$$

Quindi non abbiamo **incertezza** sull'energia.

### 2.3.4 Riassumendo

Per degli stati stazionari abbiamo i seguenti fatti:
- $\rho(x)$ è indipendente dal tempo
- $\braket{Q}$ è indipendente dal tempo
- $\braket{\hat{H}} = E$
  - L'energia è esatta, non c'è incertezza

Notiamo però che:

$$
\Delta E \Delta t \geq \frac{\hbar}{2}
$$

Quindi $\Delta E$ è tendendo verso 0, pertanto $\Delta t$ tende verso l'infinito - negli stati stazionari.

Quindi la risposta a "quando" è "sempre", ovvero non possiamo dire nulla sul tempo. Questi stati sono costanti sempre, dall'inizio alla fine del tempo.

Notiamo che quindi non sono particolarmente realistici, però hanno proprietà matematiche molto carine che useremo per imparare.

## 2.4 Superpositions of stationary states

Per ora abbiamo visto gli stati stazionari, ovvero cose che sono così nel tempo e che non cambiano.

Ma a noi interessano anche le cose che cambiano nel tempo, quindi come andiamo ad analizzare o strutturare un problema in modo da avere anche questa parte?

Seppure la loro time dependance è triviale per gli stati stazionari, se noi sommiamo insieme più stati stazionari in una superposizione, la loro dipendenza temporale non è più banale. Da qui deriva la parte interessante dell'evoluzione temporale della MQ.

### 2.4.1 Linearità dell'equazione di Schrödinger

Questo è ciò che ci permette di andare a creare una superposizione di più stati stazionari.

Supponiamo di avere due soluzioni dell'equazione di Schrödinger, $A(x,t)$ e $B(x,t)$:

$$
i \hbar \frac{\partial A}{\partial t} = -\frac{\hbar^2}{2m} \frac{\partial^2 A}{\partial x^2} + V(x) A
\\ \ \\
i \hbar \frac{\partial B}{\partial t} = -\frac{\hbar^2}{2m} \frac{\partial^2 B}{\partial x^2} + V(x) B
$$

Ora supponiamo di voler verificare se anche $\psi(x,t) = A(x,t) + B(x,t)$ è una soluzione dell'equazione di Schrödinger:

$$
i \hbar \frac{\partial \psi}{\partial t} = i \hbar \frac{\partial (A + B)}{\partial t} = i \hbar \left( \frac{\partial A}{\partial t} + \frac{\partial B}{\partial t} \right)
\\ \ \\
= -\frac{\hbar^2}{2m} \frac{\partial^2 (A + B)}{\partial x^2} + V(x) (A + B)
\\ \ \\
= -\frac{\hbar^2}{2m} \left( \frac{\partial^2 A}{\partial x^2} + \frac{\partial^2 B}{\partial x^2} \right) + V(x) (A + B)
\\ \ \\
= -\frac{\hbar^2}{2m} \frac{\partial^2 A}{\partial x^2} + V(x) A -\frac{\hbar^2}{2m} \frac{\partial^2 B}{\partial x^2} + V(x) B
\\ \ \\
= i \hbar \frac{\partial A}{\partial t} + i \hbar \frac{\partial B}{\partial t}
\\ \ \\
= i \hbar \frac{\partial \psi}{\partial t}
$$

Quindi l'equazione di Schrödinger è lineare (assumendo che il potenziale sia lineare).

### 2.4.2 Soluzione generica dell'equazione di Schrödinger

Supponiamo di avere una soluzione dipendente dal tempo $\psi(x,t)$ dell'equazione di Schrödinger. Essa può essere scritta come:

$$
\psi(x,t) = \sum_n c_n \psi_n(x,t)
\\ \ \\
\text{dove} \quad \psi_n(x,t) = \phi_n(x) e^{-\frac{iE_n}{\hbar} t}
\\ \ \\
\text{quindi possiamo scrivere} \quad  \psi(x,t) = \sum_n c_n \phi_n(x) e^{-\frac{iE_n}{\hbar} t}
$$

Dove $\phi$ è $X$. Data $c_j$ una costante (che ci indica quanto di ciascun stato andare a mischiare dentro). Questa soluzione è generale! Ciò che vuol dire è che non si limita a dare soluzioni a stati stazionari, ma anche a stati non stazionari: tutte le possibili soluzioni possono essere scritte come combinazione lineare di stati stazionari. (NON SCONTATO)

#### 2.4.2.1 Esempio

Immaginiamo di avere i due stati:

$$
\hat{H} X_1 = E_1 X_1
\\ \ \\
\hat{H} X_2 = E_2 X_2
$$

Possiamo scrivere la soluzione generale come:

$$
\psi(x,t) = c_1 X_1 e^{-\frac{iE_1}{\hbar} t} + c_2 X_2 e^{-\frac{iE_2}{\hbar} t}
$$

Se $t=0$ da notare che:

$$
\psi(x,0) = c_1 X_1 + c_2 X_2
$$

Cerchiamo ora l'expected value dell'energia:

$$
\braket{\hat{H}} = \int \psi^* \hat{H} \psi \ dx
\\ \ \\
= \int (c_1 X_1^* e^{\frac{iE_1}{\hbar} t} + c_2 X_2^* e^{\frac{iE_2}{\hbar} t}) \hat{H} (c_1 X_1 e^{-\frac{iE_1}{\hbar} t} + c_2 X_2 e^{-\frac{iE_2}{\hbar} t}) \ dx
\\ \ \\
$$

So che l'Hamiltoniana non fa nulla alla parte temporale, e so anche cosa esso faccia a $X_1$ e $X_2$, quindi possiamo riscrivere:

$$
= \int (c_1 X_1^* e^{\frac{iE_1}{\hbar} t} + c_2 X_2^* e^{\frac{iE_2}{\hbar} t}) (c_1 E_1 X_1 e^{-\frac{iE_1}{\hbar} t} + c_2 E_2 X_2 e^{-\frac{iE_2}{\hbar} t}) \ dx
\\ \ \\
$$

Facendo ora la moltiplicazione termine per termine ottengo:

$$
= \int c_1^2X_1^*X_1E_1 + c_2^2X_2^*X_2E_2 + c_1c_2X_1^*X_2E_2e^{\frac{i(E_2-E_1)t}{\hbar}} + c_1c_2X_2^*X_1E_1e^{\frac{i(E_1-E_2)t}{\hbar}} \ dx
$$

I primi due termini, se normalizzati, risultano in $c_1 E_1 + c_2 E_2$, mentre i secondi due termini risultano in 0, in quanto $\int X_1^* X_2 \ dx = 0$ e $\int X_2^* X_1 \ dx = 0$.

Quindi l'expected value dell'energia è:

$$
\braket{\hat{H}} = c_1 E_1 + c_2 E_2
$$

### 2.4.3 Densità di provabilità

To explain why the probability density $\rho(x, t) = |\Psi(x, t)|^2$ exhibits non-trivial time dependence, let's analyze the given quantum system described by the initial wave function $\Psi(x, t=0) = c_1 \chi_1(x) + c_2 \chi_2(x)$, where $\chi_1$ and $\chi_2$ are eigenfunctions of the Hamiltonian operator $\hat{H}$ with distinct eigenvalues $E_1$ and $E_2$ respectively.

Time Evolution in Quantum Mechanics:
The time evolution of a wave function in quantum mechanics is governed by the Schrödinger equation. For a wave function initially expressed as a linear combination of eigenfunctions of the Hamiltonian, the solution to the time-dependent Schrödinger equation can be written as:

$$
\Psi(x, t) = c_1 \chi_1(x) e^{-iE_1 t/\hbar} + c_2 \chi_2(x) e^{-iE_2 t/\hbar}
$$
 
where $\hbar$ is the reduced Planck constant, and $e^{-iE t/\hbar}$ is the time evolution factor for an eigenstate with energy $E$.

Probability Density:
The probability density $\rho(x, t)$ is the modulus squared of the wave function:

$$
\rho(x, t) = |\Psi(x, t)|^2 = |c_1 \chi_1(x) e^{-iE_1 t/\hbar} + c_2 \chi_2(x) e^{-iE_2 t/\hbar}|^2
$$
 
Expanding this expression, we get:

$$
\rho(x, t) = |c_1 \chi_1(x)|^2 + |c_2 \chi_2(x)|^2 + c_1^* c_2 \chi_1^*(x) \chi_2(x) e^{i(E_1 - E_2)t/\hbar} + c_1 c_2^* \chi_1(x) \chi_2^*(x) e^{i(E_2 - E_1)t/\hbar}
$$
 
This expansion includes the last two terms, which are cross terms that incorporate complex exponentials with time-dependent phases.

(These do not cancel out like before since before we had them in an integral, here they aren't in an integral).

Time Dependence:
The key to understanding the non-trivial time dependence lies in the cross terms:

$$
c_1^* c_2 \chi_1^*(x) \chi_2(x) e^{i(E_1 - E_2)t/\hbar} + c_1 c_2^* \chi_1(x) \chi_2^*(x) e^{i(E_2 - E_1)t/\hbar}
$$
 
Because $E_1 \neq E_2$, the phase $(E_1 - E_2)t/\hbar$ changes continuously with time, causing the entire expression for $\rho(x, t)$ to oscillate. These oscillations represent the interference between the two states $\chi_1$ and $\chi_2$, a manifestation of the quantum mechanical superposition principle.

Conclusion:
The non-trivial time dependence in $\rho(x, t)$ arises from the interference terms that oscillate due to the differing energies $E_1$ and $E_2$ of the states involved. If $E_1$ were equal to $E_2$, these terms would reduce to constant contributions, and the time dependence would be trivial (merely exponential decay factors without oscillations).

## 2.5 Problemi classici in MQ

1. Si inizia con uno stato fisico
   1. Per esempio una particella in un punto, una particella in movimento, etc.
2. Si scrive la funzione del potenziale
   1. Per esempio un potenziale costante, un potenziale armonico, etc.
3. Si risolve la TISE per quel potenziale
   1. Si ottengono gli autovalori e le autofunzioni
4. Si determinano gli stati stazionari
   1. Si scrive la soluzione generale come combinazione lineare di stati stazionari
   2. Essenzialmente $X_1 e^{-iE_1 t/\hbar} + X_2 e^{-iE_2 t/\hbar}$ etc.
5. Si esprimono le condizioni come una somma di stati stazionari
   1. Per esempio $\psi(x,0) = c_1 X_1 + c_2 X_2$
6. Si aggiungono le dipendenze di tempo a tutti gli stati stazionari
7. Finito!

## 2.6 Energia potenziale

Riscriviamo come al solito l'equazione di Schrödinger:

$$
- \frac{\hbar^2}{2m} \frac{\partial^2 \psi(x)}{\partial x^2} + V(x) \psi(x) = E \psi(x)
$$

In un modo euristico possiamo analizzare che, prendendo la parte $V(x) \psi(x)$:
- Se $\psi(x)$ ha un valore molto alto in una regione dove l'energia potenziale $V(x)$ è molto alta, allora c'è una buona probabilità che la particella abbia un energia poteziale molto alta
- Se $\psi(x)$ ha un valore molto basso in una regione dove l'energia potenziale $V(x)$ è molto alta, allora c'è una buona probabilità che la particella abbia un energia poteziale molto bassa

Andiamo a riorganizzare l'equazione di Schrödinger in modo da avere la seconda derivata della funzione d'onda a sinistra:

$$
\frac{\partial^2 \psi(x)}{\partial x^2} = \frac{2m}{\hbar^2} (V(x) - E) \psi(x)
$$

Notiamo che quindi:
- Se il segno della derivata seconda è negativo, allora il valore $V(x) > E$, quindi c'è più energia "potenziale" che "totale", quindi l'energia cinetica è negativa per controbilanciare
- Se $E > V(x)$, allora il segno della seconda derivata è positivo

### 2.6.1 Alcuni casi diversi di potenziali che andremo a vedere

1. Particella dentro una scatola (hard)
   1. C'è un intervallo, diciamo tra $-a$ ed $a$, dove il potenziale è 0, mentre al di fuori è infinito (con uno scatto di un gradino)
   2. La particella **non può** uscire dalla scatola indipendentemente dall'energia che gli diamo
   3. **[Capitolo 2.2 del Griffiths]**
2. Oscillatore armonico
   1. La funzione del potenziale è $V(x) \propto x^2$, quindi più ci si allontana dall'originie più il potenziale aumenta in modo quadrato, come un oscillatore armonico classico
   2. **[Capitolo 2.3 del Griffiths]**
3. $\delta$-function
   1. Un potenziale che è 0 ovunque tranne che in un punto, dove è $-\infty$
   2. Quindi la particella può andare ovunque, non ha "dominio di esistenza"
   3. **[Capitolo 2.5 del Griffiths]**
4. Particella dentro una scatola (soft)
   1. In un area $-a$ e $a$, la particella ha 0 potenziale, mentre al di fuori ha un potenziale costante ma non infinito.
   2. **[Capitolo 2.6 del Griffiths]**
5. Nessun potenziale
   1. $V(x)$ è 0 ovunque (o costante) $\implies$ questo ha conseguenze interessanti per l'equazione di Schrödinger
   2. **[Capitolo 2.4 del Griffiths]**

## 2.7 Derivate e come si comporta la funzione d'onda

Riscriviamo la derivata seconda della nostra funzione d'onda (che otteniamo dall'EQ di S. girando un po' i termini):

$$
\frac{\partial^2 \psi(x)}{\partial x^2} = \frac{2m}{\hbar^2} (V(x) - E) \psi(x)
$$

Abbiamo che quindi:
- Se $V(x) > E$, allora la derivata seconda è negativa
  - Questo vuol dire che $\psi$ si muoverà "via" dall'asse delle X
  - Ovvero, se si trova sopra l'asse delle X andrà in sù, se si trova sotto l'asse delle X sarà curvato in giù
- Se $V(x) < E$, allora la derivata seconda è positiva
  - Questo vuol dire che $\psi$ si muoverà "verso" l'asse delle X
  - Ovvero, se si trova sopra l'asse delle X andrà in giù, se si trova sotto l'asse delle X sarà curvato in sù

Usare quesat intuizione ci da un certo feel per come una soluzione dovrebbe essere, ovvero possiamo andare a capire: quando cambia curvatura, in che modo è formata, etc.

(Dobbiamo però sempre andare ad impostare un energia. Se non lo facciamo, non possiamo dire nulla sulla funzione d'onda).

Rivedere [questo video](https://youtu.be/FQugbwN9F-E?si=WvU7clKchjC4Hty7&t=1000) per vedere come viene spiegato il concetto visivamente.

Da ricordare che **quando viene attraversato un boundary, la wave function è smooth**: quindi non deve "cambiare angolo bruscamente" quando passa da una parte all'altra del boundary del potenziale.

# 3. Infinite square well

## 3.1 Introduzione

Il problema è spiegato nel modo seguente: la funzione dell'energia potenziale è:

$$
V(x) = \begin{cases} 0 & \text{se } 0 \leq x \leq a \\ \infty & \text{altrimenti} \end{cases}
$$

Riscriviamo l'equazione di Schrödinger TISE:

$$
- \frac{\hbar^2}{2m} \frac{d^2 \psi(x)}{dx^2} + V(x) \psi(x) = E \psi(x)
$$

Questa equazione fuori dalla regione non va bene: $V(x)$ sarebbe infinita: l'unico modo nel quale ha senso è se $\psi(x) = 0$ al di fuori della regione.

Se invece siamo dentro:-
- $V(x) = 0$, quindi possiamo cancellare quella parte dell'equazione

Quindi l'equazione che vogliamo risolvere diventa:

$$
- \frac{\hbar^2}{2m} \frac{d^2 \psi(x)}{dx^2} = E \psi(x)
$$

Quindi possiamo rigirare un attimo queste equazioni:

$$
\frac{d^2 \psi(x)}{dx^2} = - \frac{2mE}{\hbar^2} \psi(x)
$$

In particolare, per comodità, si definisce $k = \sqrt{\frac{2mE}{\hbar^2}}$.

Quindi l'equazione diventa:

$$
\frac{d^2 \psi(x)}{dx^2} = -k^2 \psi(x)
$$

A questo punto si può risolvere nel seguente modo "consueto":

$$
\psi(x) = A \sin(kx) + B \cos(kx)
$$

Con $A$ e $B$ costanti.

## 3.2 Boundary conditions

Le boundary conditions sono ciò che ottieni considerando la situazione a mano e in particolare cosa succede ai bordi. 

Sappiamo un paio di cose rigaurdo alla funzione d'onda che possiamo usare:
- $\psi$ deve essere continua
  - Se questo non fosse il caso allora per esempio la funzione del momento ci potrebbe dare dei valori strani in punti di discontinuità, quindi per "assurdo" assumiamo questo non sia il caso

Le boundary conditions sono le seguenti:

1. $\psi(0) = 0$
2. $\psi(a) = 0$

La prima ci implica che $B = 0$. Con la seconda condizione abbiamo che:

$$
\psi(a) = A \sin(ka) = 0
\implies ka = \plusmn n\pi
$$

In particolare non ci interessa $\psi = 0$, perché poi non la possiamo usare (la funzione d'onda è 0 ovunque). Inoltre il segno lo possiamo lasciare fuori, in quanto possiamo sempre cambiare il segno di $A$.

Quindi abbiamo:

$$
ka = n\pi
$$

Inoltre, sostituendo per $k$ il valore vero abbiamo:

$$
\sqrt{\frac{2mE}{\hbar^2}} a = n\pi
$$

Quindi possiamo risolvere per $E$ (che è l'unica variabile per la quale ha senso risolvere):

$$
E = \frac{n^2 \pi^2 \hbar^2}{2ma^2}
$$

- Questo è un **set discreto di valori di energia** possibili!

Quindi abbiamo una serie di stati stazionari, con un set discreto di valori di energia possibili:

$$
\psi_n(x) = A \sin \left( \frac{n\pi x}{a} \right)
\\ \ \\
E_n = \frac{n^2 \pi^2 \hbar^2}{2ma^2}
$$

## 3.3 Normalizzazione

A questo punto abbiamo la condizione di normalizzazione ch eci aiuta a risolvere per $A$:

$$
\int_{-\infty}^{\infty} |\psi(x)|^2 \ dx = 1
\\ \ \\
\int_{0}^{a} |A \sin \left( \frac{n\pi x}{a} \right)|^2 \ dx = 1
\\ \ \\
\int_{0}^{a} A^2 \sin^2 \left( \frac{n\pi x}{a} \right) \ dx = 1
$$

Una cosa che ci viene detta durante questa lezione è che:
- L'integrale del seno in un intervallo del genere è $\frac{1}{2}$
- Questo lo si può calcolare meglio usando l'identità trigonometrica $\sin^2(x) = \frac{1 - \cos(2x)}{2}$

Ciò che abbiamo è:

$$
A^2 \frac{1}{2} a = 1
$$

Quindi:

$$
A = \sqrt{\frac{2}{a}}
$$

Quindi il risultato a questo punto è:

$$
\psi_n(x) = \sqrt{\frac{2}{a}} \sin \left( \frac{n\pi x}{a} \right)
$$

E le energie associate a queste soluzioni sono:

$$
E_n = \frac{n^2 \pi^2 \hbar^2}{2ma^2}
$$

Da notare che nel punto centrale, ovvero ad $x = \frac{a}{2}$, la funzione d'onda o è massima, o è 0, in base a se $n$ è dispari o pari.

![Infinite square well](livellieng1.png)

## 3.4 Alcune domande per controllare se si ha capito

Spiegare cosa c'è di sbagliato con questi punti:
1. $\psi$ non può andare a 0, perché $V(x)$ infinita implica $\frac{\partial^2\psi}{\partial x^2}$ infinita, che vuol dire che $\psi$ curverebbe in su all'infinito nella regione al di fuori della scatola
2. $\psi$ in generale è compless, quindi dovremmo scrivere la soluzione in termini di $e^{ikx}$ non in termini di $sin(kx)$. Abbiamo tralasciato una parte importante della MQ!

Risposte:
1. Il valore di $V(x)$ non implica nulla direttamente per il valore della derivata seconda della funzione d'onda. Proprio per come è strutturato il problema la funzione d'onda deve essere 0 al di fuori della scatola, quindi non c'è nessun problema con la derivata seconda.
2. Noi possiamo esprimere $e^{ikx}$ come combinazione lineare di $sin(kx)$ e $cos(kx)$, cosa che facciamo (il motivo per cui il coseno è assente è perché si azzera per i calcoli che facciamo).

## 3.5 Ortogonalità e completezza

Ripasso degli stati stazionari:

![Infinite square well](stationarystatesenergies1.png)

Inoltre possiamo notare le seguenti cose:
- Le funzioni sono simmetriche se le guardiamo dal centro della scatola:
  - O sono pari o sono dispari, in particolare la funzione si annulla al centro della scatola oppure ha un massimo.
- Possiamo contare il numero di **nodi** nella scatola, ovvero il numero di volte che l'onda attraversa l'asse $x$.
  - Il numero di *nodi* è $n-1$, dove $n$ è lo stato stazionario.
- Gli stati stazionari sono **ortogonali tra di loro**
  - $\int \psi_n^* \psi_m \ dx = 0$ se $n \neq m$
- Gli stati stazionari sono **completi**
  - Ogni funzione può essere scritta come combinazione lineare di stati stazionari

### 3.5.1 Ortogonalità

Andiamo a definire meglio il concetto di ortogonalità per funzioni.

Ripartiamo scrivendo quello che è il concetto per i vettori:

$$
\vec{v} \cdot \vec{w} = 0
$$

Per le funzioni si può scrivere nel seguente modo:

$$
\int f^* g \ dx = 0 \iff f \perp g
$$

Da notare che:

$$
\vec{a} \cdot \vec{a} = |\vec{a}|^2 \quad (=1 \text{ se a è un unit vector})
$$

E anche che:

$$
\int f^* f \ dx = 1 \quad (=1 \text{ se f è normalizzato})
$$

Dimostriamo l'ortogonalità dei $sin$:

![Sin orth](orthogonalityofsin.png)

L'ultima espressione ci dice che quindi abbiamo che le funzioni d'onda sono:

$$
\int_{0}^{a} \psi_n^* (x) \psi_m(x) \ dx = \delta_{nm}
\\ \ \\
\delta_{nm} = \begin{cases} 1 & \text{se } n = m \\ 0 & \text{se } n \neq m \end{cases}
$$

### 3.5.2 Fourier's trick

Viene descritto nel libro con questo nome.

Supponiamo di avere $f(x) = \sum_{n=1}^{\infty} c_n \sin \left( \frac{n\pi x}{a} \right)$. Vogliamo trovare i coefficienti $c_n$.

Lo facciamo nel seguente modo:

![Fourier trick](fouriertrick.png)

Quindi noi potremmo andare a scrivere una funzione in termini dei sui stati stazionari.

Quindi abbiamo:

$$
f(x) = \sum_{n=1}^{\infty} c_n \sin \left( \frac{n\pi x}{a} \right)
\\ \ \\
c_n = \frac{2}{a} \int_0^a f(x) \sin \left( \frac{n\pi x}{a} \right) \ dx
$$

**Questo funziona per tutte le $f(x)$**, a patto che siano continue e square-integrable.

Quindi, se noi abbiamo una qualsiasi funzione che vogliamo scrivere in termini di stati stazionari, possiamo usare questa formula: con abbastanza $c_n$ possiamo approssimare qualsiasi funzione.

## 3.6 Esempio

### 3.6.1 General procedure

1. Risolvere la TISE, per ottenere la forma degli stati stazionari
2. Applicare le boundary conditions e ottenere le funzioni d'onda e le energie
3. Normalizzare le funzioni d'onda
4. Ottenere il set ortonormale $\psi_n(x)$ e aggiungergli la parte dipendente dal tempo, ottenere $\psi_n(x,t)$
5. Esprimere le condizioni iniziale come una somma di $\psi_n(x,t)$
6. Usa la risposta per determinare il comportamento del sistema

### 3.6.2 Esempio

Riscriviamo quindi ciò che avevamo precedentemente determinato per gli stati stazionari e l'energia e la formula dipeendente dal tempo:

$$
\psi_n(x) = \sqrt{\frac{2}{a}} \sin \left( \frac{n\pi x}{a} \right), \quad E_n = \frac{n^2 \pi^2 \hbar^2}{2ma^2}
\\ \ \\
\psi_n(x,t) = \sqrt{\frac{2}{a}} \sin \left( \frac{n\pi x}{a} \right) e^{-\frac{iE_n}{\hbar} t}
\\ \ \\
\text{che si scrive per intero come:}
\\ \ \\
\psi_n(x,t) = \sqrt{\frac{2}{a}} \sin \left( \frac{n\pi x}{a} \right) e^{-\frac{i n^2 \pi^2 \hbar t}{2ma^2}}
$$

Supponiamo di considerare la condizione iniziale seguente:

$$
\psi(x,0) = \begin{cases} \sqrt{\frac{3}{a}}(1-|{\frac{x-a/2}{a/2}}|) & \text{se } 0 \leq x \leq a \\ 0 & \text{altrimenti} \end{cases}
$$

Andiamo a riscrivere questa funzione togliendo il valore assoluto e quindi con 3 casi ora:

$$
\psi(x,0) = \begin{cases} \sqrt{\frac{3}{a}}(1-\frac{a/2 - x}{a/2}) & \text{se } 0 \leq x \leq a/2 \\ \sqrt{\frac{3}{a}}(1-\frac{x- a/2}{a/2}) & \text{se } a/2 \leq x \leq a \\ 0 & \text{altrimenti} \end{cases}
$$

A questo punto dobbiamo fare:

$$
\psi(x,0) = \sum_{n=1}^{\infty} c_n \sqrt{\frac{2}{a}} \sin \left( \frac{n\pi x}{a} \right)
$$

In particolare dobbiamo calcolare:

$$
c_n = \int_0^a \psi^*_n(x,0) \psi(x,0) \ dx
\\ \ \\
= \int_0^{a/2} \sqrt{\frac{2}{a}} \sin \left( \frac{n\pi x}{a} \right) \sqrt{\frac{3}{a}}(1-\frac{a/2 - x}{a/2}) \ dx + \int_{a/2}^{a} \sqrt{\frac{2}{a}} \sin \left( \frac{n\pi x}{a} \right) \sqrt{\frac{3}{a}}(1-\frac{x- a/2}{a/2}) \ dx
$$

E che dio ci aiuti, questa cosa richiede tempo.

Si possono usare dei software matematici per computare questi valori.

Possiamo calcolare $\braket{x^2}$, ovvero la deviazione standard della posizione. Lo possiamo fare troncando per esempio il numero di stati stazionari che prendiamo in considerazione, e vedendo come cambia il valore di $\braket{x^2}$.

Ciò che notiamo è che questa sarà una funzione sinoidale che oscilla in un punto sopra a 0. Pertanto possiamo affermare che l'onda che rappresenta la particella, nel tempo, oscilla aumentando e diminuendo "l'intensità del suo picco della posizione", quindi prima sarai quasi sicuro si trovi in un certo punto, poi di meno, e poi di nuovo piuttosto sicuro, etc.

Si può usare questo sito per fare delle prove: https://falstad.com/qm1drad/.

Nel sito:
- Si imposta una condizione iniziale, che deriva dalla combinazione di diverse onde stazionarie con diverse intensità.
- Viene mostrata l'evoluzione temporale del sistema.

# 4. Oscillatore armonico

Ci sono diversi modi per risolvere questo problema, nel nostro caso lo approcceremo con il metodo dell'operatore di abbassamento e di alzamento. (Ladder operators)

## 4.1 TISE solution by ladder operations

L'energia potenziale di un oscillatore armonico è:

$$
V(x) = \frac{1}{2} k x^2
$$

Ma è più comodo scriverlo in termini dell'**angular frequency**, ovvero $\omega = \sqrt{\frac{k}{m}}$:

$$
V(x) = \frac{1}{2} m \omega^2 x^2
$$

Questa sarà una parabola centrata in 0.

Noi abbiamo, in base a ciò che abbiamo definito prima, un idea della soluzione dell'equazione di Schrödinger, ovvero come è curvata. Nell'immagine sottostante abbiamo due esempi di come potrebbe essere la funzione d'onda dati due esempi di livelli di energia:

![Harmonic oscillator](finetuningoa.png)

Possiamo notare l'energia rispetto all'energia potenziale, e quindi possiamo disegnare la curva che rappresenta la funzione d'onda.

Se L'energia totale del sistema è maggiore dell'energia potenziale, allora la funzione d'onda "curva" in basso, e vale anche il viceversa.

Notiamo che quindi ci sono diversi parametri che sembrano liberi e che derivano da "fine tuning":
- L'angolo con il quale la funzione d'onda intercetta l'origine, se passa sopra o sotto l'energia, etc.

Riscrivamo la TISE per l'oscillatore armonico:

$$
- \frac{\hbar^2}{2m} \frac{d^2 \psi(x)}{dx^2} + \frac{1}{2} m \omega^2 x^2 \psi(x) = E \psi(x)
$$

Da ricordare che l'operatore Hamiltoniano è:

$$
\hat{H} = - \frac{\hbar^2}{2m} \frac{d^2}{dx^2} + \frac{1}{2} m \omega^2 x^2
$$

Potremmo riscrivere l'operatore Hamiltoniano usando l'operatore di momentum e raccogliendo le cose:

$$
\hat{H} = \frac{1}{2m} \hat{p}^2 + \frac{1}{2} m \omega^2 x^2
\\ \ \\
\hat{H} = \frac{1}{2m} (\hat{p}^2 + (m\omega x)^2)
$$

Da ricordare che con i numeri, usando numeri complessi, vale la formula:

$$
(a^2 + b^2) = (ia + b) (ia - b)
$$

Questa cosa ci "suggerisce" (in quanto poi da un punto di vista pratico gli operatori non si comportano esattamente come dei numeri), di avere:

$$
\plusmn i \hat{p} + m \omega \hat{x}
$$

### 4.1.1 Ladder operators

I ladder operator li definiamo nel seguente modo:

$$
\hat{a}_\plusmn = \frac{1}{\sqrt{2 \hbar m \omega}} (\mp i \hat{p} + m \omega \hat{x})
$$

Controlliamo che se abbiamo qualcosa che se davvero si fattorizza nel modo che abbiamo "suggerito" prima allora diventa l'Hamiltoniano:

$$
\hat{H} \overset{?}{=} \hat{a}_- \hat{a}_+
$$

Proviamo a fare quindi il calcolo:

$$
\frac{1}{2\hbar m \omega} (i \hat{p} + m\omega \hat{x}) (i \hat{p} - m\omega \hat{x})
\\ \ \\
= \frac{1}{2\hbar m \omega} (i \hat{p} i \hat{p} - i \hat{p} m\omega \hat{x} + m\omega \hat{x} i \hat{p} - m\omega \hat{x} m\omega \hat{x})
\\ \ \\
= \frac{1}{2\hbar m \omega} (\hat{p}^2 + m^2 \omega^2 \hat{x}^2 - i m \omega (\hat{x}\hat{p} - \hat{p}\hat{x}))
$$

Ora, notiamo che la parte di sinistra è quasi l'Hamiltoniana, con un paio di cose in più. D'altro canto, la parte a destra è un commutatore, quindi possiamo riscrivere la cosa come:

$$
\frac{1}{2\hbar m \omega} (\hat{p}^2 + m^2 \omega^2 \hat{x}^2 - i m \omega [\hat{x}, \hat{p}])
\\ \ \\
= \frac{1}{\hbar \omega} \hat{H} - \frac{i}{2\hbar} [\hat{x}, \hat{p}]
$$

### 4.1.2 Commutatore

Discutiamo ora un attimo dei commutatori. Il commutatore è definito come:

$$
[\hat{A}, \hat{B}] = \hat{A}\hat{B} - \hat{B}\hat{A}
$$

Ora analizziamo il commutatore di prima:

$$
[\hat{x}, \hat{p}] = \hat{x}\hat{p} - \hat{p}\hat{x}
$$

Ora prendiamo una funzione d'onda generica e scriviamo il commutatore applicato a questa funzione:

$$
[\hat{x}, \hat{p}] \psi(x) = \hat{x}\hat{p} \psi(x) - \hat{p}\hat{x} \psi(x)
\\ \ \\
= x (-i \hbar \frac{\partial \psi}{\partial x}) - (-i \hbar \frac{\partial}{\partial x} (x \psi))
\\ \ \\
= -i \hbar ( x \frac{\partial \psi}{\partial x} - x \frac{\partial \psi}{\partial x} - \psi) \quad \text{con regola del prodotto}
\\ \ \\
= -i \hbar \psi
$$

Quindi abbiamo:

$$
[\hat{x}, \hat{p}] = -i \hbar
$$

### 4.1.3 Ritorniamo ai ladder operators

Quindi noi abbiamo:

$$
= \frac{1}{\hbar \omega} \hat{H} - \frac{i}{2\hbar} [\hat{x}, \hat{p}]
\\ \ \\
= \frac{1}{\hbar \omega} \hat{H} - \frac{i}{2\hbar} (-i \hbar)
\\ \ \\
= \frac{1}{\hbar \omega} \hat{H} + \frac{1}{2}
$$

Notiamo che se poi invertiamo invece l'ordine dei ladder operators otteniamo:

$$
\hat{a}_+ \hat{a}_- = \frac{1}{\hbar \omega} \hat{H} - \frac{1}{2}
\\ \ \\
\hat{a}_- \hat{a}_+ = \frac{1}{\hbar \omega} \hat{H} + \frac{1}{2}
$$

Quindi noi possiamo riscrivere la nostra Hamiltoniana come:

$$
\hat{H} = \hbar \omega \left( \hat{a}_- \hat{a}_+ - \frac{1}{2} \right)
\\ \ \\
\hat{H} = \hbar \omega \left( \hat{a}_+ \hat{a}_- + \frac{1}{2} \right)
$$

### 4.1.4 Energies

Quindi noi possiamo scrivere la nostra EQ in genrale come:

$$
\hat{H} \psi(x) = E \psi(x)
$$

Se noi ci mettiamo dentro i ladder operators, otteniamo:

$$
\hbar \omega \left( \hat{a}_+ \hat{a}_- + \frac{1}{2} \right) \psi(x) = E \psi(x)
$$

**Parte intelligente**: facciamo applicare $\hat{a}_+$ a $\psi(x)$, quindi:

$$
\hat{H} (\hat{a}_+ \psi(x))
$$

Quindi ora eseguiamo dei calcoli e vediamo cosa otteniamo:

$$
\hbar \omega \left( \hat{a}_+ \hat{a}_- + \frac{1}{2} \right) \hat{a}_+ \psi(x) =
\\ \ \\
= \hbar \omega \left( \hat{a}_+ \hat{a}_- \hat{a}_+ + \frac{1}{2} \hat{a}_+ \right) \psi(x)
$$

Visto che ho due $\hat{a}_+$ a sinistra, posso raccoglierli a sinistra, quindi ottengo:

$$
\hbar \omega  \hat{a}_+ \left( \hat{a}_+ \hat{a}_- + \frac{1}{2} \right) \psi(x)
\\ \ \\
\hbar \omega  \hat{a}_+ \left( \hat{a}_+ \hat{a}_- - \frac{1}{2} + 1 \right) \psi(x)
\\ \ \\
\hat{a}_+ (\hat{H} + \hbar \omega) \psi(x)
$$

Quindi adesso che ho una Hamiltoniana, posso scrivere:

$$
\hat{a}_+ (E + \hbar \omega) \psi(x) = (E + \hbar \omega) \hat{a}_+ \psi(x)
$$

(Posso muoverlo in quanto adesso è una costante).

Quindi possiamo riscrivere tutto come, partendo dall'inizio:

$$
\hat{H}(\hat{a}_+ \psi) = (E + \hbar \omega) (\hat{a}_+ \psi)
$$

Quindi:
- **Se $\psi$ è una soluzione per l'equazione di Schrödinger, allora $\hat{a}_+ \psi$ è una soluzione per l'equazione di Schrödinger con un'energia maggiore di $\hbar \omega$ rispetto a $\psi$**

Abbiamo le seguenti conseguenze
- *Se $\psi$ è una soluzione, allora $\hat{a}_+ \psi$ è una soluzione*
  - Con un aumento di energia di $\hbar \omega$
- *Se $\psi$ è una soluzione, allora $\hat{a}_- \psi$ è una soluzione*
  - Con un decremento di energia di $\hbar \omega$

Possiamo scrivere un processo del tipo:

$$
... \overset{\hat{a}_+}\leftarrow \psi_{n-2} \overset{\hat{a}_-}\leftarrow \psi_{n-1} \overset{\hat{a}_-}\leftarrow \psi_n \overset{\hat{a}_+}\rightarrow \psi_{n+1} \overset{\hat{a}_+}\rightarrow \psi_{n+2} \overset{\hat{a}_+}\rightarrow ...
$$

Da notare che però da questo processo non possiamo avere energia bassa a piacere, ma c'è un lowerbound al quale possiamo arrivare: se il livello di energia è troppo basso, per esempio è sempre inferiore al'energia potenziale, allora la funzione d'onda curverebbe **sempre** in alto, quindi vorrebbe dire che va ad infinito ai bordi, quindi vuol dire che non è square-integrable (non è più valida).

Quindi impostiamo la seguente condizione:

$$
\hat{a}_- \psi_0 = 0
$$

E questo lo possiamo risolvere! Sappiamo cosa è $\hat{a}_-$, quindi possiamo risolvere per $\psi_0$. La soluzione prende la seguente forma:

$$
\frac{1}{\sqrt{2m\omega \hbar}} \left( \hbar \frac{\partial}{\partial x} + m \omega x \right) \psi_0 = 0
\\ \ \\
\implies
\\ \ \\
\frac{\partial \psi_0}{\partial x} = - \frac{m \omega}{\hbar} x \psi_0
\\ \ \\
\implies
\\ \ \\
\int \frac{d\psi_0}{\psi_0} = - \frac{m \omega}{\hbar} \int x \ dx
\\ \ \\
\ln(\psi_0) = - \frac{m \omega}{2\hbar} x^2 + C
\\ \ \\
\psi_0 = A e^{-\frac{m \omega}{2\hbar} x^2}
$$

Dove la $A$ è una costante di normalizzazione. Il professore ci da il valore di:

$$
A= \left( \frac{m \omega}{\pi \hbar} \right)^{1/4}
$$

Quindi:

$$
\psi_0 = \left( \frac{m \omega}{\pi \hbar} \right)^{1/4} e^{-\frac{m \omega}{2\hbar} x^2}
$$

## 4.2 Sommario ladder operators

- $\hat{a}_+$ e $\hat{a}_-$ sono ladder operators

$$
\hat{a}_+ = \frac{1}{\sqrt{2m\omega \hbar}} (-i \hbar \frac{\partial}{\partial x} + m \omega x)
\\ \ \\
\hat{a}_- = \frac{1}{\sqrt{2m\omega \hbar}} (i \hbar \frac{\partial}{\partial x} + m \omega x)
\\ \ \\
\hat{H} = \hbar \omega \left( \hat{a}_+ \hat{a}_- + \frac{1}{2} \right) = \hbar \omega \left( \hat{a}_- \hat{a}_+ - \frac{1}{2} \right)
$$

E poi abbiamo le seguenti cose (con delle costanti di normalizzazione che non abbiamo derivato nelle spiegazioni ma che nel libro ci sono):

$$
\hat{a}_+ \psi_n = \sqrt{n+1} \psi_{n+1}
\\ \ \\
\hat{a}_- \psi_n = \sqrt{n} \psi_{n-1}
$$

Il position operator per il quantum harmonic oscillator è:

$$
\hat{x} = \sqrt{\frac{\hbar}{2m\omega}} (\hat{a}_+ + \hat{a}_-)
$$

Che, nel linguaggio di costruttori e distruttori (che si introdurrà più avanti), si scrive come:

$$
\hat{x} = \sqrt{\frac{\hbar}{2m\omega}} (\hat{a}^\dagger + \hat{a})
$$

L'onda $\psi_0$ è:

$$
\psi_0 = \left( \frac{m \omega}{\pi \hbar} \right)^{1/4} e^{-\frac{m \omega}{2\hbar} x^2}
\\ \ \\
\hat{a}_- \psi_0 = 0
$$

E abbiamo i seguenti valori per l'energia e per le funzioni d'onda:

$$
\psi_n = \frac{1}{\sqrt{n!}} (\hat{a}_+)^n \psi_0
\\ \ \\
E_n = \hbar \omega \left( n + \frac{1}{2} \right)
$$

### 4.2.1 Esempio

Calcoliamo $\psi_1$:

$$
\psi_1 = \frac{\hat{a}_+ \psi_0}{\sqrt{0+1}}
\\ \ \\
= \frac{1}{\sqrt{1}} \frac{1}{\sqrt{2m\omega \hbar}} (-i \hbar \frac{\partial}{\partial x} + m \omega x) \left( \frac{m \omega}{\pi \hbar} \right)^{1/4} e^{-\frac{m \omega}{2\hbar} x^2}
\\ \ \\
= \frac{1}{\sqrt{2m\omega \hbar}} \left( -i \hbar \frac{\partial}{\partial x} + m \omega x \right) \left( \frac{m \omega}{\pi \hbar} \right)^{1/4} e^{-\frac{m \omega}{2\hbar} x^2}
\\ \ \\
= \frac{1}{\sqrt{2m\omega \hbar}} \left( \frac{m \omega}{\pi \hbar} \right)^{1/4}\left( -i \hbar \left( -\frac{m \omega}{\hbar} x \right) + m \omega x \right) e^{-\frac{m \omega}{2\hbar} x^2}
\\ \ \\
= \frac{1}{\sqrt{2m\omega \hbar}} \left( \frac{m \omega}{\pi \hbar} \right)^{1/4}\left( i m \omega x + m \omega x \right) e^{-\frac{m \omega}{2\hbar} x^2}
\\ \ \\
= \frac{1}{\sqrt{2m\omega \hbar}} \left( \frac{m \omega}{\pi \hbar} \right)^{1/4} 2 m \omega x e^{-\frac{m \omega}{2\hbar} x^2}
\\ \ \\
= \left( \frac{m \omega}{\pi \hbar} \right)^{1/4} \sqrt{\frac{2m \omega}{\hbar}} x e^{-\frac{m \omega}{2\hbar} x^2} = \psi_1
$$

Da qui quindi possiamo trovare tutti i possibili stati stazionari dell'oscillatore armonico.

## 4.3 Harmonic oscillator TISE solutions by power series

Abbiamo in precedenza trovato i risultati usando i ladder operators, usando un po di "intelligenza", ora invece andiamo ad usare un metodo più "bruto".

Power series, ovvero scrivere la funzione d'onda come una serie di potenze, è un modo usato per risolvere anche altre equazioni differenziali, ed è un metodo molto utile.

### 4.3.1 Harmonic oscillator TISE

Riscriviamo un attimo la funzione di Schrödinger per l'oscillatore armonico:

$$
- \frac{\hbar^2}{2m} \frac{\partial^2 \psi}{\partial x^2} + \frac{1}{2} m \omega^2 x^2 \psi = E \psi
$$

Noi vogliamo applicare un cambio di variabili (il modo nel quale lo troviamo è andando a tentativi) che in questo caso è:

$$
x = \sqrt{\frac{\hbar}{m \omega}} \xi
$$

Quindi: andiamo a calcolare come va a cambiare la funzione di Schrödinger usando questo cambio di variabili.

$$
-\frac{\hbar^2}{2m} \frac{\partial^2 \psi(x)}{\partial x^2} + \frac{1}{2} m \omega^2 x^2 \psi(x) = E \psi(x)
\\ \ \\
-\frac{\hbar^2}{2m} \frac{\partial^2 \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)}{\partial x^2} + \frac{1}{2} m \omega^2 \frac{\hbar}{m \omega} \xi^2 \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right) = E \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)
$$

A questo punto si può notare che si potrebbero andare a cambiare determinate cose all'interno della funzione, ma lo lasceremo per più tardi. Ora come ora ci interessa andare a modificare la seconda derivata di $\psi$ rispetto a $x$. Quando noi facciamo questo tipo di operazioni, dobbiamo andare ad applicare la **regola della catena**.

Quindi ciò che succede è, unicamente per la prima parte:

$$
\frac{\partial^2 \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)}{\partial x^2} = \frac{\partial}{\partial x} \left( \frac{\partial \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)}{\partial x} \right)
\\ \ \\
= \frac{\partial}{\partial x} \left( \frac{\partial \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)}{\partial \xi} \frac{\partial \xi}{\partial x} \right)
\\ \ \\
= \frac{\partial}{\partial x} \left( \frac{\partial \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)}{\partial \xi} \sqrt{\frac{m \omega}{\hbar}} \right)
\\ \ \\
= \frac{\partial}{\partial x} \left( \sqrt{\frac{m \omega}{\hbar}} \frac{\partial \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)}{\partial \xi} \right)
$$

A questo punto dobbiamo andare a rieseguire l'operazione (tirando fuori la costante ottenuta un'altra volta):

$$
= \sqrt{\frac{m \omega}{\hbar}} \frac{\partial}{\partial x} \left( \frac{\partial \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)}{\partial \xi} \right)
\\ \ \\
= \sqrt{\frac{m \omega}{\hbar}} \frac{\partial}{\partial \xi} \left( \frac{\partial \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)}{\partial \xi} \right) \frac{\partial \xi}{\partial x}
\\ \ \\
= \sqrt{\frac{m \omega}{\hbar}} \frac{\partial^2 \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)}{\partial \xi^2} \frac{\partial \xi}{\partial x}
\\ \ \\
= \sqrt{\frac{m \omega}{\hbar}} \frac{\partial^2 \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)}{\partial \xi^2} \sqrt{\frac{m \omega}{\hbar}}
\\ \ \\
= \frac{m \omega}{\hbar} \frac{\partial^2 \psi \left(\sqrt{\frac{\hbar}{m \omega}} \xi\right)}{\partial \xi^2}
$$

Adesso andiamo a riscrivere l'intera equazione:

$$
- \frac{\hbar^2}{2m} \frac{m\omega}{\hbar} \frac{\partial^2 \psi}{\partial \xi} + \frac{1}{2} m \omega^2 \frac{\hbar}{m \omega} \xi^2 \psi = E \psi
\\ \ \\
- \frac{\hbar \omega}{2} \frac{\partial^2 \psi}{\partial \xi^2} + \frac{\hbar \omega}{2} \xi^2 \psi = E \psi
\\ \ \\
- \frac{\partial^2 \psi}{\partial \xi^2} + \xi^2 \psi = \frac{2E}{\hbar \omega} \psi
\\ \ \\
\frac{\partial^2 \psi}{\partial \xi^2} = (\xi^2 - \frac{2E}{\hbar \omega}) \psi
$$

E questa cosa si scrive con $K=\frac{2E}{\hbar \omega}$:

$$
\frac{\partial^2 \psi}{\partial \xi^2} = (\xi^2 - K) \psi
$$

### 4.3.2 Soluzioni asintotiche

Andiamo a vedere le soluzioni asintotiche, ovvero per valori di $\xi \gg 1$. In questo caso abbiamo:

$$
\frac{\partial^2 \psi}{\partial \xi^2} = \xi^2 \psi
$$

In quanto la $K$ diventa trascurabile, ooncettualmente.

Quindi otteniamo che la funzione d'onda è circa uguale a:

$$
\psi \approx A e^{-\xi^2/2} + B e^{\xi^2/2}
$$

Anche qua noi lo stiamo scrivendo con un approssimazione, in quanto se eseguiamo la derivata otteniamo:

$$
\frac{\partial^2}{\partial \xi^2} e^{-\xi^2/2} = (\xi^2 - 2) e^{-\xi^2/2}
$$

Ma in quanto abbiamo precedentemente impostato $\xi \gg 1$, allora possiamo trascurare il termine $-2$, quindi riotteniamo la nostra soluzione iniziale.

Tuttavia, a partire da questa soluzione asintotica, possiamo notare che dobbiamo rispettare una condizione affinché la funzione d'onda sia **square integrable**, che ci viene richiesto dalla parte matematica della funzione d'onda.

Quindi, *se vogliamo che la nostra funzione d'onda sia normalizzabile*, dobbiamo avere $B=0$. Quindi abbiamo che:

$$
\psi \approx A e^{-\xi^2/2}
$$

Questo va a 0 per grandi valori di $\xi$, quindi si comporta bene. Tuttavia, cose che vanno a 0 per grandi valori sono difficili da rappresentare con i le serie di potenze, in quanto sono polinomi.

Quindi ciò che vogliamo fare è rimuovere la soluzione asintotica.

### 4.3.3 Rimozione della soluzione asintotica

Quello che vogliamo fare è andare a ottenre una soluzione alla nostra equazione precedente, ovvero:

$$
\frac{\partial^2 \psi}{\partial \xi^2} = (\xi^2 - K) \psi
$$

Dove inseriamo:

$$
\psi(\xi) = h(\xi) e^{-\xi^2/2}
$$

Dove $h(\xi)$ è una funzione che vogliamo determinare, fatta in modo da cercare di andare a rimuovere questo behaviour asintotico nella power series.

Andiamo quindi ad eseguire calcoli calcoli calcoli, ovvero andiamo ad ottenre la seconda derivata di $\psi$:

$$
\frac{\partial \psi}{\partial \xi} = \frac{\partial h}{\partial \xi} e^{-\xi^2/2} - \xi h e^{-\xi^2/2}
\\ \ \\
\frac{\partial^2 \psi}{\partial \xi^2} = \frac{\partial^2 h}{\partial \xi^2} e^{-\xi^2/2} - 2 \xi \frac{\partial h}{\partial \xi} e^{-\xi^2/2} - h e^{-\xi^2/2} + \xi^2 h e^{-\xi^2/2}
$$

A questo punto: possiamo raccogliere $e^{-\xi^2/2}$ 

$$
\frac{\partial^2 \psi}{\partial \xi^2} = e^{-\xi^2/2} \left( \frac{\partial^2 h}{\partial \xi^2} - 2 \xi \frac{\partial h}{\partial \xi} - h + \xi^2 h \right)
$$

Notiamo quindi che abbiamo il termine $e^{-\xi^2/2}$ sia a destra che sinistra, in quanto:

$$
\frac{\partial^2 \psi}{\partial \xi^2} = (\xi^2 - K) \psi
\\ \ \\
\frac{\partial^2 h}{\partial \xi^2} - 2 \xi \frac{\partial h}{\partial \xi} - h + \xi^2 h = (\xi^2 - K) h
$$

Adesso abbiamo la stessa $\xi^2$ sia a destra che sinistra, quindi possiamo semplificare e andiamo ad ottenre:

$$
\frac{\partial^2 h}{\partial \xi^2} - 2 \xi \frac{\partial h}{\partial \xi} + (K-1) h = 0
$$

### 4.3.4 Solution by power series

Adesso andiamo a risolvere la funzione usando una somma di potenze per $\xi$:

$$
h(\xi) = \sum_{j=0}^{\infty} a_j \xi^j
$$

E ora andiamo a calcolare anche la prima ela seconda derivata di questa funzione:

$$
\frac{\partial h}{\partial \xi} = \sum_{j=0}^{\infty} j a_j \xi^{j-1}
\\ \ \\
\frac{\partial^2 h}{\partial \xi^2} = \sum_{j=0}^{\infty}  j (j-1) a_j \xi^{j-2}
$$

Quindi adesso andiamo a sostituire dentro l'equazione che avevamo scritto prima questa $h$:

$$
\sum_{j=0}^{\infty}  j (j-1) a_j \xi^{j-2} - 2 \xi \sum_{j=0}^{\infty} j a_j \xi^{j-1} + (K-1) \sum_{j=0}^{\infty} a_j \xi^j = 0
$$

Quindi otteniamo:

$$
\sum_{j=0}^{\infty}  [(j+2)(j+1)a_{j+2} - 2j a_j + (K+1) a_j] \xi^j = 0
$$

Ora, l'unico modo in questo è uguale a 0, è se tutti i termini a sinistra sono uguali a 0. Quindi dobbiamo trovare le soluzioni di:

$$
(j+2)(j+1)a_{j+2} - 2j a_j + (K+1) a_j = 0
$$

Quindi una soluzione di $a_{j+2}$ è:

$$
a_{j+2} = \frac{2j - (K+1)}{(j+2)(j+1)} a_j
$$

Abbiamo che quindi possiamo calcolare tutte le cose a partire da $a_0$ e $a_1$, ovvero possiamo determinare:
- Con $a_0$: $a_2, a_4, a_6, ...$
- Con $a_1$: $a_3, a_5, a_7, ...$

Abbiamo solo due variabili di cui dobbiamo tener conto (un po come posizione e velocità per trovare la soluzione in fisica classica con le leggi di newton).

Se la power series non termina, allora dobbiamo considerare che: abbiamo che la nostra funzione $h$ è $\approx e^{\xi^2}$, quindi in realtà la nostra funzione d'onda prima definita, ovvero:

$$
\psi(\xi) = h(\xi) e^{-\xi^2/2}
\\ \ \\
= e^{\xi^2} e^{-\xi^2/2}
\\ \ \\
= e^{\xi^2/2}
$$

Quindi in realtà vediamo che non troviamo un risultato soddisfacente: la power series pertanto **deve terminare**, ovvero esiste una potenza di $n$ oltre la quale non va (in base al problema).

Noi abbiamo quindi:

$$
a_{n+2} = 0 = \frac{2n - (K+1)}{(n+2)(n+1)} a_n
$$

Ed abbiamo quindi la condizione sul numeratore, ovvero che:

$$
K = 2n + 1
$$

A partire da questo, abbiamo che dobbiamo avere o $a_0$ o $a_1$ uguali a 0, in quanto se entrambi non fossero diversi da 0, allora la serie divergerebbe.

Quindi questo ci toglie abbastanza gradi di libertà.

Andiamo quindi a capire come avviene la quantizzazione:

Abbiamo $K = 2n + 1$; quindi $K = \frac{2E}{\hbar \omega}$ (come originariamente definito), e quindi abbiamo che $E = \left( n + \frac{1}{2} \right) \hbar \omega$.

Quindi andiamo a scrivere alcune soluzioni di queste cose che abbiamo trovato, dove:
- $h_0$ ci dice "la power series che termina ad $a_0$"
- $a_0$ e $a_1$ saranno i nostri valori iniziali
- $n$ sarà il valore più alto di $n$ che possiamo avere

Quindi per esempio:

$$
a_0 \neq 0, n=0, a_1 = 0
\\
h_0 = a_0 \quad, \quad \psi_0(\xi) = a_0 e^{-\xi^2/2}
\\ \ \\
a_0 = 0, n=1, a_1 \neq 0
\\
h_1 = a_1 \xi \quad, \quad \psi_1(\xi) = a_1 \xi e^{-\xi^2/2}
\\ \ \\
a_0 \neq 0, n=2, a_1 = 0
\\
h_2 = a_0 (1 - 2\xi^2) \quad, \quad \psi_2(\xi) = a_0 (1 - 2\xi^2) e^{-\xi^2/2}
$$

### 4.3.5 Solutions as Hermite polynomials

Abbiamo una serie di polinomi particolari, che hanno attorno a loro sviluppata abbastanza matematica, che possiamo usare per ottenre essenzialmente gli stessi concetti, e sono gli **Hermite polynomials**.

Essi sono:

$$
\begin{align*}
H_0(\xi) &= 1 \\
H_1(\xi) &= 2\xi \\
H_2(\xi) &= 4\xi^2 - 2 \\
H_3(\xi) &= 8\xi^3 - 12\xi \\
H_4(\xi) &= 16\xi^4 - 48\xi^2 + 12 \\
H_5(\xi) &= 32\xi^5 - 160\xi^3 + 120\xi \\
\vdots
\end{align*}
$$

Possiamo usare questi polinomi all'interno della nostra formula ed ottenere:

$$
x = \sqrt{\frac{\hbar}{m \omega}} \xi
\\ \ \\
\psi_n(x) = \left( \frac{m \omega}{\pi \hbar} \right)^{1/4} \frac{1}{\sqrt{2^n n!}} H_n \left( \sqrt{\frac{m \omega}{\hbar}} x \right) e^{-\frac{m \omega}{2\hbar} x^2}
$$

E possiamo ottenere le energie:

$$
E_n = \hbar \omega \left( n + \frac{1}{2} \right)
$$

# 5. Particella libera

Il problema della particella libera considera uno spazio dove non c'è un potenziale, pertanto l'intero spazio è "vuoto".

## 5.1 Free particle TISE

Andiamo a scrivere l'equazione di Schrödinger:

$$
- \frac{\hbar^2}{2m} \frac{\partial^2 \psi}{\partial x^2} + V(x) \psi = E \psi
$$

Tuttavia l'energia potenziale è 0 ovunque, quindi possiamo scrivere:

$$
- \frac{\hbar^2}{2m} \frac{\partial^2 \psi}{\partial x^2} = E \psi
$$

Abbiamo però delle costanti a destra e costanti a sinistra, quindi possiamo scrivere:

$$
\frac{\partial^2 \psi}{\partial x^2} = - \frac{2mE}{\hbar^2} \psi
$$

Scriviamo ora al posto delle costanti una costante al quadrato $k$:

$$
k^2 = \frac{2mE}{\hbar^2} \quad, \quad k = \frac{\sqrt{2mE}}{\hbar}
\\ \ \\
\frac{\partial^2 \psi}{\partial x^2} = - k^2 \psi
$$

La soluzione generale a questo problema è quindi:

$$
\psi = A e^{-ikx} + B e^{ikx}
$$

Scrivendola ora in funzione del tempo, otteniamo:

$$
\psi(x,t) = A e^{-ikx} e^{-i\frac{Et}{\hbar}} + B e^{ikx} e^{-i\frac{Et}{\hbar}}
$$

Questo lo possiamo riscrivere (usando la definizione precedente di $k$) come:

$$
\psi(x,t) = A e^{-ikx} e^{\frac{\hbar k^2}{2m}} + B e^{ikx} e^{\frac{\hbar k^2}{2m}}
\\ \ \\
= A e^{ik (x-\frac{\hbar k}{2m}t)} + B e^{-ik (x+\frac{\hbar k}{2m}t)}
$$

Quindi queste sono le nostre soluzioni alla particella libera.

Sono **traveling waves**. Possiamo pensare ad essere come traveling waves pensando al fatto che sono complex numbers. Se noi pensiamo ad $e^{ikx}$, possiamo immaginare che con il variare di $x$, la particella ruota nel piano complesso. Se invece noi pensiamo a $e^{ik(x-\frac{\hbar k}{2m}t)}$, possiamo pensare al fatto che ruota nel piano complesso con il variare del tempo (ma nella direzione opposta).

![immagine](travellingwaves.png)

All'interno di questa immagine possiamo vedere meglio cosa succede:
- La particella viene rappresentata nell'asse dello spazio come ruotando nel piano complesso.
- Quello che il tempo fa è "spostare" tutto in una certa direzione (frecce sopra)
- Quindi noi possiamo prendere un punto e vedere in che direzione si muove. In questo caso possiamo notare che se prendiamo il punto arancione, esso, con l'aumentare del tempo, si sposterà nella direzione $x+$.
- Ciò che viene descritto è la parte della prima parte della formula dell'onda (quella con normalizzazione A, sottolineata in arancione): per la seconda parte della formula, l'onda della particella si muoverà in senso opposto.

Alcune cose che possiamo considerare sono: con l'aumentare dell'energia, gli stati stazionari della particella libera sono:
- **Velocità**: la velocità della particella libera è proporzionale alla radice dell'energia, quindi all'aumentare dell'energia, la velocità aumenta.
  - **Aumenta**
- **Lunghezza d'onda**: la lunghezza d'onda è inversamente proporzionale al momento (dalla relazione di de Broglie $\lambda = \frac{h}{p}$). All'aumentare dell'energia aumenta il momentum, quindi all'aumentare dell'energia, la lunghezza d'onda diminuisce.
  - **Diminuisce**
- **Frequenza**: la frequenza è proporzionale all'energia (dall'equazione $E = hf$), quindi all'aumentare dell'energia, la frequenza aumenta.
  - **Aumenta**

## 5.2 Boundary conditions? Quantization?

Questo è il punto nel quale inizia ad essere un po' più difficile lavorare con la particella libera.

Visto che $V(x)=0$ ovunque, allora **non ci sono boundaries**.

Questo vuol dire che noi possiamo avere **qualsiasi $k$**, ovvero possiamo avere qualsiasi energia $E$. Quindi **non c'è la quantization**! (Questo è un problema. Non è necessariamente "alla base", ma diventa un problema in quanto è diverso da cosa abbiamo risolto fin'ora, sia per la infinite power well che per l'harmonic oscillator).

## 5.3 Normalizzazione?

Un altro problema nel quale incorriamo è quando cerchiamo di normalizzare la funzione d'onda. Ciò che dovevamo fare era trovare una soluzione tale che:

$$
\int_{-\infty}^{+\infty} \psi^*(x,t) \psi(x,t) dx = 1
$$

Andiamo a provare a calcolarlo usando la formula che abbiamo trovato (consideriamo solo il termine con $A$):

$$
\int_{-\infty}^{+\infty} A^* e^{ik(x-\frac{\hbar k}{2m}t)} A e^{-ik(x-\frac{\hbar k}{2m}t)} dx
\\ \ \\
= |A|^2 \int_{-\infty}^{+\infty} e^{ik(x-\frac{\hbar k}{2m}t)} e^{-ik(x-\frac{\hbar k}{2m}t)} dx
\\ \ \\
= |A|^2 \int_{-\infty}^{+\infty} e^{ik(x-\frac{\hbar k}{2m}t) - ik(x-\frac{\hbar k}{2m}t)} dx
\\ \ \\
= |A|^2 \int_{-\infty}^{+\infty} e^{0} dx
\\ \ \\
= |A|^2 \int_{-\infty}^{+\infty} dx
\\ \ \\
= |A|^2 \left[ x \right]_{-\infty}^{+\infty}
$$

Il problema è che quindi ottiamo $A^* A \cdot \infty$ (e non possiamo impostare $A = \frac{1}{\infty}$), quindi non possiamo normalizzare la funzione d'onda.

## 5.4 Wave packets

Come andiamo quindi a risolvere questa serie di problemi? Una soluzione è quella di usare **wave packets**.

Possiamo comunque scrivere $\psi(x,t=0)$ come la superposizione di un insieme di traveling waves.

Essenzialmente avremo $\psi$ che sarà un onda, formata da parte immaginaria e parte reale, che sarà non zero in un certo range di $x$ (*over a limited domain*). Questa onda normalizzabile dovrà venire ottenuto dalla somma di onde non normalizzabili (da traveling waves).

### 5.3.1 Check of understanding

Dato lo stato stazionario:

$$
\psi(x,t) = Ae^{ik\left(x-\frac{\hbar k}{2m}t\right)}
$$

Rispondere alle seguenti domande:
- L'onda si muove a destra o a sinistra?
  - Per determinare la direzione del movimento, andiamo ad analizzare il termine $-\frac{\hbar k}{2m}t$. Il numero $k$ determina la direzione: se $k$ è positivo, allora l'onda si muove a destra, se è negativo, si muove a sinistra.
  - Ciò che noi dobbiamo vedere: data questa cosa costante, ovvero $=0$, allora se io cambio $t$, $x$ come deve cambiare per mantenere lo stesso valore? in quanto $t$ aumenta, la funzione diminuisce, quindi $x$ deve aumentare. Quindi l'onda si muove a destra.
- Dato lo stato che si estende su tutto lo spazio e include una quantità infinita di wavelength, cosa possiamo dire sull'incertezza della posizione ($\Delta x$) e del momentum ($\Delta p$)?
  - Se l'onda si estende su tutto lo spazio, allora $\Delta x = \infty$.
  - Il momentum è ben definito, in quanto è dato da $p=\hbar k$. In quanto $k$ è definito e non c'è spread (in quanto $k=\frac{\sqrt{2mE}}{\hbar}$, e la nostra energia è ben definita, così come la massa), allora $\Delta p = 0$.
  - Quindi questo ci va a soddisfare il principio di indeterminazione di Heisenberg, in quanto $\Delta x \Delta p \geq \frac{\hbar}{2}$. Anche se in realtà la loro moltiplicazione è indefinita, possiamo interpretarla come rispettante del principio.
- Guardando la forma della definizione di $k= \frac{\sqrt{2mE}}{\hbar}$, derivare la formula per il momentum $p$ in termini di $k$:
  - Iniziamo definendo la formula del momentum, come essere $E=\frac{p^2}{2m}$.
  - Risolviamo per ottenere $p$, quindi $p=\sqrt{2mE}$.
  - Ora possiamo scrivere $k=\frac{p}{\hbar}$, quindi $p=\hbar k$.
  - Questo si allinea con l'ipotesi di Dee Broglie sul momentum proporzionale al numero d'onda e alla costante di Planck.

## 5.5 Wave packets continuation

Quello che vogliamo fare è quindi andare a sommare un insieme di onde che vanno da $-\infty$ a $+\infty$, sia nel dominio temporale che spaziale, per cercare di ottenere qualcosa di normalizzabile. Questo è il concetto di **wave packets**.

### 5.5.1 Cosa è un wave packet

Ciò che ci interessa è che sia $0$ per valori grandi di $x$ (ovvero che tende a $0$ per $x \to \pm \infty$) e che invece sia non zero in un certo range di $x$.

Come andiamo a costruire qualcosa del genere?

Andiamo a ripetere come abbiamo definito la sommatoria per le onde stazionarie per la particella in una scatola / infinite square well:

$$
\psi(x,t) = \sum_{n=1}^{\infty} c_n \psi_n(x) e^{-iE_n t / \hbar}
\\ \ \\
= \sum_{n=1}^{\infty} c_n \sqrt{\frac{2}{a}} \sin \left( \frac{n \pi x}{a} \right) e^{-iE_n t / \hbar}
\\ \ \\
= \sum_{n=1}^{\infty} c_n \sqrt{\frac{2}{a}} \sin \left( \frac{n \pi x}{a} \right) e^{-i \frac{n^2 \pi^2 \hbar t}{2ma^2}}
$$

Questo non funzionerà per la nostra particella libera per una serie di motivi:
- Innzitutto, abbiamo qua una somma discreta, ovvero abbiamo $\psi_n$ diverse con ognuno una propria energia $E_n$. In questo caso però non abbiamo stati quantizzati, ma soluzioni continue. Quindi questi stati stazionari devono avere la sembianza delle nostre travelling waves, ovvero: $e^{ik(x- \frac{\hbar k}{2m} t)}$ (il nostro parametro sarà $k$, che questa volta non è necessario sia un intero)
- Il secondo motivo è la parte a sinistra, ovvero $c_n$, che ora dovrà anch'esso diventare continuo in qualche modo, ovvero dovrà essere una funzione (che scriveremo come $\phi(k)$).
- Infine, non possiamo usare la sommatoria, ma dobbiamo usare un integrale

Quindi, in generale la nostra nuova idea deve essere qualcosa del tipo:

$$
\int_{-\infty}^{+\infty} \phi(k) e^{ik \left(x - \frac{\hbar k}{2m} t\right)} dk
$$

Il problema principale di questa espressione è $\phi(k)$, ovvero come possiamo definire questa funzione?

Come abbiamo fatto a trovare l'analogo di questo (ovvero $c_n$)? Abbiamo usato "Fourier's trick", ovvero abbiamo moltiplicato per $\psi_m^*(x)$ e integrato su tutto lo spazio. (Abbiamo "fatto collassare la sommatoria in un integrale", ma ora non è chiaro cosa vuol dire "far collassare l'integrale")

Rivediamo ora un attimo cosa abbiamo fatto per trovare $c_n$:

$$
\psi(x,t=0) = \sum_{n=1}^{\infty} c_n \sqrt{\frac{2}{a}} \sin \left( \frac{n \pi x}{a} \right)
\\ \ \\
\int_{-\infty}^{+\infty} \psi_m^*(x) \psi(x,t=0) dx = \int_{-\infty}^{+\infty} \psi_m^*(x) \sum_{n=1}^{\infty} c_n \sqrt{\frac{2}{a}} \sin \left( \frac{n \pi x}{a} \right) dx
\\ \ \\
\int_{-\infty}^{+\infty} \sqrt{\frac{2}{a}} \sin \left( \frac{n \pi x}{a} \right) \psi(x,0) dx = \sum_{n=1}^{\infty} c_n \frac{2}{a} \int_{-\infty}^{+\infty} \sin \left( \frac{n \pi x}{a} \right) \sin \left( \frac{m \pi x}{a} \right) dx
\\ \ \\
c_m = \int_{0}^{a} \sqrt{\frac{2}{a}} \sin \left( \frac{m \pi x}{a} \right) \psi(x,0) dx
$$

Andiamo ad eseguire un procedimento analogo per trovare $\phi(k)$:

$$
\psi(x,0) = \int_{-\infty}^{+\infty} \phi(k) e^{ikx} dk
\\ \ \\
\int_{-\infty}^{+\infty} e^{-ik'x} \psi(x,0) dx = \int_{-\infty}^{+\infty} \left( \int_{-\infty}^{+\infty} \phi(k) e^{ikx} dk \right) e^{-ik'x} dx
\\ \ \\
= \int_{-\infty}^{+\infty} \phi(k) \left( \int_{-\infty}^{+\infty} e^{ikx} e^{-ikx} dx \right) dk
\\ \ \\
= \int_{-\infty}^{+\infty} \phi(k) \delta(k-k') dk
\\ \ \\
= \phi(k')
$$

L'ultima cosa che abbiamo fatto è usare la definizione di delta di Dirac, ovvero:

$$
\int_{-\infty}^{+\infty} f(x) \delta(x-x') dx = f(x')
$$

Questo succede in quanto la delta di Dirac è una funzione che è nulla ovunque tranne che in $x=x'$, dove è infinita, e inoltre $\int_{-\infty}^{+\infty} \delta(x-x') dx = 1$. Quindi viene valutata in un unico punto dove è infinito moltiplicato con il valore della funzione, che facendo la media su tutto lo spazio, ci dà il valore della funzione in quel punto. (Intuitivamente)

Quindi abbiamo:

$$
\phi(k) = \int_{-\infty}^{+\infty} e^{-ikx} \psi(x,0) dx
$$

Questo quindi determina $\phi(k)$

### 5.5.2 Fourier transform and the wavefunction

Essenzialmente la Fourier transform è la seguente:

$$
f(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} F(k) e^{ikx} dk
\\ \ \\
F(k) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} f(x) e^{-ikx} dx
$$

Ora, possiamo usare questa conoscenza, data una funzione d'onda $\psi$ oppure la funzione $\phi$, per determinare una o l'altra, visto che abbiamo:

$$
\psi(x,t)= \int_{-\infty}^{+\infty} \phi(k) e^{ik \left(x - \frac{\hbar k}{2m} t\right)} dk
\\ \ \\
\phi(k) = \int_{-\infty}^{+\infty} e^{-ikx} \psi(x,0) dx
$$

#### Esempio proposto

Supponiamo di avere la funzione d'onda seguente:

$$
\psi(x,0) = \begin{cases} 
\frac{1}{\sqrt{2a}} & \text{se } -a \leq x \leq a \\
0 & \text{altrimenti}
\end{cases}
$$

Dobbiamo trovare $\phi(k)$.

Andiamo a calcolare $\phi(k)$:

$$
\phi(k) = \int_{-\infty}^{+\infty} e^{-ikx} \psi(x,0) dx
\\ \ \\
= \int_{-a}^{+a} e^{-ikx} \frac{1}{\sqrt{2a}} dx
\\ \ \\
= \frac{1}{\sqrt{2a}} \int_{-a}^{+a} e^{-ikx} dx
\\ \ \\
= \frac{1}{\sqrt{2a}} \left[ \frac{e^{-ikx}}{-ik} \right]_{-a}^{+a}
\\ \ \\
= \frac{1}{\sqrt{2a}} \left[ \frac{e^{-ika}}{-ik} - \frac{e^{ika}}{-ik} \right]
\\ \ \\
= \frac{1}{\sqrt{2a}} \left[ \frac{e^{-ika} - e^{ika}}{-ik} \right]
\\ \ \\
= \frac{1}{\sqrt{2a}} \left[ \frac{2i \sin(ka)}{-ik} \right]
$$

Ora possiamo semplificare ulteriormente:

$$
\phi(k) = \frac{1}{\sqrt{2a}} \left[ \frac{2i \sin(ka)}{-ik} \right]
\\ \ \\
= \frac{1}{\sqrt{2a}} \left[ \frac{2 \sin(ka)}{-k} \right]
$$

Quindi abbiamo ottenuto la nostra $\phi(k)$.

(Procedimento potrebbe avere dei problemi, non sono sicurissimo dei passaggi, però l'idea generale dovrebbe essere questa).

## 5.6 Wave speed

Andiamo ora a calcolare la velocità delle nostre onde.

Consideriamo quindi un onda del tipo:

$$
\psi(x,t) = e^{i(kx - \frac{\hbar k^2}{2m} t)}
$$

Ora, noi vogliamo sapere come si muove un determinato punto della nostra onda. Quindi dobbiamo fissare che la parte all'esponente sia uguale ad una costante, e vedere come cambia la $x$ al variare di $t$.

Impostiamo per esempio l'esponente uguale a $0$:

$$
kx - \frac{\hbar k^2}{2m} t = 0
$$

Quindi abbiamo che:

$$
x = \frac{\hbar k}{2m} t
$$

Pertanto notiamo che: $t\uparrow \implies x\uparrow\implies$ l'onda si muove a destra.

Quanto in fretta? Notiamo che abbiamo $x = \frac{\hbar k}{2m} t$, quindi $x = vt$, quindi $v = \frac{\hbar k}{2m}$.

Riportando la definizione di $k$, arriviamo a scrivere:

$$
v = \frac{\hbar k}{2m} = \frac{\hbar}{2m} \frac{\sqrt{2mE}}{\hbar} = \frac{1}{2} \sqrt{\frac{2E}{m}} = \frac{1}{2} v_{\text{classical}}
$$

(Dove la velocità classica deriva dall'equazione: $E = \frac{1}{2} m v^2$, ovvero $v= \sqrt{\frac{2E}{m}}$). Notiamo quindi che c'è una discrepanza! Questo vuol dire che la velocità delle nostre onde è diversa da quella classica? Non proprio. Ricordiamo che l'espressione dalla quale siamo partiti non può rappresentare un onda, in quanto non è normalizzabile. Pertanto ci interessa calcolare un wave packet, quindi qualcosa che deriva da una somma di onde, non l'onda singola.

### 5.6.1 Wave packet velocity

Andiamo quindi a fare questa cosa per un wave packet.

Supponiamo di avere il "wave packet" (non propriamente wave packet in quanto comunque non è normalizzabile da quel che ho capito, ma almeno ci aiuta a dimostrare questa cosa):

$$
\psi(x,t) = e^{i(kx - \frac{\hbar k^2}{2m} t)} + e^{i(k'x - \frac{\hbar k'^2}{2m} t)}
$$

Andiamo a definire due cose:

$$
\alpha \equiv \frac{k+k'}{2}x - \frac{\hbar (k^2+k'^2)}{4m} t
\\ \ \\
\Delta \equiv \frac{k-k'}{2}x - \frac{\hbar (k^2-k'^2)}{4m} t
$$

Adesso che abbiamo questi due (che essenzilamente derivano dalla somma e dalla differenza dei due esponenti) possiamo andarea a riscrivere l'espressione dell'onda come:

$$
\psi(x,t) = e^{i(\alpha + \Delta)} + e^{i(\alpha - \Delta)}
\\ \ \\
= e^{i\alpha} e^{i\Delta} + e^{i\alpha} e^{-i\Delta}
\\ \ \\
= e^{i\alpha} (e^{i\Delta} + e^{-i\Delta})
$$

Ora, possiamo andare a scrivere $e^{i\Delta} + e^{-i\Delta}$ come:

$$
e^{i\Delta} + e^{-i\Delta} = 2 \cos(\Delta)
$$

Pertanto la nostra equazione è:

$$
\psi(x,t) = 2 e^{i\alpha} \cos(\Delta)
$$

Andiamo ad impostare la nostra $\Delta = 0$, un po come abbiamo fatto prima impostando la cosa all'esponente a $0$, o comunque ad una costante, senza soffermarci troppo su quale costante sia. Questo corrisponde a fissarci a guardare 1 punto della funzione d'onda, essenzialmente. Otteniamo:

$$
\Delta = 0
\\ \ \\
\frac{k-k'}{2}x - \frac{\hbar (k^2-k'^2)}{4m} t = 0
\\ \ \\
\frac{k-k'}{2}x = \frac{\hbar (k^2-k'^2)}{4m} t
\\ \ \\
\frac{x}{2} = \frac{\hbar (k+k')}{4m} t \quad, \quad k+k' = 2\bar{k}
\\ \ \\
x = \frac{\hbar }{m} \bar{k} \ t
$$

Se noi adesso andiamo a sostituire la $\bar{k}$ (che ricordo essere "la k media" dei due valori) con la definizione di $\bar{k}$, ovvero $\bar{k} = \frac{\sqrt{2mE}}{\hbar}$, otteniamo:

$$
x = \frac{\hbar }{m} \frac{\sqrt{2mE}}{\hbar} \ t
\\ \ \\
x = \sqrt{\frac{2E}{m}} \ t
$$

Che è proprio la velocità classica! Quindi la velocità delle nostre onde (wave packets) è effettivamente la stessa della velocità classica, solo delle singole onde non lo è.

Da notare che è simile a quella classica in quanto non abbiamo una sola energia, ma ne abbiamo 2. Essenzialmente la nostra velocità è "spalmata" in due energie diverse, e più le energie sono diverse e più lo spread della velocità sarà diverso. Quindi ciò che succederà è che anche se è un wave packet, non sarà un wave packet a lungo in quanto si propagherà a diverse velocità (alcune parti si muoveranno più in fretta delle altre).

Da notare graficamente come viene rappresentato $\psi(x,t) = 2 e^{i\alpha} \cos(\Delta)$:
- Abbiamo due cose che vengono moltiplicate tra di loro:
  - Abbiamo che se $k$ e $k'$ sono simili, allora $\Delta$ si andrà ad evolvere m\olto lentamente, quindi avremo un coseno che varia molto lentamente. Sarà un "envelope" con il quale si moltiplicherà la prima cosa che sale e scende lentamente.
  - D'altro canto, $\alpha$ sarà grande.
  - Quindi il risultato finale sarà un onda che ha amplitudo modificato da un coseno, che varia molto lentamente, con all'interno una frequenza molto alta. Questo è graficamente rappresentato come segue:

![immagine](wavepacket.png)

(Le frecce ci danno la direzione di movimento se $k > 0$)

Il wave packet si muove nel seguente modo:

![immagine](wavemovementpacket.png)

Notiamo che essenzialmente il wavepacket si muove seguendo le linee nere, mentre le "feature" del wave packet si muovono seguendo le linee grigie, quindi più lentamente.

Questa è una proprietà di molte onde, non tutte, per esempio quelle del suono non lo anno, però se si guarda quello che succede all'acqua quando si lancia un sasso, quelle onde hanno i ripples che si muovono più in fretta del wave packet stesso.

Essenzialmente le due parti sono:
- Group velocity, che è la velocità con la quale si muove il wave packet
- Phase velocity, che è la velocità con la quale si muove la singola onda

## 5.7 Free particle wave packet example

Le condizioni iniziali sono le seguenti:

$$
\psi(x,0) = \sqrt{\frac{3}{2a}} 
\begin{cases}
\frac{a+x}{a} & \text{se } -a \leq x \leq 0 \\
\frac{a-x}{a} & \text{se } 0 \leq x \leq a \\
0 & \text{altrimenti}
\end{cases}
$$

Andiamo ad esprimere questa funzione come una somma di onde stazionarie:

$$
\phi(k) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} e^{-ikx} \psi(x,0) dx
\\ \ \\
= \frac{1}{\sqrt{2\pi}} \int_{-a}^{0} e^{-ikx} \sqrt{\frac{3}{2a}} \frac{a+x}{a} dx + \frac{1}{\sqrt{2\pi}} \int_{0}^{a} e^{-ikx} \sqrt{\frac{3}{2a}} \frac{a-x}{a} dx
\\ \ \\
= \frac{1}{\sqrt{2\pi}} \sqrt{\frac{3}{2a}} \left[ \int_{-a}^{0} e^{-ikx} \frac{a+x}{a} dx + \int_{0}^{a} e^{-ikx} \frac{a-x}{a} dx \right]
$$

Saltiamo i passaggi algebrici: comunque tutto si condensa ad integrare o $e^{-ikx}$ oppure $xe^{-ikx}$, quindi si può fare per parti. Alla fine si ottiene:

$$
\phi(k) \sim \frac{sin^2(x)}{x^2}
$$

Non andiamo a scandire per bene tutte le cose, ci basta sapere che questa è l'idea.

Quello che otteniamo graficamente sarà quindi:

![immagine](wavepacketexample.png)

Ora che sappiamo $\phi(k)$, possiamo andare a scrivere la nostra $\psi(x,t)$:

$$
\psi(x,t) = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \phi(k) e^{i(kx - \frac{\hbar k^2}{2m} t)} dk
$$

Andiamo a scrivere la $\psi(x,t)$:

$$
\psi(x,t) = \frac{1}{2\pi} \int_{-\infty}^{+\infty} \frac{sin^2(x)}{x^2} e^{i(kx - \frac{\hbar k^2}{2m} t)} dk
$$

Il professore non va a risolvere questo integrale, ma lo va a mostrare da un punto di vista grafico. Ci viene mostrato quindi sia la funzione d'onda che la densità di probabilità e come essi si evolvono nel tempo a [questo link](https://youtu.be/k8sDC2juOdY?si=KJo_zm57NuCWW1-q&t=400).

Essenzialmente la probabilità si allarga nel tempo tempo e la funzione d'onda si "dilaga" nel tempo.

Alcune domande:
- Cosa ci dice il fatto che $\phi(k) = \phi(-k)$?
  - In quanto il momento è related a $k$ da $p = \hbar k$, abbiamo che una simmetria da $k$ a $-k$ ci suggerisce che la particella non ha una direzione preferita di movimento, bensì coincide con una "standing wave", in quanto non predilige il movimento ne a sinistra ne a destra.
- Con l'aumento del tempo, la funzione d'onda si "spalma" nello spazio. La rappresentazione del momento di $\phi(k)$ si spalma anch'essa con il passare del tempo?
  - No, in quanto con l'aumento dell'incertezza della posizione, l'incertezza del momento diminuisce. Quindi il momento non si spalma, ma diventa sempre più definito.

# 6. Dirac delta function

Innanzitutto andiamo a definire la delta di Dirac come il limite che tende a $\sigma \to 0$ di:

$$
\delta(x) = \lim_{\sigma \to 0} \frac{1}{\sqrt{2\pi} \sigma} e^{-\frac{x^2}{2\sigma^2}}
$$

Ovvero di una gaussiana con $\sigma$ che tende a $0$, ovvero, da un punto di vista grafico, abbiamo che la gaussiana si "stringe" sempre più, e la sua area rimane sempre unitaria.

Il risultato finale sarà un "picco" infinitamente alto e infinitamente stretto, con un'area unitaria. Pertanto abbiamo questa ""definizione"":

$$
\delta(x) = \begin{cases}
\infty & \text{se } x = 0 \\
0 & \text{se } x \neq 0
\end{cases}
$$

Non è matematicamente molto corretta, però è una buona rappresentazione intuitiva.

## 6.1 Delta function integral

La **prima proprietà** che abbiamo è che:

$$
\int_{-\infty}^{+\infty} \delta(x) dx = 1
$$

**Seconda proprietà**: se noi valutiamo un integrale da meno infinito a più infinito della delta di Dirac moltiplicata ad una funzione, otteniamo:

$$
\int_{-\infty}^{+\infty} \delta(x) f(x) dx = f(0)
$$

- Deriva dal fatto che la delta di Dirac è nulla ovunque tranne che in $x=0$, quindi l'integrale sarà uguale a $f(0)$, in quanto diventa l'unico valore che ci interessa, in un certo senso, cioè ci focalizziamo su quel valore ecco.

**Terza proprietà**:

$$
\int_{-\infty}^{+\infty} \delta(x-a) f(x) dx = f(a)
$$

**Quarta proprietà**: valutare la delta di Dirac usando una funzione:

$$
\delta(f(x)) = \sum_i \frac{1}{|f'(x_i)|} \delta(x-x_i) \quad, \quad \text{dove } f(x_i) = 0, \forall i
$$

Ovvero:
- Praticamente ci possiamo immaginare che la funzione $f(x)$ attraversi l'asse delle $x$ nei punti $x_i$, e in questi punti la delta di Dirac sarà quindi nulla, pertanto dobbiamo valutare la funzione in questi punti.
- Ogni punto però avrà una diversa pendenza con la quale arriva a $0$, quindi dobbiamo usare questa informazione in quanto se la pendenza è molto ripida, allora la delta di Dirac sarà molto alta, e viceversa: la pendenza della funzione dentro la delta di Dirac influenza "quanta delta di Dirac" ci sarà in quel punto.
- Questo è dato da un ragionamento con gli infinitesimi, che si può vedere meglio [qui](https://youtu.be/1pr1kLCHymc?si=_d7vxwHIu4kYnjVw&t=841).

Questo si traduce nella seguente formula:

$$
\int_{-\infty}^{+\infty} \delta(g(x)) f(x) dx = \sum_i \frac{1}{|g'(x_i)|} f(x_i) \quad, \quad \text{dove } g(x_i) = 0, \forall i
$$

### 6.1.1 Esempio 1

Andiamo quindi a fare un esempio:

$$
\delta(ax- bx^2) = \delta (ax(1-\frac{b}{a}x))
$$


Le due soluzioni sono $x_1=0$ e $x_2=\frac{a}{b}$.

Le due derivate saranno quindi:

$$
g'(x_1) = a \quad, \quad g'(x_2) = a - 2bx = a - 2\frac{a}{b}b = -a
$$

Quindi il nostro risultato sarà:

$$
\delta(ax- bx^2) = \frac{\delta(x)}{|a|} + \frac{\delta(x-\frac{a}{b})}{|-a|}
$$

### 6.1.1 Esempio 2

Facciamo un altro esempio andando a calcolare un integrale:

$$
\int_{-\infty}^{+\infty} \delta(x^3 - x) e^{-x} dx
$$

Abbiamo che $g(x) = x^3 - x$, quindi dobbiamo trovare i punti in cui $g(x) = 0$:

$$
g(x) = x(x^2 - 1) = x(x+1)(x-1)
$$

Quindi: $x_1=0$, $x_2=-1$, $x_3=1$.

La derivata sarà:

$$
g'(x) = 3x^2 - 1
$$

Quindi possiamo scrivere $\delta$ come:

$$
\delta(x^3 - x) = \frac{\delta(x)}{|g'(x_1)|} + \frac{\delta(x+1)}{|g'(x_2)|} + \frac{\delta(x-1)}{|g'(x_3)|}
\\ \ \\
= \frac{\delta(x)}{1} + \frac{\delta(x+1)}{2} + \frac{\delta(x-1)}{2}
$$

Quindi abbiamo l'integrale che sarà:

$$
\int_{-\infty}^{+\infty} \delta(x^3 - x) e^{-x} dx = e^0 + \frac{e^{-1}}{2} + \frac{e^{1}}{2} = \frac{e^{-1} + e^{1} + 2}{2}
$$

## 6.2 Delta function derivates

La delta di Dirac ha delle proprietà interessanti anche con le derivate:

$$
\int_{-\infty}^{+\infty} \frac{d \delta(x)}{dx} f(x) dx = -f'(0)
$$

Questo deriva dalla derivazione per parti seguente:

$$
\int_{-\infty}^{+\infty} \frac{d \delta(x)}{dx} f(x) dx = \left[ \delta(x) f(x) \right]_{-\infty}^{+\infty} - \int_{-\infty}^{+\infty} \delta(x) f'(x) dx
$$

Dove il primo membro è 0 ($\delta$ è 0 per ogni punto diverso da 0, noi lì lo stiamo valutando a infinito) e il secondo membro è $-f'(0)$.

## 6.3 Delta function ricollegato alle trasformate di Fourier

Avevamo le due formule che ci erano state date prima che sono:

$$
F(k) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} f(x) e^{-ikx} dx
\\ \ \\
f(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} F(k) e^{ikx} dk
$$

Andiamo ad impostare come $f(x) = \delta(x-x_0)$ e vediamo se riusciamo a riottenere la formula della delta di Dirac:

$$
f(x) = \delta(x-x_0)
\\ \ \\
\frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} \delta(x-x_0) e^{ikx} dx
\\ \ \\
= \frac{1}{\sqrt{2\pi}} e^{ikx_0}
$$

A questo punto andiamo ad inserire il nostro risultato dentro la seconda formula:

$$
\delta(x-x_0) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{+\infty} \frac{1}{\sqrt{2\pi}} e^{ikx_0} e^{ikx} dk
\\ \ \\
= \frac{1}{2\pi} \int_{-\infty}^{+\infty} e^{ik(x-x_0)} dk
$$

Essenzialmente ora notiamo che noi stiamo valutando questa funzione che:
- Quando $x_0 = x$, abbiamo che la funzione è 1, quindi noi integriamo una funzione da $-\infty$ a $+\infty$ che vale una costante, che quindi sarà $\infty$.
- Invece quando $x_0 \neq x$ sarà una sinusoide che va su e giù all'infinito. Dare un valore a questa funzione ci può sembrare complesso, e difatti lo è, però notiamo che se assume proprio valore 0 ritorniamo a definire la nostra delta di Dirac.

Quindi otteniamo:

$$
\delta(x-x_0) = \begin{cases}
\infty & \text{se } x = x_0 \\
0 & \text{se } x \neq x_0
\end{cases}
$$

Proprio come precedentemente definita.

# 7. Boundary conditions, bound states, scattering states and tunneling

## 7.1 Bound states

![classica](classicalpotential.png)

Andiamo a vedere da questa immagine come si comporterebbe qualcosa nel mondo classico: se si trova da una parte o dall'altra del potenziale, in base alla sua quantità di energia iniziale, potrà o meno superare il potenziale.

Nel caso a sinistra avrà più potenziali stati dove si può trovare (tipo delle conche), nel caso di sinistra, se l'energia iniziale è troppo bassa, non riuscirà ad attraversare il dosso.

In generale comunque, l'energia totale non può essere più bassa dell'energia potenziale.

![quantum](quantumpotential.png)

In base all'energia totale per un corpo che segue la meccanica quantistica, possiamo avere fenomeni chiamati di "tunneling" dove si va ad attraversare una barriera che in base alla meccanica classica non si potrebbe attraversare.

Questo comportamento lo possiamo intuire graficamente (come si vede nei grafici), usando le intuizioni che abbiamo su come la curvatura della funzione d'onda è in base all'energia vs il potenziale.

Una cosa che tuttavia ci rimane impossibile è avere un sistema che ha un'energia minore dell'energia potenziale. Questa legge è comunque rispettata dalla MQ.

![boundstate](scatteringandbounded.png)

Andiamo quindi a definire due possibili stati:
- **Bound states**: sono sistemi che sono confinati da energia potenziale, e che sono quantizzati e normalizzabili.
- **Scattering states**: sono stati che non sono confinati da energia potenziale, e che non sono quantizzati (hanno uno "spettro continuo") e non sono normalizzabili. Si estendono all'infinito. All'interno di scattering states possiamo avere anche stati bounded, o che comunque si trovano in dei confini, come visto nell'immagine sopra.

## 7.2 Boundary conditions in the time indipendent Schrödinger equation

Essenzialmente in questa lezione andiamo a vedere meglio come possono essere definite le funzioni d'onda e come si possono definire le condizioni al contorno.

Per le funzioni d'onda:
- Non possiamo avere discontinuità nella funzione d'onda
  - La derivata seconda darebbe problemi e ci uscirebbe un potenziale infinito
  - Questo corrisponde ad avere un salto nella funzione d'onda (dove in uno spazio infinitamente piccolo si passa da un valore ad un altro, tipo una scaletta)
- Non possiamo avere discontinuità nella prima derivata della funzione d'onda
  - A meno che il potenziale non tenda ad infinito
  - Questo corrisponde a non poter avere una cosa a forma di piramide come funzione d'onda (sempre a meno che il potenziale non tenda ad infinito)

Cosa possiamo dire invece se abbiamo due regioni di spazio tali che:
- **Regione 1**:
  - Soluzione a $\psi_1(x)$
  - $\psi_1(x)$ è continua
  - $\psi_1'(x)$ è continua
- **Regione 2**:
  - Soluzione a $\psi_2(x)$
  - $\psi_2(x)$ è continua
  - $\psi_2'(x)$ è continua

Cosa deve succedere al bordo?
- $\psi_1(x) = \psi_2(x)$
- $\psi_1'(x) = \psi_2'(x)$
  - A meno che il potenziale non sia infinito al bordo

Quindi $\psi$ e $\frac{d \psi}{d x}$ devono essere continue al boundary.

![boundary](boundarystatespotentialexample.png)

In questo esempio invece vediamo che il potenziale può invece avere step, e le soluzioni assumono prima dello step, dove l'energia è più alta del potenziale, una forma di onda ($B \sin (x+\phi)$, dove B è un coefficiente di normalizzazione e $\phi$ è una fase), mentre dopo lo step, dove l'energia è minore del potenziale, assumono una forma esponenziale ($A e^{-x}$. Queste due funzioni avranno quindi alcuni gradi di libertà per essere "matchate" da una parte all'altra nel boundary.

# 8. Delta function potential TISE

Il problema in questione ha una funzione del potenziale che è:

$$
V(x) = -\alpha \delta(x)
$$

Dove $\alpha$ è una costante che ci dice quanto è forte il potenziale.

Abbiamo essenzialmente due possibili casi, dato questo potenziale:
- O la particella ha energia inferiore a 0 ($E < 0$) e quindi è confinata (si tratta di una soluzione ad un problema bounded, che quindi sarà quantizzato e normalizzabile)
- O la particella ha energia superiore a 0 ($E > 0$) e quindi è libera (si tratta di una soluzione ad un problema scattering, che quindi non sarà quantizzato e non sarà normalizzabile)

Da notare inoltre:
- Se $\alpha > 0$, allora il potenziale è attrattivo (ovvero c'è un "infinite well potential" al centro)
- Se $\alpha < 0$, allora il potenziale è repulsivo (ovvero c'è un "infinite barrier potential" al centro)
- si tratta quindi di un dip o di un peak di potenziale infinito e con width "0".

## 8.1 Bounded solution

La nostra EQ di Schrödinger sarà:

$$
-\frac{\hbar^2}{2m} \frac{d^2 \psi}{dx^2} - \alpha \delta(x) \psi = E \psi
$$

In tutti i punti diversi da $x=0$, quindi con $V(x)=0$, abbiamo la seguente formula:

$$
\partial_x^2 \psi = k^2 \psi \quad, \quad k = \frac{\sqrt{-2mE}}{\hbar} \quad \text{quindi E < 0 per avere } k \in \mathbb{R}
\\ \ \\
\psi(x) = A e^{-kx} + B e^{kx}
$$

Quindi abbiamo che:

$$
x < 0 \implies A = 0 \implies \psi_1(x)= B e^{kx}
\\ \ \\
x > 0 \implies B = 0 \implies \psi_2(x) = A e^{-kx}
$$

Ora abbiamo due regioni diverse, per capire come si comporta al boundary andiamo a fare dei calcoli per rendere la funzione d'onda continua:

$$
\psi_1(0) = \psi_2(0)
\\ \ \\
B e^{kx} |_{x=0} = A e^{-kx} |_{x=0}
\\ \ \\
B = A
$$

La seconda boundary condition è vedere se la derivata è continua. Tuttavia, in quanto abbiamo potenziale inifito,non è da controllare veramente, può anche non essere continua.

Capiamo tuttavia cosa succede alla derivata nel boundary.

Quello che faremo sarà prendere la funzione di Schrödinger e integrare da $-\epsilon$ a $+\epsilon$ e vedere cosa succede al limite per $\epsilon \to 0$.

$$
\int_{-\epsilon}^{+\epsilon} \left( -\frac{\hbar^2}{2m} \frac{d^2 \psi}{dx^2} - \alpha \delta(x) \psi \right) dx = \int_{-\epsilon}^{+\epsilon} E \psi dx = \int_{-\epsilon}^{+\epsilon} E \psi dx
\\ \ \\
- \frac{\hbar^2}{2m} \left[ \frac{d \psi}{dx} \right]_{-\epsilon}^{+\epsilon} - \alpha \psi(0) = E \int_{-\epsilon}^{+\epsilon} \psi dx
$$

I passaggi sono piuttosto intuitivi:
- La delta di Dirac ci permette di "estrarre" il valore della funzione in 0
- L'integrale con $\epsilon$ che tende a 0 è 0.

Quindi il risultato finale sarà il seguente:

$$
- \frac{\hbar^2}{2m} \left[ \frac{d \psi}{dx} \right]_{-\epsilon}^{+\epsilon} - \alpha \psi(0) = 0
\\ \ \\
\frac{d\psi}{dx}|^{\epsilon}_{\epsilon} = - \frac{2m \alpha}{\hbar^2} \psi(0)
$$

Quindi abbiamo:

$$
\frac{d\psi_1}{dx} = Bk \psi_1 \quad, \quad \frac{d\psi_2}{dx} = -Ak \psi_2
$$

Da notare che però $B = A$, quindi possiamo anche scriverli con la stessa cosa. Quindi andiamo a valutare la derivata al boundary:

$$
-Bk -Bk = - \frac{2m \alpha}{\hbar^2} B
\\ \ \\
-2k = - \frac{2m \alpha}{\hbar^2}
$$

Ora, risolvendo per l'energia, abbiamo:

$$
E = - \frac{ma^2}{2\hbar^2}
$$

Che sarà quindi un energia quantizzata.

Adesso possiamo riscrivere la funzione d'onda come:

$$
\psi(x) = B \begin{cases}
e^{\frac{ma}{\hbar^2} x} & \text{se } x < 0 \\
e^{-\frac{ma}{\hbar^2} x} & \text{se } x > 0
\end{cases}
$$

Quindi le soluzioni saranno le seguenti:

![ns](normalizedboundstatessolution.png)

Alcune domande per capire meglio:
- Perché c'è solo 1 bound state?
  - Deriva dalla matematica
  - Esiste 1 solo stato: il ground state
  - La quantità di stati dipende dalla quantità di spazio disponibile (?)
- Posso esprimere le condizioni iniziali come la superposition di bound state solutions?
  - No
  - Visto che c'è un unico bound state, non possiamo esprimere le condizioni iniziali come superposition di bound state solutions, in quanto non ce ne sono più di 1.

## 8.2 Scattering states

Abbiamo adesso un energia che è maggiore di 0, ovvero $E > 0$.

Andiamo quindi a riscrivere l'equazione di Schrödinger:


$$
-\frac{\hbar^2}{2m} \frac{d^2 \psi}{dx^2} - \alpha \delta(x) \psi = E \psi
$$

Ricontrolliamo di nuovo per il potenziale 0, quindi lontano da $x=0$:

$$
\partial_x^2 \psi = - k^2 \psi \quad, \quad k = \frac{\sqrt{2mE}}{\hbar} \quad \text{quindi E > 0 per avere } k \in \mathbb{R}
$$

Queste saranno due onde (sinusoidali).

E quinidi le due funzioni d'onda nei due lati del boundary saranno:

$$
\psi_1(x) = A e^{ikx} + B e^{-ikx} \quad x < 0
\\ \ \\
\psi_2(x) = F e^{ikx} + G e^{-ikx} \quad x > 0
$$

Ci viene quindi data la prima boundary condition che è:

$$
\psi_1(0) = \psi_2(0)
\\ \ \\
A + B = F + G
$$

Adesso andiamo a calcolare anche la seconda boundary condition:

$$
\frac{d\psi_1}{dx} = ikA e^{ikx} - ikB e^{-ikx} \quad x < 0
\\ \ \\
\frac{d\psi_2}{dx} = ikF e^{ikx} - ikG e^{-ikx} \quad x > 0
$$

Adesso riutilizziamo il metodo dell'ultima volta, dove andiamo ad integrare l'equazione di Schrödinger da $-\epsilon$ a $+\epsilon$ e vediamo cosa succede al limite per $\epsilon \to 0$.

$$
\int_{-\epsilon}^{+\epsilon} \left( -\frac{\hbar^2}{2m} \frac{d^2 \psi}{dx^2} - \alpha \delta(x) \psi \right) dx = \int_{-\epsilon}^{+\epsilon} E \psi dx = \int_{-\epsilon}^{+\epsilon} E \psi dx
\\ \ \\
- \frac{\hbar^2}{2m} \left[ \frac{d \psi}{dx} \right]_{-\epsilon}^{+\epsilon} - \alpha \psi(0) = E \int_{-\epsilon}^{+\epsilon} \psi dx
\\ \ \\
\frac{d\psi}{dx}|^{\epsilon}_{\epsilon} = - \frac{2m \alpha}{\hbar^2} \psi(0)
$$

Adesso andiamo a valutare le due derivate a $x=0$:

$$
\frac{d\psi_1}{dx} |_0= ik (A-B)
\\ \ \\
\frac{d\psi_2}{dx} |_0 = ik (F-G)
$$

Scriviamo di nuovo l'equazione (valutando anche la parte a destra, quindi $\psi(0)$. Dobbiamo scegliere una delle due $\psi$, no sceglieremo la $\psi_1$):

$$
ik (A-B) - ik (F-G) = - \frac{2m \alpha}{\hbar^2} (A+B)
$$

Definiamo $\beta = \frac{ma}{\hbar^2 K}$, e quindi possiamo scrivere:

$$
F - G = A (1 + 2i\beta) - B( 1- 2i\beta)
$$

Quindi adesso abbiamo le seguenti 2 equazioni e 4 cose che non conosciamo:

$$
\psi_1(x) = A e^{ikx} + B e^{-ikx} \quad x < 0
\\ \ \\
\psi_2(x) = F e^{ikx} + G e^{-ikx} \quad x > 0
\\ \ \\
A + B = F + G
\\ \ \\
F - G = A (1 + 2i\beta) - B( 1- 2i\beta)
$$

Possiamo andare ad interpretare meglio cosa vogliono dire le varie cose:
- $A$ ci indica un onda di amplitudo $A$ che va verso il boundary, mentre $B$ ci indica un onda che va via dal boundary
- Al contempo, $F$ ci indica un onda che si allontana dal boundary, mentre $G$ ci indica un onda che va verso il boundary

Quello che possiamo fare è andare ad impostare alcune condizioni iniziali, in modo da non dover risolvere tutto il sistema di equazioni.

Per esempio, **siano le nostre condizioni iniziali** lo "scattering da sinistra", allora le onde che vanno verso il boundary da destra, ovvero quelle modulate da $G$, non ci sono. Abbiamo quindi $G=0$, mentre $A$ è un valore impostato da noi (in base al nostro esperimento). Ciò che rimane sarà $F$ e $B$ che rappresentano le onde che vengono trasmesse e quelle riflesse, rispettivamente, dal boundary. Quindi adesso possiamo calcolare $B$ ed $F$ in termini di $A$:

$$
B = \frac{i\beta}{1+i\beta} A
\\ \ \\
F = \frac{1}{1-i\beta} A
$$

Adesso possiamo calcolare il coefficiente di riflessione, usando $B$, e quello di trasmissione, usando $F$:

$$
R \equiv \frac{|B|^2}{|A|^2} = \frac{\beta^2}{1+\beta^2}
\\ \ \\
T \equiv \frac{|F|^2}{|A|^2} = \frac{1}{1+\beta^2}
$$

Da notare che quindi la somma di questi due è 1:

$$
R + T = 1
$$

Espandendo $\beta$ e $k$, abbiamo:

$$
\beta \equiv \frac{ma}{\hbar^2 k} \quad, \quad k = \frac{\sqrt{2mE}}{\hbar}
$$

Otteniamo:

$$
R = \frac{1}{1+ \frac{2\hbar^2 E}{ma^2}}
\\ \ \\
T = \frac{1}{1+ \frac{ma^2}{2\hbar^2 E}}
$$

### 8.2.1 Cosa succede se abbiamo una barriera al posto di una buca?

Allora notiamo che visto che abbiamo:

$$
R = \frac{1}{1+ \frac{2\hbar^2 E}{ma^2}}
\\ \ \\
T = \frac{1}{1+ \frac{ma^2}{2\hbar^2 E}}
$$

E in questo si usa per entrambe $a^2$, allora il segno di $a$, che determina se è una buca o una barriera, non modifica i valori di $R$ e $T$.

Quindi:
- **Classicamente**
  - $a > 0$ (c'è una buca): $T=1$, $R=0$
  - $a < 0$ (c'è una barriera): $T=0$, $R=1$
  - Quindi si trasmette sempre se c'è una buca, non riflette mai e viceversa se c'è una barriera
- **Quantisticamente**
  - Il comportamento della particella rimane identico, sia che sia una buca che una barriera
  - Questo è il fenomeno del tunneling

In questo caso:
- Si può rappresentare come somma di più onde, in quanto è un fenomeno quantistico
  - A differenza della bound solution dove c'è 1 sola bound state, qua abbiamo più soluzioni che possono essere sommate
- Non è possibile avere un bound state nel caso di una delta barrier

# 9. Finite square well

Si tratta di un problema simile all'infinite square well, ma con un potenziale che è finito e non infinito ai bordi.

Il problema è impostato come segue:
- In una regione, da $-a$ a $a$, il potenziale è $-V_0$
- Nelle regioni $x < -a$ e $x > a$, il potenziale è 0

## 9.1 Bounded state solution

Vediamo innanzitutto qual'è la soluzione per uno stato la cui energia non supera quella del potenziale in tutti i punti, ma solo in una regione.

Abbiamo quindi 3 regioni: una sinistra, una al centro e una a destra, rispetto alla regione dove c'è il potenziale.

Vediamo quindi ogni regione in parte, ripartendo dall'EQ di Schrödinger.

**Regione dove $x < -a$**:
- $E < V$ - per come è impostato il problema
- $\partial_{xx} \psi = k^2 \psi$
  - Dove $k$ è $\frac{\sqrt{-2mE}}{\hbar}$
  - Abbiamo che $E < 0$, quindi $k$ sarà un valore reale e positivo.
  - La derivata parziale di $\psi$ deve essere positiva, come visto in precedenza.
- Abbiamo già visto funzioni così, la soluzione sarà $\psi(x) = A e^{-kx} + B e^{kx}$
- Dobbiamo normalizzare questa funzione (in quanto è una bound state solution), quindi $A = 0$, in quanto sennò andrebbe ad infinito per grandi valori di $x$.
- Il risultato sarà quindi:
  - $\psi_1(x) = B e^{kx}$

**Regione dove $-a < x < a$**:
- $E > V$
- $V(x) = -V_{0}$ in questa regione di spazio
- $\partial_{xx} \psi = -l^2 \psi$
  - $l^2 = (E + V_0) \frac{2m}{\hbar^2}$
  - La derivata parziale di $\psi$ deve essere positiva, come visto in precedenza.
- Anche qua sappiamo risolvere ed abbiamo:
  - $\psi_2(x) = C \sin(lx) + D \cos(lx)$

**Regione dove $x > a$**:
- $E < V$
- $\partial_{xx} \psi = k^2 \psi$
- $\psi_3(x) = F e^{-kx} + G e^{kx}$
  - Ma abbiamo che, affinché la funzione sia normalizzabile, $G = 0$
- Il risultato sarà quindi:
  - $\psi_3(x) = F e^{-kx}$

A questo punto abbiamo 5 unknowns:
- $A, C, D, F, k$

### 9.1.1 Even solutions

A questo punto consideriamo le soluzioni pari, ovvero quelle che sono simmetriche rispetto all'origine.

Quindi, data la nostra funzione d'onda, sappiamo che il coefficiente $C$ sarà 0, in quanto se non lo fosse non sarebbe simmetrica.

Inoltre abbiamo un'altra condizione, ovvero se la soluzione è pari, allora dobbiamo avere che $\psi_1$ e $\psi_3$ sono uguali, in quanto simmetriche, quindi $B = F$.

Adesso che abbiamo deciso questo, possiamo iniziare ad usare le nostre 2 boundary conditions: $\psi$ e $\frac{d \psi}{dx}$ sono continue.

Quindi, per $\psi$ continua, abbiamo:

$$
Fe^{-ka} = D\cos(la)
$$

Per la seconda boundary condition, abbiamo:

$$
-kFe^{-ka} = -lD \sin(la)
\\ \ \\
-k = -l \tan (la)
$$

E ricordiamo che $k = \sqrt{\frac{2mE}{\hbar^2}}$ e $l = \sqrt{\frac{2m(E+V_0)}{\hbar^2}}$.

Andiamo quindi a scrivere una serie di equazioni che ci aiuteranno successivamente con i calcoli:

$$
k^2 = -\frac{2mE}{\hbar^2}
\\ \ \\
l^2 = \frac{2m}{\hbar^2} (E + V_0)
\\ \ \\
\frac{k}{l} = \tan(la)
\\ \ \\
z \equiv la
\\ \ \\
z^2 = \frac{2ma^2}{\hbar^2} (E + V_0)
\\ \ \\
\frac{k}{l} = \sqrt{\frac{-2mE / \hbar^2} {z^2 / a^2}} = \sqrt{\frac{z_0^2}{z^2}-1} \quad,\quad z_0^2 = \frac{2ma^2V_0}{\hbar^2}
$$

E quindi otteniamo:

$$
\tan (z) = \sqrt{\frac{z_0^2}{z^2}-1}
$$

### 9.1.2 Odd solutions

Essenzialmente possiamo ripercorrere gli stessi passaggi che abbiamo eseguito prima per ottenere le soluzioni dispari.

Il risultato finale sarà:

$$
k = -l \cot (la)
$$

### 9.1.3 Esempio numerico

Tristemente queste sono funzioni trascendentali per le quali non è possibile trovare soluzioni matematiche particolarmente decenti. Tuttavia si possono mostrare da un punto di vista grafico e si possono analizzare.

Essenzialmente cosa fa il professore è plottare $tan$ e $-cot$ e $\sqrt{\frac{z_0^2}{z^2}-1}$ e vedere dove si intersecano. Quando si intersecano, abbiamo una soluzione.

Notiamo che all'aumentare di $z_0$, ovvero del potenziale, abbiamo più soluzioni (all'inizio ne abbiamo 1, man mano inizia a combaciare con la infinite well potential).

Quindi andiamo ad analizzare i casi limite:
- Se noi mettiamo $z_0$ molto grande
  - Otteniamo $z = \frac{\pi}{2}$
  - Quindi abbiamo $E_n + V_0 = \frac{n^2 \pi^2 \hbar^2}{4 \cdot 2m a^2}$
  - Vediamo che l'equazione è molto simile a quella di ina infinite square well di larghezza $2a$. L'unica cosa che cambia è il fattore di 4.
- Nel caso invece di una **shallow, narrow well**, otteniamo 1 unico, even, bounded state.

## 9.2 Scattering states

L'energia sarà più grande del potenziale in tutti i punti.

Essenzialmente anche qui abbiamo 3 regioni diverse che andiamo ad analizzare una ad una:

**Regione dove $x < -a$**:
- $E > V$
- $\partial_{xx} \psi = -k^2 \psi$
  - $k^2 = \frac{2mE}{\hbar^2}$
- $\psi_1(x) = A e^{ikx} + B e^{-ikx}$

**Regione dove $-a < x < a$**:
- $E > V$
- $\partial_{xx} \psi = -l^2 \psi$
  - $l^2 = \frac{2m}{\hbar^2} (E + V_0)$
- $\psi_2(x) = C \sin(lx) + D \cos(lx)$

**Regione dove $x > a$**:
- $E > V$
- $\partial_{xx} \psi = -k^2 \psi$
- $\psi_3(x) = F e^{ikx} + G e^{-ikx}$

Impostiamo come prima un caso dove non ci interessa una totalità di possibili casi, ma solo quelli dove la particella arriva da sinistra (quindi possiamo impostare $G = 0$).

A questo punto andiamo a creare le equazioni nei boundary:

$$
\text{per } -a
\\ \ \\
A e^{-ika} + B e^{ika} = - C \sin(la) + D \cos(la)
\\ \ \\
ik[A e^{-ika} - B e^{ika}] = l [C \cos(la) + D \sin(la)]
\\ \ \\
\text{per } a
\\ \ \\
C \sin(la) + D \cos(la) = F e^{ika}
\\ \ \\
l [C \cos(la) - D \sin(la)] = ik F e^{ika}
$$

Queste sono le condizioni per $\psi$ e $\frac{d\psi}{dx}$.

A questo punto usiamo le ultime 2 equazioni per eliminare $C,D$. Quindi ci rimangono le equazioni con $A,B,F$. Ciò che si ottiene è:

$$
F = \frac{e^{2ika}A}{\cos(2la) - i \frac{k^2 + l^2}{2kl} sin(2la)}
$$

Quindi possiamo calcolare $T$, ovvero il coefficiente di trasmissione:

$$
T = \frac{|F|^2}{|A|^2}
\\ \ \\
T = \frac{1}{1 + \frac{V_0^2}{4E(E+V_0)} \sin^2(\frac{2a}{\hbar} \sqrt{2mE})}
$$

Possiamo graficare questa $T$ in funzione di $E$ e vedere come si comporta. Ciò che succede è che abbiamo anche riflessione, e non solo trasmissione, in alcuni casi. Abbiamo alcuni casi dove la trasmissione è al $100%$, mentre altri dove il coefficiente non lo è. Questo è diverso dal caso classico ed avviene in picchi che diminuiscono di intensità e aumentano la wavelength nel tempo. Per vederlo graficamente, andare [qui](https://youtu.be/Ex-gF7FQm5o?si=MC5lgm88JwDZ02FA&t=970)

# 10. Linear algebra

## 10.1 Notazione

Andiamo ad utilizzare $\ket{a}$ e $\bra{a}$ per indicare rispettivamente un vettore e il suo trasposto coniugato.

Per questi vettori valgono le seguenti proprietà:
- **Addizione, commutatività**
  - $\ket{a} + \ket{b} = \ket{b} + \ket{a} = \ket{c}$
- **Zero**
  - $\ket{a} + \ket{0} = \ket{a}$
- **Moltiplicazione per scalari**
  - $\alpha \ket{a} = \ket{a} \alpha$
- **Distributiva**
  - $\alpha (\ket{a} + \ket{b}) = \alpha \ket{a} + \alpha \ket{b}$
- **Associativa**
  - $\alpha (\beta \ket{a}) = (\alpha \beta) \ket{a}$
- **Identità**
  - $1 \ket{a} = \ket{a}$

Poi ci viene data la definizione di **linearmente indipendenti**, cosa è una **base**, cosa vuol dire **span** e cosa è la dimensione di uno **spazio vettoriale**.

Poi ci viene definito l'innter product e le sue proprietà:
- L'inner product è definito come:
  - $\braket{a|b}$
- Se invertiamo i termini cambia nel seguente modo:
  - $\braket{a|b} = \braket{b|a}^*$
- $\braket{a|a} \geq 0$
- $\braket{a|a} = 0 \iff \ket{a} = 0$
- $\braket{a|b} = 0 \iff \ket{a} \perp \ket{b}$
  - Si dice che sono "ortogonali"
- $\braket{x_i|x_j} = \delta_{ij}$
  - Allora la base $\ket{x_i}$ è detta "ortonormale"

La **normalizzazione** funziona come segue:
- $||\alpha || = \sqrt{\braket{\alpha | \alpha}}$
  - Ci indica la "lunghezza" del vettore
- $\braket{\alpha | \alpha} = 1$
  - Si dice che il vettore sia normalizzato

**Le componenti**:
- Consideriamo di avere la base $\{\ket{x}, \ket{y}, \ket{z} \}$
  - Allora possiamo scrivere $\ket{a} = a_x \ket{x} + a_y \ket{y} + a_z \ket{z}$
  - E per esempio possiamo definire un altro vettore $\ket{b} = b_x \ket{x} + b_y \ket{y} + b_z \ket{z}$
- Il loro inner product sarà:
  - $\braket{a|b} = a_x^* b_x + a_y^* b_y + a_z^* b_z$
- L'inner product di $\ket{a}$ con se stesso è:
  - $\braket{a|a} = |a_x|^2 + |a_y|^2 + |a_z|^2$
- Per estrarre le singole componenti possiamo fare $a_x = \braket{x|a}$

Possiamo definire tutto ciò più rigorosamente usando delle sommatorie:
- Data la base $\{\ket{x_i}\}$, possiamo scrivere $\ket{a} = \sum_i a_i \ket{x_i}$
- L'inner product sarà $\braket{a|b} = \sum_i a_i^* b_i$
- L'inner product di $\ket{a}$ con se stesso sarà $\braket{a|a} = \sum_i |a_i|^2$

## 10.2 Schwarz inequality

Questa ci dice che:

$$
|\braket{a | b}|^2 <\leq \braket{a|a} \braket{b|b}
$$

## 10.3 Linear transformations

Una trasformazione lineare, che indicheremo con $\hat{T}$, è una funzione che deve appunto essere lineare, ovvero:

$$
\hat{T}(\alpha \ket{a} + \beta \ket{b}) = \alpha \hat{T}(\ket{a}) + \beta \hat{T}(\ket{b})
$$

Immaginiamo di avere una base $\{\ket{x_i}\}$ e una trasformazione lineare $\hat{T}$, possiamo scrivere:

$$
\hat{T} \ket{x_1} = T_{11} \ket{x_1} + T_{12} \ket{x_2} + T_{13} \ket{x_3} + ...
\\ \ \\
\hat{T} \ket{x_2} = T_{21} \ket{x_1} + T_{22} \ket{x_2} + T_{23} \ket{x_3} + ...
\\ \ \\
\vdots
$$

Se noi abbiamo che $\ket{a} = a_1 \ket{x_1} + a_2 \ket{x_2} + a_3 \ket{x_3} + ...$, allora possiamo scrivere:

$$
\ket{a} = \sum_{j = 1}^{n} a_j \ket{x_j}
$$

E quindi la nostra trasformazione lineare sarà:

$$
\hat{T} \ket{a} = \sum_{i=1}^{n} \sum_{j=1}^{n} T_{ij} a_j \ket{x_i}
$$

Usando usa base, possiamo esprimere $\hat{T}$ come una matrice, ovvero:

$$
\hat{T} \to T_{ij} \to \begin{bmatrix}
T_{11} & T_{12} & T_{13} & \dots \\
T_{21} & T_{22} & T_{23} & \dots \\
T_{31} & T_{32} & T_{33} & \dots \\
\vdots & \vdots & \vdots & \ddots
\end{bmatrix}
$$

Se vogliamo "tirare fuori" un valore da questa matrice, possiamo fare:

$$
T_{ij} = \braket{x_i | \hat{T} | x_j}
$$

Dove $\ket{x_i}$ e $\ket{x_j}$ due elemnti della base che ci danno l'indice.

Quindi noi possiamo scrivere $\ket{a}$ come un vettore colonna e pertanto avere:

$$
\hat{T} \ket{a} = \begin{bmatrix}
T_{11} & T_{12} & T_{13} & \dots \\
T_{21} & T_{22} & T_{23} & \dots \\
T_{31} & T_{32} & T_{33} & \dots \\
\vdots & \vdots & \vdots & \ddots
\end{bmatrix} \begin{bmatrix}
a_1 \\
a_2 \\
a_3 \\
\vdots
\end{bmatrix}
$$

Si possono combinare delle trasformazioni lineari tra di loro, ottenendo:

$$
(\hat{A} + \hat{B}) \ket{a} = \hat{A} \ket{a} + \hat{B} \ket{a}
\\ \ \\
(\hat{A} \hat{B}) \ket{a} = \hat{A} (\hat{B} \ket{a})
$$

E questo lo possiamo tradurre nelle operazioni sulle matrici:

$$
(\hat{A} + \hat{B})_{ij} = A_{ij} + B_{ij}
\\ \ \\
(\hat{A} \hat{B})_{ij} = \sum_k A_{ik} B_{kj}
$$

Hanno diverse proprietà:
- **Trasposta**
  - $\tilde{A} := \tilde{A}_{ij} = A_{ji}$
- **Simmetrica**
  - $\tilde{A} = A$
- **Antisimettrica**
  - $\tilde{A} = -A$
- **Complesso conugato**
  - $A^* := A_{ij}^*$
- **Hermitian conjugate (adjoint)**
  - $A^\dagger \equiv \tilde{A}^*$
  - ***Hermitian*** se $A = A^\dagger$
  - ***Unitary*** se $A^\dagger = A^{-1}$

Abbiamo inoltre una definizione più intuitiva dell'inner product:

$$
\braket{a|b} = \alpha^\dagger \beta
$$

Il primo è un vettore riga, l'altro è un vettore colonna che moltiplicati insieme ci danno un unico elemento, che possiamo trattare come scalare.

Altre proprietà delle matrici sono:
- **Commutatore**
  - $[A,B] = AB - BA$
- **Trasposta di $AB$**
  - $\tilde{(AB)} = \tilde{B} \tilde{A}$
- **Dagger**
  - $(AB)^\dagger = B^\dagger A^\dagger$

Abbiamo anche la trasformazione dell'identità che è:

$$
\mathbb{1} \ket{a} = \ket{a}
\\ \ \\
\mathbb{1}_{ij} = \delta_{ij}
$$

Infine abbiamo il cambio di basi, dove possiamo prendere una qualsiasi trasformazione lineare $\hat{A}$ e definirla in più basi, ci basta avere qualcosa che ci porta da una base all'altra.

## 10.4 Eigenvalues and eigenvectors

Essenzialmente gli **eigenvectors** sono quelli che non cambiano direzione dopo l'applicazione della trasformazione lineare e gli **eigenvalues** sono i valori che vengono moltiplicati per questi vettori. Questo si scrive come:$

$$
\hat{T} \ket{a} = \lambda \ket{a}
$$

Con $\lambda$ che è l'eigenvalue e $\ket{a}$ che è l'eigenvector.

Per trovare gli **eigenvalues** dobbiamo trovare le soluzioni di:

$$
\det(T - \lambda \mathbb{I}) = 0
$$

Per trovare invece gli **eigenvalues**, dobbiamo risolvere:

$$
(T - \lambda \mathbb{I}) \ket{a} = 0
$$

E ottenere $\ket{a}$, e lo facciamo per ogni $\lambda$.

### 10.4.1 Diagonalizzazione

Diagonalizzare vuol dire modificare la base di una trasformazione lineare in modo da avere tutti gli **eigenvalues** sulla diagonale.

Come si fa? Data la trasformazione lineare $\hat{T}$, la quale ha, nella base $\{\ket{x_i}\}$, gli eigenvalues $\lambda_i$ e gli eigenvectors $\ket{v_i}$, possiamo scrivere:

$$
T^{\text{diag}} = S^{-1} A S
\\ \ \\
S = \begin{bmatrix}
\ket{v_1} & \ket{v_2} & \ket{v_3} & \dots
\end{bmatrix}
$$

### 10.5 Hermitian transformations

Dato l'Hermitian di una trasformazione lineare, possiamo scrivere:

$$
A^\dagger = \tilde{A}^*
\\ \ \\
\implies 
\\ \ \\
\braket{a | \hat{A} b} = \braket{\hat{A}^\dagger a | b}
$$

Che scrivendo vettori normali sarebbe:

$$
a^\dagger A b = (A^\dagger a)^\dagger b
$$

Un operatore è considerato Hermitiano se $A = A^\dagger$, o anche se non cambia se noi applichiamo $A$ a sinistra o a destra, ovvero:

$$
\braket{a | \hat{A} b} = \braket{\hat{A} a | b}
$$

Le trasformazioni **hermitian** hanno belle proprietà:
- **Gli eigenvalues sono reali**
- **Gli eigenvectors sono ortogonali**
- **Gli eigenventors spannano lo spazio** 

# 11. Mathematical formalism of quantum mechanics

Abbiamo visto che possiamo andare ad esprimere le funzioni d'onda in tanti diversi modi e non solo, hanno anche associate ad esse diverse operazioni e cose che si possono fare. Questo ci va a suggerire che c'è qualcosa più profondo che sta alla base di tutto ciò, che andremo ad esplorare in questa sezione dove ci concentriamo sul rendere più formalmente corretto il tutto.

## 11.1 Linear algebra in Hilbert space

Innanzitutto:
- **Hilbert space** è uno spazio vettoriale di dimensione *infinita*. Ha molte caratteristiche condivise con gli spazi vettoriali con i quali siamo familiari quindi andiamo a tradurre tutti questi concetti:

Abbiamo dei **vettori**: $\ket{a}$, che possiamo immagine esprimano uno stato, ovvero una $\psi(x)$. Spesso la rappresentazione vettoriale è molto più utile per la MQ, difatti riusciremo a trarre conclusioni importanti anche senza fare mai riferimento alla funzione d'onda concreta.

Abbiamo **l'inner product**: $\braket{\beta | \alpha}$ che corrisponde all'integrale della funzione d'onda coniugata, ovvero $\int_{-\infty}^{+\infty} \psi_\beta^*(x) \psi_\alpha(x) dx$. Questo ci permette di calcolare la probabilità di transizione tra due stati.

Abbiamo inoltre il concetto di **normalizzazione**, secondo il quale $\braket{\alpha | \alpha} = 1$ indica che $\ket{\alpha}$ è normalizzato. Questo corrisponde a $\int_{-\infty}^{+\infty} |\psi_\alpha(x)|^2 dx = 1$.

Poi vi è il concetto di **ortogonalità**:
- Per gli spazi vettoriali finiti è piuttosto facile da immaginare: ci basta pensare che i vettori sono tra loro perpendicolari
- Nello **spazio di Hilbert** possiamo semplicemente dire che due vettori sono ortogonali se il loro inner product è 0, ovvero $\braket{\alpha | \beta} = 0$
- Tradotto in quello che abbiamo fatto fin'ora, con gli integrali, possiamo scrivere che $\int_{-\infty}^{+\infty} \psi_\alpha^*(x) \psi_\beta(x) dx = 0$
- Quest'ultima cosa la possiamo immaginare nel seguente modo: dato un set di possibili funzioni d'onda, ovvero $\{\ket{\psi_n}\}$, allora diciamo che è una base ortonormale se $\braket{\psi_n | \psi_m} = \delta_{nm}$ (Da notare che questo ci da sia ortogonalità che la sicurezza che tutti gli elementi sono normalizzati)

Infine abbiamo la **complezza** di una base, ovvero immaginiamo di avere una base $\{\ket{\psi_n}\}$, allora se noi possiamo scrivere qualsiasi vettore $\ket{\psi} = \sum_n c_n \ket{\psi_n}$, allora diciamo che la base è completa (dove possiamo notare che i singoli coefficienti sono: $c_n = \braket{\psi_n | \psi}$, ovvero la proiezione di $\psi$ sull'elemento $\psi_n$ (concettualmente)).

## 11.2 Observables

Essi saranno dei valori reali che hanno un determinato expectation value, che per ora abbiamo visto espressi come $\braket{Q}$. L'osservabile sarà un operatore, che quindi scriveremo come $\hat{Q}$.

Consideriamo quindi $\braket{Q}$:
- Questo si può scrivere, per il linguaggio che abbiamo studiato prima, come $\int_{-\infty}^{+\infty} \psi^*(x) Q \psi(x) dx$
- Con il nuovo linguaggio, possiamo scrivere $\braket{Q} = \braket{\psi | \hat{Q} | \psi}$ o anche $\braket{Q} = \braket{\psi | \hat{Q} \psi}$
  - Da notare che scrivere $\hat{Q} \ket{\psi}$, stiamo dicendo che $\hat{Q}$ agisce su $\ket{\psi}$ e ci dà un nuovo vettore
- Se noi andiamo a prendere il suo complex conjugate otteniamo: $\braket{Q}^* = \braket{\psi | \hat{Q} \psi}^* = \braket{\hat{Q} \psi | \psi}$
- Notiamo che: **il valore di aspettazione è reale**, quindi lui e il suo complesso coniugato sono la **stessa cosa**. Quindi deve valere l'equazione: $\braket{\hat{Q} \psi | \psi} = \braket{\psi | \hat{Q} \psi}$, questo vuol dire che $\hat{Q}$ è un **operatore hermitiano**.
  - Viene poi dimostrato che $\hat{p}$ è un operatore hermitiano:

$$
\braket{f | \hat{p} g} \overset{?}{=} \braket{\hat{p} f | g}
\\ \ \\
\int_{-\infty}^{\infty} f^* (x) \left( -i \hbar \frac{d}{dx} \right) g(x) dx \overset{?}{=} \int_{-\infty}^{\infty} \left( -i \hbar \frac{d}{dx} f(x) \right)^* g(x) dx
\\ \ \\
-i \hbar \left( f^*(x) g(x) |_{-\infty}^{\infty} - \int_{-\infty}^{\infty} \frac{df(x)}{dx} g(x) \ dx \right) \overset{?}{=} -i \hbar \int_{-\infty}^{\infty} \frac{df(x)}{dx} g(x) dx
\\ \ \\
\text{Ma visto che } f^*(x) g(x) |_{-\infty}^{\infty} = 0 \text{ (sono square integrable), allora abbiamo che } \braket{f | \hat{p} g} = \braket{\hat{p} f | g}
$$

## 11.3 States with no uncertainty

Si chiamano anche **determinate states**. Per esempio possiamo immaginare $\hat{Q}$, che quindi ci dà l'osservabile $Q$ e vogliamo capire se questo ci dà un valore ben definito o meno.

Alcune cose, come la posizione o il momentum, tendenzialmente non saranno defined states. 

Andiamo quindi a vedere la deviazione standard di un osservabile, che è definita come:

$$
\sigma_Q^2 = \braket{(\hat{Q}-\braket{Q})^2} \quad (= \braket{\hat{Q}^2} - \braket{Q}^2)
\\ \ \\
= \braket{\psi | (\hat{Q} - \braket{Q})^2 | \psi}
\\ \ \\
= \braket{(\hat{Q} - \braket{Q}) \psi | (\hat{Q} - \braket{Q}) | \psi} = 0
\\ \ \\
\text{E vogliamo che sia 0, che quindi sia un determinate state}
\\ 
\text{Abbiamo che } \psi=0 \text{, ma questo risultato è triviale, oppure che:}
\\ \ \\
(\hat{Q} - \braket{Q}) \ket{\psi} = 0
\\ \ \\
\hat{Q} \ket{\psi} = \braket{Q} \ket{\psi}
$$

Quest'ultimo è un **eigenvalue problem**, in quanto come notiamo stiamo descrivendo un vettore che non cambia direzione dopo l'applicazione di $\hat{Q}$, ma solo la moltiplica per un valore.

Notiamo anche che per esempio l'energia di un sistema legato è un determinate state, in quanto è un osservabile che ha un valore ben definito (notiamo il parallelismo di $\hat{H}\ket{\psi} = E\ket{\psi}$ con $\hat{Q}\ket{\psi} = \braket{Q}\ket{\psi}$).

## 11.4 Hermitian operators and eigenvalue problems

Ricordiamo cosa è un **Hermitian operator**: un operatore $\hat{Q}$ è Hermitian $\iff$ $\braket{f | \hat{Q} g} = \braket{\hat{Q} f | g}$, $\forall \ket{f}, \ket{g}$.

Uno stato generico invece di un **eigeinvalue problem** è:

$$
\hat{Q} \ket{\psi} = q \ket{\psi}
$$

Quindi applicare l'operatore $\hat{Q}$ lo modifica di un fattore $q$.

Per esempio la TISE è un eigenvalue problem, in quanto possiamo scrivere:

$$
\hat{H} \ket{\psi} = E \ket{\psi}
$$

Quello che cerchiamo di ottenere saranno quindi:
- Degli **eigeinstates** $\ket{\psi}$
  - Ce ne saranno tanti
- Degli **eigenvalues** $q$
  - Ce ne sarà uno per ogni stato (di solito), quindi ce ne saranno tanti anche di questi

Abbiamo due tipi di classi di soluzioni:
- **Discrete**
  - Dove abbiamo un numero discreto di soluzioni che possiamo scrivere come lista
  - $\{\ket{\psi_n}\}$ e $\{q_n\}$
  - Per esempio: **particle in a box**, la TISE ci da un numero discreto di soluzioni
- **Continuous**
  - Abbiamo un tipo di soluzioni che sono del tipo $\hat{p}\ket{\psi} = p \ket{\psi}$, dove $p$ è un numero continuo
  - Le nostre soluzioni sono del tipo: $\psi_k(x) = \frac{1}{\sqrt{2\pi}} e^{i(kx - \frac{\hbar k^2}{2m}t)}$, dove $k$ è un numero continuo
  - Quindi questo valore può essere qualsiasi cosa, quindi abbiamo un numero continuo di soluzioni
- Le matematiche che usiamo per l'uno e l'altro saranno diversi

### 11.4.1 Eigenvalues of hermitian operators are *real*

Dimostriamo che gli eigenvalues di un operatore hermitiano sono reali:

$$
\hat{Q} \ket{\psi} = q \ket{\psi} \quad \overset{*}{\to} \quad \bra{\hat{Q}\psi} = q^* \bra{\psi}
\\ \ \\
\text{Abbiamo questa cosa: } \braket{\psi | \hat{Q} \psi} = \braket{\hat{Q} \psi | \psi}
\\ \ \\
\text{Ma possiamo scrivere questa cosa come: } \braket{\psi | \hat{Q} \psi} = \braket{\psi | q \psi} = q \braket{\psi | \psi}
\\ \ \\
\text{E possiamo scrivere questa cosa come: } \braket{\hat{Q} \psi | \psi} = \braket{q \psi | \psi} = q^* \braket{\psi | \psi}
\\ \ \\
\text{Quindi abbiamo che: } q \braket{\psi | \psi} = q^* \braket{\psi | \psi}
\\ \ \\
\text{Ma visto che } \braket{\psi | \psi} \neq 0 \text{, allora abbiamo che } q = q^*
$$

### 11.4.2 Eigenstates of hermitian operators are orthogonal

Andiamo a dimostrare questa cosa:

$$
\hat{Q} \ket{\psi_n} = q_n \ket{\psi_n} \quad \text{e} \quad \hat{Q} \ket{\psi_m} = q_m \ket{\psi_m}
\\ \ \\
\braket{\psi_n | \hat{Q} \psi_m} = \braket{\hat{Q} \psi_n | \psi_m}
\\ \ \\
\braket{\psi_n | q_m \psi_m} = \braket{q_n \psi_n | \psi_m}
\\ \ \\
q_m \braket{\psi_n | \psi_m} = q_n \braket{\psi_n | \psi_m}
\\ \ \\
\braket{f | g} = 0 \quad \vee \quad q_m = q_n
$$

In particolare però diciamo che se $q_m = q_n$, allora $\ket{\psi_n}$ e $\ket{\psi_m}$ sono **degenerate states**, quindi possiamo seguire la **procedura di Gram-Schmidt** per trovare una base ortonormale: si tratta di prendere i due vettori $\ket{\psi_n}$ e $\ket{\psi_m}$ e sottrarre la loro proiezione l'uno sull'altro, ottenendo così due vettori ortogonali tra di loro (che sono la superposizione dei due vettori originali).

### 11.4.3 Completeness of eigenstates

Dato:

$$
\hat{Q} \ket{\psi_n} = q_n \ket{\psi_n} \quad, \quad \{\ket{\psi_n}\}, \{q_n\}
$$

La completezza vuol dire che i nostri vettori "spannano" l'intero spazio, quindi: **qualsiasi** $\ket{f}$ può essere scritto come una combinazione lineare di questi vettori:

$$
\ket{f} = \sum_n c_n \ket{\psi_n}
$$

Si può applicare fourier's trick per ottenere il valore di $c_n$:

$$
c_n = \braket{\psi_n | f}
$$

Da notare che la completezza non viene tendenzialmente provata in quanto la matematica alla base è più complessa. Tuttavia viene spesso "presa per scontata".

### 11.4.4 Continuous spectrum

Ritorniamo indietro e scriviamo l'espressione e il tipo di soluzioni che otteniamo e i loro eigenvalues:

$$
\hat{p} \ket{\psi} = p \ket{\psi} \quad, \quad e^{i(kx - \frac{\hbar k^2}{2m}t)} , \hbar k
$$

Il primo problema è che questo **non è normalizzabile**. Questo vuol dire che $\braket{\psi | \psi} = ?$, quindi non possiamo usare la stessa matematica che abbiamo usato prima.

Cosa vuol dire quindi l'ortogonalità in questo caso? Abbiamo che:

$$
\braket{\psi_{p_1} | \psi_{p_2}} = \int_{-\infty}^{+\infty} \psi_{p_1}^*(x) \psi_{p_2}(x) dx =
\\ \ \\
= \int_{-\infty}^{+\infty} e^{-i(k_1x - \frac{\hbar k_1^2}{2m}t)} e^{i(k_2x - \frac{\hbar k_2^2}{2m}t)} dx
\\ \ \\
= \int_{-\infty}^{+\infty} e^{i(k_2 - k_1)x} dx
\\ \ \\
\text{Se } k_1 = k_2 \text{, allora abbiamo che } \braket{\psi_{p_1} | \psi_{p_2}} = \infty
\\ \ \\
\text{Se } k_1 \neq k_2 \text{, allora abbiamo che } \braket{\psi_{p_1} | \psi_{p_2}} = \int_{-\infty}^{+\infty} e^{i(k_2 - k_1)x} dx \text{ che è una funzione che oscilla} = 0
$$

Da notare che l'ultima equazione è molto un po' per aria: stiamo dicendo: è una funzione che oscilla, sopra e sotto lo 0, quindi sicuramente non va ad infinito come funzione. Diciamo "che è 0", però non è proprio rigorosissima come cosa matematica.

Sappiamo che però formano una **base completa**, in quanto noi abbiamo in precedenza potuto scrivere un onda come:

$$
\psi(x) = \int_{-\infty}^{\infty} dk \phi(k) e^{ikx}
$$

Quindi data una definizione suitable di $\phi(k)$, allora possiamo scrivere qualsiasi funzione come combinazione di queste funzioni. Questo prima l'avevamo calcolato come:

$$
\psi(x) = \int_{-\infty}^{\infty} dk \left( \int_{-\infty}^{\infty} d \xi \psi(\xi) e^{-ik\xi} \right) e^{ikx}
\\ \ \\
= \int_{-\infty}^{\infty} d\xi  \left( \int_{-\infty}^{\infty} dk e^{ik(x-\xi)} \right) \psi(\xi) = \psi(x)
$$

Cosa ci da il valore in un punto quando la moltiplichiamo per la funzione? La Delta di Dirac, ovvero, possiamo scrivere:

$$
\delta(x - \xi) = \int_{-\infty}^{\infty} dk e^{ik(x-\xi)}
$$

Questa espressione vediamo che coincide abbastanza bene con cosa avevamo dedotto prima, ovvero che:

$$
\text{Se } k_1 = k_2 \text{, allora abbiamo che } \braket{\psi_{p_1} | \psi_{p_2}} = \infty
\\ \ \\
\text{Se } k_1 \neq k_2 \text{, allora abbiamo che } \braket{\psi_{p_1} | \psi_{p_2}} = \int_{-\infty}^{+\infty} e^{i(k_2 - k_1)x} dx = 0
$$

Quindi riscriviamo:

$$
\psi(x) = \int_{-\infty}^{\infty} d\xi \delta(x - \xi) \psi(\xi) = \psi(x)
$$

### 11.4.5 Il position operator

$\hat{x}$ è:
- **Hermitian**
- Lo spettro di $\hat{x}$ è **continuo**
  - La posizione della particella può assumere un qualsiasi valore reale
- Le **eigenfunctions** di $\hat{x}$ sono le delta di dirac, quindi abbiamo:
  - $\hat{x} \ket{x} = x \ket{x}$
  - $\hat{x} \delta(x - x_0) = x_0 \delta(x - x_0)$
- E' completo